{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jueunkim429/Cloud-cloud/blob/main/CNN_Cloud_Cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX70GOa1pgC3",
        "outputId": "9aec5f61-8d21-4eb0-a135-3efc42dfb63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: libarchive-c in /usr/local/lib/python3.10/dist-packages (4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install libarchive-c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuEb_3v7pzfI",
        "outputId": "ac558fed-71de-4bcc-fb33-83db2150a3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.22.4)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.1)\n",
            "Requirement already satisfied: pyshp>=2.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.0.0->cartopy) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1->cartopy) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL3ulF7qqO5y",
        "outputId": "c5f6d336-0cd1-4242-c1d6-9a78810b982f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-DFi-fpqQ4O",
        "outputId": "fe89cd27-e347-4845-a7b5-95850de401d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I9WwjvTcpLa1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os, glob, numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.backend import set_session as K\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import libarchive\n",
        "import pydot\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCJ-nD6lq8i-",
        "outputId": "139bf951-c411-4382-d89a-96e62f2dcaac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "import tensorflow.keras\n",
        "print(tensorflow.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzqQpOpoq_JP",
        "outputId": "053a314c-20b4-494f-8fcf-6f91c16af1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image를 학습데이터로 변환"
      ],
      "metadata": {
        "id": "77sU2UXKm0i6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKKuyIoTyzLT",
        "outputId": "beeedb16-a63d-467e-bf5b-d997bfc92c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N163_0_181.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N168_0_4735.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N209_0_5639.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N253_0_7349.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N059_0_6502.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N111_0_8293.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N145_0_4242.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/Ns-N091.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Ns/new_Ns-N026_0_7109.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N103_0_5491.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N105_0_6055.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N152_0_5524.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N197_0_4664.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N022_0_1460.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N029_0_4803.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/St/new_St-N090_0_1701.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N156_0_5806.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N149_0_1911.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N159_0_1495.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N227_0_2302.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N012_0_9875.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N063_0_4613.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/new_Cb-N111_0_8320.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cb/Cb-N115.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N233_0_5472.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N267_0_1416.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N310_0_3576.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N323_0_6181.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N108_0_7183.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N144_0_2927.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N167_0_6436.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/Sc-N287.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N035_0_7189.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/new_Sc-N077_0_5835.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Sc/Sc-N009.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N115_0_4823.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N189_0_5038.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N202_0_5746.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N238_0_7965.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N067_0_2039.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N092_0_8313.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N135_0_2630.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/Cc-N088.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train4/Cc/new_Cc-N009_0_6962.jpg\n"
          ]
        }
      ],
      "source": [
        "img_dir =  \"/content/drive/MyDrive/Colab Notebooks/clouddata/train4\" #학습데이터로 변환할 데이터 위치\n",
        "categories = os.listdir(img_dir)\n",
        "num_classes = len(categories)\n",
        "\n",
        "image_w = 64  #64*64*3 사이즈로 조정\n",
        "image_h = 64\n",
        "\n",
        "pixel=  image_w * image_h * 3\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for idx, cat in enumerate(categories): # 카테고리를 enumerate를 이용하여 카테고리와 인덱스 사용\n",
        "    img_dir_detail = img_dir + '/' + cat\n",
        "    files = glob.glob(img_dir_detail + \"/*.jpg\")\n",
        "    for i,f in enumerate(files):\n",
        "        try:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('RGB')\n",
        "            img = img.resize((image_w,image_h)) #이미지의 사이즈를 조정\n",
        "            data = np.asarray(img)\n",
        "            X.append(data)\n",
        "            y.append(idx)\n",
        "            if i % 300 == 0 : # 300번 마다 프린트\n",
        "                print(cat, \" : \", f)\n",
        "        except:\n",
        "            print(cat,str(i),\" 번째에서 에러\")\n",
        "\n",
        "X = np.array(X)  #array로 변환\n",
        "y = np.array(y)  #array로 변환\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3) #train test 구분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4OsknnR0WDb"
      },
      "source": [
        "## 학습데이터 가공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uLDY5yh0ZXh",
        "outputId": "771703d5-ee71-4c2a-e2f8-296fa58e8955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8579, 64, 64, 3)\n",
            "(8579,)\n",
            "(3678, 64, 64, 3)\n",
            "(3678,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape) # 데이터 크기 확인\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# img를 array로 변환시 0~255의 값을 가지는데 이것을 0~1로 변환\n",
        "X_train = X_train.astype(float) / 255.0\n",
        "X_test = X_test.astype(float) / 255.0\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "# 기존의 1의 값을가지는 y값을 [0,1,0,0,---]와 같이 변환\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCvW0wvM0d05"
      },
      "source": [
        "## 모델 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 1"
      ],
      "metadata": {
        "id": "1378HxWJBN5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4O4u7E_uz76B"
      },
      "outputs": [],
      "source": [
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model'\n",
        "    model_path = model_dir + \"/cloud_classify.model\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LtDJgVI05II",
        "outputId": "245ffa7c-b888-4cff-992c-ec464ddfcd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkP_irWDqdVS",
        "outputId": "0fa23dfa-328f-4a39-88a8-06c26fb2dd84"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 13s 11ms/step - loss: 1.3715 - accuracy: 0.4306 - val_loss: 1.2233 - val_accuracy: 0.5070\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1671 - accuracy: 0.5283 - val_loss: 1.0850 - val_accuracy: 0.5513\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0524 - accuracy: 0.5697 - val_loss: 1.0042 - val_accuracy: 0.6084\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9647 - accuracy: 0.6182 - val_loss: 0.9032 - val_accuracy: 0.6457\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8389 - accuracy: 0.6665 - val_loss: 0.8168 - val_accuracy: 0.6760\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7538 - accuracy: 0.7019 - val_loss: 0.7386 - val_accuracy: 0.7075\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6788 - accuracy: 0.7315 - val_loss: 0.6569 - val_accuracy: 0.7471\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5790 - accuracy: 0.7774 - val_loss: 0.5709 - val_accuracy: 0.7751\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5370 - accuracy: 0.7894 - val_loss: 0.5292 - val_accuracy: 0.7925\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4606 - accuracy: 0.8202 - val_loss: 0.5599 - val_accuracy: 0.7692\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4260 - accuracy: 0.8336 - val_loss: 0.5163 - val_accuracy: 0.8135\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3740 - accuracy: 0.8587 - val_loss: 0.4118 - val_accuracy: 0.8298\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3429 - accuracy: 0.8719 - val_loss: 0.3548 - val_accuracy: 0.8695\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3234 - accuracy: 0.8768 - val_loss: 0.3438 - val_accuracy: 0.8858\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2870 - accuracy: 0.8909 - val_loss: 0.3377 - val_accuracy: 0.8776\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2527 - accuracy: 0.9053 - val_loss: 0.3354 - val_accuracy: 0.8834\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2420 - accuracy: 0.9118 - val_loss: 0.2934 - val_accuracy: 0.8963\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2284 - accuracy: 0.9148 - val_loss: 0.2994 - val_accuracy: 0.8858\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2228 - accuracy: 0.9163 - val_loss: 0.3097 - val_accuracy: 0.8916\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1960 - accuracy: 0.9251 - val_loss: 0.2949 - val_accuracy: 0.8951\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1979 - accuracy: 0.9248 - val_loss: 0.2906 - val_accuracy: 0.9009\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1956 - accuracy: 0.9281 - val_loss: 0.2596 - val_accuracy: 0.9021\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1886 - accuracy: 0.9270 - val_loss: 0.2865 - val_accuracy: 0.9021\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1744 - accuracy: 0.9358 - val_loss: 0.2806 - val_accuracy: 0.8963\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1691 - accuracy: 0.9389 - val_loss: 0.2677 - val_accuracy: 0.9091\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1619 - accuracy: 0.9403 - val_loss: 0.3250 - val_accuracy: 0.8858\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1711 - accuracy: 0.9347 - val_loss: 0.2292 - val_accuracy: 0.9044\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1473 - accuracy: 0.9416 - val_loss: 0.2429 - val_accuracy: 0.9207\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1487 - accuracy: 0.9425 - val_loss: 0.2543 - val_accuracy: 0.9103\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1559 - accuracy: 0.9367 - val_loss: 0.2862 - val_accuracy: 0.9044\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1454 - accuracy: 0.9459 - val_loss: 0.2396 - val_accuracy: 0.9289\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1376 - accuracy: 0.9488 - val_loss: 0.2948 - val_accuracy: 0.9021\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1384 - accuracy: 0.9473 - val_loss: 0.2745 - val_accuracy: 0.9138\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1449 - accuracy: 0.9463 - val_loss: 0.2657 - val_accuracy: 0.9114\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1420 - accuracy: 0.9491 - val_loss: 0.3176 - val_accuracy: 0.8904\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1260 - accuracy: 0.9509 - val_loss: 0.2618 - val_accuracy: 0.9266\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1313 - accuracy: 0.9514 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1156 - accuracy: 0.9547 - val_loss: 0.2948 - val_accuracy: 0.9149\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1165 - accuracy: 0.9553 - val_loss: 0.2267 - val_accuracy: 0.9359\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1119 - accuracy: 0.9617 - val_loss: 0.3079 - val_accuracy: 0.9021\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1256 - accuracy: 0.9536 - val_loss: 0.2651 - val_accuracy: 0.9126\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1165 - accuracy: 0.9557 - val_loss: 0.3183 - val_accuracy: 0.9033\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1124 - accuracy: 0.9582 - val_loss: 0.2548 - val_accuracy: 0.9079\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1115 - accuracy: 0.9569 - val_loss: 0.2989 - val_accuracy: 0.9021\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1060 - accuracy: 0.9604 - val_loss: 0.3104 - val_accuracy: 0.9044\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1043 - accuracy: 0.9608 - val_loss: 0.2820 - val_accuracy: 0.9126\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1044 - accuracy: 0.9604 - val_loss: 0.3320 - val_accuracy: 0.9056\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1092 - accuracy: 0.9604 - val_loss: 0.2888 - val_accuracy: 0.9161\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1099 - accuracy: 0.9586 - val_loss: 0.3540 - val_accuracy: 0.9009\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1164 - accuracy: 0.9587 - val_loss: 0.2574 - val_accuracy: 0.9289\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0961 - accuracy: 0.9627 - val_loss: 0.2703 - val_accuracy: 0.9219\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0868 - accuracy: 0.9670 - val_loss: 0.2783 - val_accuracy: 0.9254\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0835 - accuracy: 0.9679 - val_loss: 0.2898 - val_accuracy: 0.9231\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0952 - accuracy: 0.9641 - val_loss: 0.3070 - val_accuracy: 0.9091\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0853 - accuracy: 0.9676 - val_loss: 0.2776 - val_accuracy: 0.9196\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0933 - accuracy: 0.9653 - val_loss: 0.4021 - val_accuracy: 0.8893\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0972 - accuracy: 0.9637 - val_loss: 0.3086 - val_accuracy: 0.9149\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.2766 - val_accuracy: 0.9219\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1089 - accuracy: 0.9615 - val_loss: 0.2747 - val_accuracy: 0.9196\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0796 - accuracy: 0.9694 - val_loss: 0.2380 - val_accuracy: 0.9312\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0852 - accuracy: 0.9689 - val_loss: 0.2832 - val_accuracy: 0.9207\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0857 - accuracy: 0.9685 - val_loss: 0.2675 - val_accuracy: 0.9289\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 0.2917 - val_accuracy: 0.9266\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0856 - accuracy: 0.9697 - val_loss: 0.2810 - val_accuracy: 0.9301\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0891 - accuracy: 0.9666 - val_loss: 0.2609 - val_accuracy: 0.9324\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1088 - accuracy: 0.9602 - val_loss: 0.2986 - val_accuracy: 0.9219\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0869 - accuracy: 0.9668 - val_loss: 0.2969 - val_accuracy: 0.9242\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.3052 - val_accuracy: 0.9289\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0743 - accuracy: 0.9718 - val_loss: 0.3474 - val_accuracy: 0.9103\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0762 - accuracy: 0.9687 - val_loss: 0.3395 - val_accuracy: 0.9149\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.3573 - val_accuracy: 0.9114\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0838 - accuracy: 0.9694 - val_loss: 0.3079 - val_accuracy: 0.9184\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0774 - accuracy: 0.9724 - val_loss: 0.3173 - val_accuracy: 0.9242\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0741 - accuracy: 0.9737 - val_loss: 0.3374 - val_accuracy: 0.9196\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0941 - accuracy: 0.9679 - val_loss: 0.3176 - val_accuracy: 0.9242\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0756 - accuracy: 0.9727 - val_loss: 0.3274 - val_accuracy: 0.9161\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 0.3160 - val_accuracy: 0.9172\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0849 - accuracy: 0.9701 - val_loss: 0.2843 - val_accuracy: 0.9184\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0762 - accuracy: 0.9700 - val_loss: 0.3163 - val_accuracy: 0.9231\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0566 - accuracy: 0.9788 - val_loss: 0.3698 - val_accuracy: 0.9184\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0691 - accuracy: 0.9749 - val_loss: 0.3427 - val_accuracy: 0.9172\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.3181 - val_accuracy: 0.9138\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0675 - accuracy: 0.9742 - val_loss: 0.3337 - val_accuracy: 0.9196\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0914 - accuracy: 0.9687 - val_loss: 0.3199 - val_accuracy: 0.9091\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0731 - accuracy: 0.9720 - val_loss: 0.2990 - val_accuracy: 0.9254\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0596 - accuracy: 0.9769 - val_loss: 0.3511 - val_accuracy: 0.9231\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0903 - accuracy: 0.9684 - val_loss: 0.3506 - val_accuracy: 0.9184\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0632 - accuracy: 0.9772 - val_loss: 0.3412 - val_accuracy: 0.9184\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0751 - accuracy: 0.9742 - val_loss: 0.3780 - val_accuracy: 0.9184\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0724 - accuracy: 0.9731 - val_loss: 0.3425 - val_accuracy: 0.9172\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0627 - accuracy: 0.9769 - val_loss: 0.3357 - val_accuracy: 0.9324\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0677 - accuracy: 0.9744 - val_loss: 0.3714 - val_accuracy: 0.9103\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0750 - accuracy: 0.9715 - val_loss: 0.3844 - val_accuracy: 0.9138\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0693 - accuracy: 0.9749 - val_loss: 0.3490 - val_accuracy: 0.9254\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0643 - accuracy: 0.9768 - val_loss: 0.3639 - val_accuracy: 0.9149\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0690 - accuracy: 0.9755 - val_loss: 0.3209 - val_accuracy: 0.9242\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0746 - accuracy: 0.9736 - val_loss: 0.2956 - val_accuracy: 0.9254\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0607 - accuracy: 0.9777 - val_loss: 0.3773 - val_accuracy: 0.9207\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 0.3677 - val_accuracy: 0.9196\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0804 - accuracy: 0.9737 - val_loss: 0.3649 - val_accuracy: 0.9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"정확도 : %.2f\" %(model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sijwAwL_srAw",
        "outputId": "8a06f065-d62e-44e7-c8d5-217337dc5bef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 1s 4ms/step - loss: 0.3675 - accuracy: 0.9241\n",
            "정확도 : 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3HIcRwbqugE",
        "outputId": "2c1efbab-0785-48fc-9dde-4a6b94c0a980"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9253\n",
            "평균 손실: 0.1941\n",
            "평균 검증 정확도: 0.8877\n",
            "평균 검증 손실: 0.3605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2GzOWo31s5V"
      },
      "source": [
        "### model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d-4hviku1vTX"
      },
      "outputs": [],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model2 = Sequential()\n",
        "\n",
        "    model2.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model2.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(256, activation = 'relu'))\n",
        "    model2.add(Dropout(0.5))\n",
        "    model2.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model2'\n",
        "    model_path = model_dir + \"/cloud_classify.model2\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNdCALYSsyyL",
        "outputId": "bac46a87-806f-4fbf-b894-db5b3fb1c4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BJ2gUL9jtq0",
        "outputId": "1a053f5b-09da-4a2a-994e-0fc1bb2a9424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 5s 11ms/step - loss: 1.3710 - accuracy: 0.4246 - val_loss: 1.3017 - val_accuracy: 0.4499\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1594 - accuracy: 0.5365 - val_loss: 1.0758 - val_accuracy: 0.5618\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0545 - accuracy: 0.5736 - val_loss: 1.1198 - val_accuracy: 0.5431\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9304 - accuracy: 0.6270 - val_loss: 0.8850 - val_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.8174 - accuracy: 0.6735 - val_loss: 0.7437 - val_accuracy: 0.7075\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7067 - accuracy: 0.7189 - val_loss: 0.6940 - val_accuracy: 0.7214\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5885 - accuracy: 0.7684 - val_loss: 0.5222 - val_accuracy: 0.7867\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5146 - accuracy: 0.8042 - val_loss: 0.4612 - val_accuracy: 0.8252\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4535 - accuracy: 0.8279 - val_loss: 0.4014 - val_accuracy: 0.8566\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4136 - accuracy: 0.8441 - val_loss: 0.4239 - val_accuracy: 0.8508\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3657 - accuracy: 0.8632 - val_loss: 0.3306 - val_accuracy: 0.8776\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3089 - accuracy: 0.8827 - val_loss: 0.2633 - val_accuracy: 0.8951\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2757 - accuracy: 0.8937 - val_loss: 0.3149 - val_accuracy: 0.8753\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2768 - accuracy: 0.8963 - val_loss: 0.3049 - val_accuracy: 0.8974\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2443 - accuracy: 0.9070 - val_loss: 0.2583 - val_accuracy: 0.8939\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2233 - accuracy: 0.9178 - val_loss: 0.2934 - val_accuracy: 0.8846\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2254 - accuracy: 0.9144 - val_loss: 0.2875 - val_accuracy: 0.8869\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2082 - accuracy: 0.9258 - val_loss: 0.2289 - val_accuracy: 0.9114\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1930 - accuracy: 0.9271 - val_loss: 0.2255 - val_accuracy: 0.9254\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1910 - accuracy: 0.9288 - val_loss: 0.2188 - val_accuracy: 0.9149\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1633 - accuracy: 0.9394 - val_loss: 0.1955 - val_accuracy: 0.9231\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1677 - accuracy: 0.9399 - val_loss: 0.2550 - val_accuracy: 0.9219\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1767 - accuracy: 0.9336 - val_loss: 0.2095 - val_accuracy: 0.9289\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1684 - accuracy: 0.9345 - val_loss: 0.2173 - val_accuracy: 0.9196\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1554 - accuracy: 0.9434 - val_loss: 0.1727 - val_accuracy: 0.9382\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1425 - accuracy: 0.9487 - val_loss: 0.1794 - val_accuracy: 0.9324\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1353 - accuracy: 0.9500 - val_loss: 0.3663 - val_accuracy: 0.8741\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1460 - accuracy: 0.9468 - val_loss: 0.2205 - val_accuracy: 0.9196\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1502 - accuracy: 0.9460 - val_loss: 0.2261 - val_accuracy: 0.9289\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1569 - accuracy: 0.9359 - val_loss: 0.2356 - val_accuracy: 0.9196\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1300 - accuracy: 0.9508 - val_loss: 0.1868 - val_accuracy: 0.9371\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1452 - accuracy: 0.9457 - val_loss: 0.2149 - val_accuracy: 0.9301\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1435 - accuracy: 0.9438 - val_loss: 0.2040 - val_accuracy: 0.9277\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1468 - accuracy: 0.9446 - val_loss: 0.1924 - val_accuracy: 0.9301\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1312 - accuracy: 0.9492 - val_loss: 0.2057 - val_accuracy: 0.9254\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1172 - accuracy: 0.9551 - val_loss: 0.2171 - val_accuracy: 0.9242\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1350 - accuracy: 0.9483 - val_loss: 0.2228 - val_accuracy: 0.9207\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1256 - accuracy: 0.9538 - val_loss: 0.2127 - val_accuracy: 0.9172\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1139 - accuracy: 0.9596 - val_loss: 0.2523 - val_accuracy: 0.9161\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1291 - accuracy: 0.9535 - val_loss: 0.2372 - val_accuracy: 0.9231\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1159 - accuracy: 0.9573 - val_loss: 0.2597 - val_accuracy: 0.9161\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1210 - accuracy: 0.9539 - val_loss: 0.1908 - val_accuracy: 0.9359\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1046 - accuracy: 0.9608 - val_loss: 0.1951 - val_accuracy: 0.9347\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1118 - accuracy: 0.9584 - val_loss: 0.2162 - val_accuracy: 0.9231\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1271 - accuracy: 0.9510 - val_loss: 0.2526 - val_accuracy: 0.9242\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1152 - accuracy: 0.9566 - val_loss: 0.1941 - val_accuracy: 0.9266\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1183 - accuracy: 0.9579 - val_loss: 0.1734 - val_accuracy: 0.9429\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1084 - accuracy: 0.9610 - val_loss: 0.2487 - val_accuracy: 0.9231\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0916 - accuracy: 0.9648 - val_loss: 0.1969 - val_accuracy: 0.9406\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1045 - accuracy: 0.9622 - val_loss: 0.2119 - val_accuracy: 0.9406\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1051 - accuracy: 0.9617 - val_loss: 0.2053 - val_accuracy: 0.9406\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1098 - accuracy: 0.9605 - val_loss: 0.2141 - val_accuracy: 0.9301\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1008 - accuracy: 0.9631 - val_loss: 0.1753 - val_accuracy: 0.9312\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1113 - accuracy: 0.9583 - val_loss: 0.2738 - val_accuracy: 0.9184\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0874 - accuracy: 0.9693 - val_loss: 0.2379 - val_accuracy: 0.9254\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0991 - accuracy: 0.9653 - val_loss: 0.2066 - val_accuracy: 0.9452\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1205 - accuracy: 0.9588 - val_loss: 0.2557 - val_accuracy: 0.9103\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1034 - accuracy: 0.9635 - val_loss: 0.2017 - val_accuracy: 0.9324\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0960 - accuracy: 0.9659 - val_loss: 0.1749 - val_accuracy: 0.9347\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0902 - accuracy: 0.9676 - val_loss: 0.2498 - val_accuracy: 0.9266\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0933 - accuracy: 0.9649 - val_loss: 0.2980 - val_accuracy: 0.9103\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0917 - accuracy: 0.9643 - val_loss: 0.1791 - val_accuracy: 0.9429\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1025 - accuracy: 0.9615 - val_loss: 0.1576 - val_accuracy: 0.9429\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1067 - accuracy: 0.9606 - val_loss: 0.2085 - val_accuracy: 0.9429\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1105 - accuracy: 0.9626 - val_loss: 0.1879 - val_accuracy: 0.9429\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0670 - accuracy: 0.9727 - val_loss: 0.2761 - val_accuracy: 0.9347\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1070 - accuracy: 0.9633 - val_loss: 0.3833 - val_accuracy: 0.8834\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0926 - accuracy: 0.9675 - val_loss: 0.2224 - val_accuracy: 0.9382\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0962 - accuracy: 0.9663 - val_loss: 0.2540 - val_accuracy: 0.9336\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0932 - accuracy: 0.9692 - val_loss: 0.2384 - val_accuracy: 0.9394\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0917 - accuracy: 0.9653 - val_loss: 0.1964 - val_accuracy: 0.9429\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0914 - accuracy: 0.9688 - val_loss: 0.2692 - val_accuracy: 0.9371\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1021 - accuracy: 0.9627 - val_loss: 0.2587 - val_accuracy: 0.9289\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0835 - accuracy: 0.9715 - val_loss: 0.2610 - val_accuracy: 0.9161\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0847 - accuracy: 0.9698 - val_loss: 0.2887 - val_accuracy: 0.9138\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.2119 - val_accuracy: 0.9382\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 0.2629 - val_accuracy: 0.9242\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1042 - accuracy: 0.9670 - val_loss: 0.2440 - val_accuracy: 0.9254\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0860 - accuracy: 0.9696 - val_loss: 0.1976 - val_accuracy: 0.9452\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0837 - accuracy: 0.9671 - val_loss: 0.2479 - val_accuracy: 0.9324\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0846 - accuracy: 0.9679 - val_loss: 0.2029 - val_accuracy: 0.9417\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0972 - accuracy: 0.9668 - val_loss: 0.2691 - val_accuracy: 0.9324\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0843 - accuracy: 0.9705 - val_loss: 0.2023 - val_accuracy: 0.9417\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0910 - accuracy: 0.9678 - val_loss: 0.3215 - val_accuracy: 0.9242\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0961 - accuracy: 0.9641 - val_loss: 0.2201 - val_accuracy: 0.9429\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0851 - accuracy: 0.9725 - val_loss: 0.2324 - val_accuracy: 0.9394\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0872 - accuracy: 0.9680 - val_loss: 0.2701 - val_accuracy: 0.9312\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0932 - accuracy: 0.9683 - val_loss: 0.2756 - val_accuracy: 0.9207\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0623 - accuracy: 0.9746 - val_loss: 0.2226 - val_accuracy: 0.9429\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0867 - accuracy: 0.9683 - val_loss: 0.3050 - val_accuracy: 0.9254\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0696 - accuracy: 0.9747 - val_loss: 0.2175 - val_accuracy: 0.9452\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0970 - accuracy: 0.9672 - val_loss: 0.2680 - val_accuracy: 0.9371\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0890 - accuracy: 0.9705 - val_loss: 0.2370 - val_accuracy: 0.9371\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1058 - accuracy: 0.9657 - val_loss: 0.2719 - val_accuracy: 0.9347\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0794 - accuracy: 0.9725 - val_loss: 0.2441 - val_accuracy: 0.9371\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.2663 - val_accuracy: 0.9406\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0736 - accuracy: 0.9738 - val_loss: 0.2351 - val_accuracy: 0.9359\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0700 - accuracy: 0.9769 - val_loss: 0.2073 - val_accuracy: 0.9371\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0676 - accuracy: 0.9755 - val_loss: 0.2834 - val_accuracy: 0.9312\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0862 - accuracy: 0.9711 - val_loss: 0.2709 - val_accuracy: 0.9406\n"
          ]
        }
      ],
      "source": [
        "history = model2.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "U8-w1hlI9W36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57753c6-7400-4275-86eb-0ea7092597e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9275\n",
            "평균 손실: 0.1907\n",
            "평균 검증 정확도: 0.9033\n",
            "평균 검증 손실: 0.2898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2 + normalization"
      ],
      "metadata": {
        "id": "8zHgHkZt_zq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model3 = Sequential()\n",
        "\n",
        "    model3.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(256, activation='relu'))\n",
        "    model3.add(Dropout(0.5))\n",
        "    model3.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model3'\n",
        "    model_path = model_dir + \"/cloud_classify.model3\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "TGx9a-GNBjL-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akOKOhEQBmF1",
        "outputId": "09d34da5-83c6-4588-ad00-cb4a6470709b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64, 64, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,933\n",
            "Trainable params: 2,340,229\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yfVSjEQBolX",
        "outputId": "0514e15b-1e3e-418b-e059-523297ffd871"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1130 - accuracy: 0.9540 - val_loss: 0.2132 - val_accuracy: 0.9277\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1336 - accuracy: 0.9485 - val_loss: 0.3509 - val_accuracy: 0.8974\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1105 - accuracy: 0.9542 - val_loss: 2.2269 - val_accuracy: 0.7098\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1298 - accuracy: 0.9470 - val_loss: 0.1841 - val_accuracy: 0.9347\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1335 - accuracy: 0.9482 - val_loss: 0.1660 - val_accuracy: 0.9441\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1104 - accuracy: 0.9558 - val_loss: 0.1509 - val_accuracy: 0.9417\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1113 - accuracy: 0.9532 - val_loss: 0.4341 - val_accuracy: 0.8998\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1292 - accuracy: 0.9491 - val_loss: 5.6554 - val_accuracy: 0.5594\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1058 - accuracy: 0.9517 - val_loss: 0.1425 - val_accuracy: 0.9545\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1064 - accuracy: 0.9560 - val_loss: 1.2832 - val_accuracy: 0.7867\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1117 - accuracy: 0.9542 - val_loss: 0.6488 - val_accuracy: 0.8566\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1028 - accuracy: 0.9545 - val_loss: 0.2322 - val_accuracy: 0.9266\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1223 - accuracy: 0.9521 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.2499 - val_accuracy: 0.9254\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1012 - accuracy: 0.9571 - val_loss: 0.4926 - val_accuracy: 0.8858\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1018 - accuracy: 0.9583 - val_loss: 0.3187 - val_accuracy: 0.9207\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0971 - accuracy: 0.9606 - val_loss: 0.5631 - val_accuracy: 0.8939\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0927 - accuracy: 0.9622 - val_loss: 2.2505 - val_accuracy: 0.7249\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1122 - accuracy: 0.9554 - val_loss: 0.2882 - val_accuracy: 0.9207\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0894 - accuracy: 0.9649 - val_loss: 0.1531 - val_accuracy: 0.9476\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0990 - accuracy: 0.9626 - val_loss: 0.4970 - val_accuracy: 0.8800\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0987 - accuracy: 0.9582 - val_loss: 0.2333 - val_accuracy: 0.9324\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1057 - accuracy: 0.9575 - val_loss: 0.3143 - val_accuracy: 0.9184\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0951 - accuracy: 0.9633 - val_loss: 0.1956 - val_accuracy: 0.9452\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0894 - accuracy: 0.9637 - val_loss: 0.1686 - val_accuracy: 0.9464\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1153 - accuracy: 0.9553 - val_loss: 0.2453 - val_accuracy: 0.9289\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0823 - accuracy: 0.9650 - val_loss: 0.1599 - val_accuracy: 0.9464\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0901 - accuracy: 0.9623 - val_loss: 0.4189 - val_accuracy: 0.9103\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0861 - accuracy: 0.9662 - val_loss: 0.2127 - val_accuracy: 0.9289\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0793 - accuracy: 0.9654 - val_loss: 0.1899 - val_accuracy: 0.9441\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1041 - accuracy: 0.9582 - val_loss: 0.2942 - val_accuracy: 0.9114\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0826 - accuracy: 0.9698 - val_loss: 0.1886 - val_accuracy: 0.9510\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0913 - accuracy: 0.9630 - val_loss: 0.1722 - val_accuracy: 0.9394\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0919 - accuracy: 0.9644 - val_loss: 0.4701 - val_accuracy: 0.8974\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0738 - accuracy: 0.9702 - val_loss: 0.2448 - val_accuracy: 0.9441\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0827 - accuracy: 0.9665 - val_loss: 0.2877 - val_accuracy: 0.9068\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0708 - accuracy: 0.9711 - val_loss: 0.2903 - val_accuracy: 0.9184\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0725 - accuracy: 0.9710 - val_loss: 26.9189 - val_accuracy: 0.2914\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0759 - accuracy: 0.9690 - val_loss: 3.8112 - val_accuracy: 0.6387\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0843 - accuracy: 0.9668 - val_loss: 0.4825 - val_accuracy: 0.8823\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0697 - accuracy: 0.9722 - val_loss: 0.1907 - val_accuracy: 0.9522\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0688 - accuracy: 0.9701 - val_loss: 0.2463 - val_accuracy: 0.9382\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0628 - accuracy: 0.9719 - val_loss: 0.2474 - val_accuracy: 0.9312\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0735 - accuracy: 0.9714 - val_loss: 0.7288 - val_accuracy: 0.8858\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0687 - accuracy: 0.9701 - val_loss: 22.0768 - val_accuracy: 0.3671\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0794 - accuracy: 0.9689 - val_loss: 0.3830 - val_accuracy: 0.8939\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0762 - accuracy: 0.9692 - val_loss: 0.7619 - val_accuracy: 0.8706\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0690 - accuracy: 0.9709 - val_loss: 0.1894 - val_accuracy: 0.9371\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0785 - accuracy: 0.9687 - val_loss: 0.6748 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0864 - accuracy: 0.9688 - val_loss: 0.2270 - val_accuracy: 0.9499\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 3.9167 - val_accuracy: 0.6760\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0721 - accuracy: 0.9710 - val_loss: 2.2078 - val_accuracy: 0.7541\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0667 - accuracy: 0.9712 - val_loss: 0.6972 - val_accuracy: 0.8555\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0598 - accuracy: 0.9759 - val_loss: 4.9944 - val_accuracy: 0.6643\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0659 - accuracy: 0.9728 - val_loss: 0.4489 - val_accuracy: 0.9114\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0643 - accuracy: 0.9749 - val_loss: 1.2784 - val_accuracy: 0.8193\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.2982 - val_accuracy: 0.9312\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0673 - accuracy: 0.9736 - val_loss: 0.1684 - val_accuracy: 0.9499\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0573 - accuracy: 0.9766 - val_loss: 0.1630 - val_accuracy: 0.9522\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 0.2268 - val_accuracy: 0.9359\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0635 - accuracy: 0.9750 - val_loss: 0.2121 - val_accuracy: 0.9406\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0636 - accuracy: 0.9718 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0595 - accuracy: 0.9745 - val_loss: 1.0682 - val_accuracy: 0.8357\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0636 - accuracy: 0.9741 - val_loss: 0.5407 - val_accuracy: 0.9091\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0602 - accuracy: 0.9753 - val_loss: 0.5251 - val_accuracy: 0.8963\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0668 - accuracy: 0.9729 - val_loss: 0.2549 - val_accuracy: 0.9406\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0641 - accuracy: 0.9722 - val_loss: 0.2707 - val_accuracy: 0.9336\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0672 - accuracy: 0.9745 - val_loss: 0.6674 - val_accuracy: 0.8904\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0577 - accuracy: 0.9750 - val_loss: 0.3767 - val_accuracy: 0.9103\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0621 - accuracy: 0.9749 - val_loss: 0.3420 - val_accuracy: 0.9114\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0741 - accuracy: 0.9738 - val_loss: 0.2341 - val_accuracy: 0.9371\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0542 - accuracy: 0.9786 - val_loss: 0.2478 - val_accuracy: 0.9382\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0581 - accuracy: 0.9755 - val_loss: 0.3851 - val_accuracy: 0.9021\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 0.2395 - val_accuracy: 0.9406\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0599 - accuracy: 0.9773 - val_loss: 0.7089 - val_accuracy: 0.8881\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0604 - accuracy: 0.9745 - val_loss: 0.2267 - val_accuracy: 0.9499\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0578 - accuracy: 0.9749 - val_loss: 0.2649 - val_accuracy: 0.9382\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0619 - accuracy: 0.9759 - val_loss: 0.6916 - val_accuracy: 0.8916\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0609 - accuracy: 0.9757 - val_loss: 0.2006 - val_accuracy: 0.9417\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0570 - accuracy: 0.9749 - val_loss: 0.2370 - val_accuracy: 0.9441\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0575 - accuracy: 0.9769 - val_loss: 9.9871 - val_accuracy: 0.4977\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 0.2879 - val_accuracy: 0.9231\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0514 - accuracy: 0.9775 - val_loss: 0.3547 - val_accuracy: 0.9359\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0702 - accuracy: 0.9766 - val_loss: 0.1928 - val_accuracy: 0.9464\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0632 - accuracy: 0.9753 - val_loss: 1.5865 - val_accuracy: 0.8135\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0514 - accuracy: 0.9803 - val_loss: 0.7006 - val_accuracy: 0.8788\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0487 - accuracy: 0.9798 - val_loss: 0.1995 - val_accuracy: 0.9534\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0514 - accuracy: 0.9803 - val_loss: 0.2777 - val_accuracy: 0.9452\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0618 - accuracy: 0.9760 - val_loss: 0.2460 - val_accuracy: 0.9452\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0617 - accuracy: 0.9771 - val_loss: 0.2712 - val_accuracy: 0.9406\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 4.7261 - val_accuracy: 0.6725\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.0515 - accuracy: 0.9789 - val_loss: 1.8997 - val_accuracy: 0.7844\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0658 - accuracy: 0.9758 - val_loss: 0.2025 - val_accuracy: 0.9464\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0462 - accuracy: 0.9803 - val_loss: 0.3522 - val_accuracy: 0.9207\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0531 - accuracy: 0.9795 - val_loss: 0.2445 - val_accuracy: 0.9347\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0555 - accuracy: 0.9788 - val_loss: 1.0126 - val_accuracy: 0.8788\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0531 - accuracy: 0.9795 - val_loss: 0.2617 - val_accuracy: 0.9499\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0525 - accuracy: 0.9799 - val_loss: 0.5189 - val_accuracy: 0.9103\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0507 - accuracy: 0.9789 - val_loss: 0.9458 - val_accuracy: 0.8753\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.0536 - accuracy: 0.9791 - val_loss: 0.3110 - val_accuracy: 0.9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reHN-FkVGn7-",
        "outputId": "cdacc296-4abc-4b76-d0b3-124fa546a084"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9689\n",
            "평균 손실: 0.0771\n",
            "평균 검증 정확도: 0.8802\n",
            "평균 검증 손실: 1.2463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1 + **normalization**"
      ],
      "metadata": {
        "id": "n2STjUPnIgB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# 모델 구성\n",
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(image_w, image_h, 3), activation=\"relu\"))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model4.add(Dropout(0.25))\n",
        "\n",
        "model4.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model4.add(Dropout(0.25))\n",
        "\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(256, activation='relu'))\n",
        "model4.add(Dropout(0.5))\n",
        "model4.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_dir = './model4'\n",
        "model_path = model_dir + \"/cloud_classify.model4\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "Chv4_PoxIibb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbtYdLSII-8_",
        "outputId": "ca92336f-2042-48af-a945-a210c1d9a183"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,621\n",
            "Trainable params: 4,215,429\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model4.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p1_8OKIJApk",
        "outputId": "a18c35da-6ce1-4671-f06b-af320e5ecf6f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 5s 11ms/step - loss: 1.9721 - accuracy: 0.3830 - val_loss: 9.6367 - val_accuracy: 0.3042\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 1.3328 - accuracy: 0.4278 - val_loss: 1.8203 - val_accuracy: 0.4872\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.2706 - accuracy: 0.4489 - val_loss: 1.2126 - val_accuracy: 0.4918\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.2334 - accuracy: 0.4747 - val_loss: 1.2606 - val_accuracy: 0.4720\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.2167 - accuracy: 0.4769 - val_loss: 1.1019 - val_accuracy: 0.5256\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1723 - accuracy: 0.5128 - val_loss: 1.1512 - val_accuracy: 0.5210\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 1.1384 - accuracy: 0.5217 - val_loss: 1.0533 - val_accuracy: 0.5828\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1213 - accuracy: 0.5277 - val_loss: 1.0172 - val_accuracy: 0.5909\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1038 - accuracy: 0.5467 - val_loss: 0.9994 - val_accuracy: 0.5979\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0444 - accuracy: 0.5589 - val_loss: 1.0669 - val_accuracy: 0.5606\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0314 - accuracy: 0.5713 - val_loss: 1.7573 - val_accuracy: 0.4825\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 1.0078 - accuracy: 0.5743 - val_loss: 0.9910 - val_accuracy: 0.5711\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.9744 - accuracy: 0.5932 - val_loss: 0.8343 - val_accuracy: 0.6503\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9508 - accuracy: 0.6091 - val_loss: 0.9840 - val_accuracy: 0.6002\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9025 - accuracy: 0.6196 - val_loss: 0.9802 - val_accuracy: 0.6270\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.8823 - accuracy: 0.6314 - val_loss: 0.8499 - val_accuracy: 0.6737\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.8649 - accuracy: 0.6379 - val_loss: 0.8105 - val_accuracy: 0.6772\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.8576 - accuracy: 0.6399 - val_loss: 0.8612 - val_accuracy: 0.6643\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.8224 - accuracy: 0.6586 - val_loss: 0.8271 - val_accuracy: 0.6678\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.7992 - accuracy: 0.6644 - val_loss: 0.7841 - val_accuracy: 0.6760\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.7580 - accuracy: 0.6867 - val_loss: 0.8024 - val_accuracy: 0.6981\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7611 - accuracy: 0.6800 - val_loss: 0.6840 - val_accuracy: 0.7075\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.7599 - accuracy: 0.6823 - val_loss: 0.8021 - val_accuracy: 0.7075\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7189 - accuracy: 0.6981 - val_loss: 0.6769 - val_accuracy: 0.7156\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6930 - accuracy: 0.7033 - val_loss: 0.7420 - val_accuracy: 0.7121\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7084 - accuracy: 0.7158 - val_loss: 0.7669 - val_accuracy: 0.7191\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6701 - accuracy: 0.7160 - val_loss: 0.5147 - val_accuracy: 0.7879\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.6517 - accuracy: 0.7214 - val_loss: 0.6554 - val_accuracy: 0.7459\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.6327 - accuracy: 0.7318 - val_loss: 0.7558 - val_accuracy: 0.7261\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.6444 - accuracy: 0.7319 - val_loss: 0.5553 - val_accuracy: 0.7797\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.6275 - accuracy: 0.7393 - val_loss: 1.5311 - val_accuracy: 0.6235\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5982 - accuracy: 0.7474 - val_loss: 0.5417 - val_accuracy: 0.7902\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5901 - accuracy: 0.7502 - val_loss: 0.5847 - val_accuracy: 0.7541\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.5664 - accuracy: 0.7621 - val_loss: 0.5444 - val_accuracy: 0.7774\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5547 - accuracy: 0.7657 - val_loss: 0.4184 - val_accuracy: 0.8403\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5487 - accuracy: 0.7657 - val_loss: 0.5981 - val_accuracy: 0.7646\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5272 - accuracy: 0.7781 - val_loss: 0.8491 - val_accuracy: 0.7261\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5244 - accuracy: 0.7829 - val_loss: 0.5232 - val_accuracy: 0.7972\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5333 - accuracy: 0.7779 - val_loss: 0.6705 - val_accuracy: 0.7716\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.5066 - accuracy: 0.7825 - val_loss: 0.4580 - val_accuracy: 0.8182\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4958 - accuracy: 0.7898 - val_loss: 0.6086 - val_accuracy: 0.7564\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4993 - accuracy: 0.7959 - val_loss: 0.5660 - val_accuracy: 0.7879\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4954 - accuracy: 0.7947 - val_loss: 0.6369 - val_accuracy: 0.7786\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4912 - accuracy: 0.8002 - val_loss: 0.4829 - val_accuracy: 0.8287\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.4726 - accuracy: 0.8073 - val_loss: 0.4801 - val_accuracy: 0.8240\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4837 - accuracy: 0.8044 - val_loss: 0.5703 - val_accuracy: 0.7914\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4355 - accuracy: 0.8158 - val_loss: 0.5172 - val_accuracy: 0.8124\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4314 - accuracy: 0.8171 - val_loss: 0.4656 - val_accuracy: 0.8217\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4357 - accuracy: 0.8193 - val_loss: 0.3793 - val_accuracy: 0.8660\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4326 - accuracy: 0.8210 - val_loss: 1.1021 - val_accuracy: 0.7168\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4335 - accuracy: 0.8252 - val_loss: 0.5204 - val_accuracy: 0.8240\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4286 - accuracy: 0.8283 - val_loss: 0.3807 - val_accuracy: 0.8508\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4070 - accuracy: 0.8289 - val_loss: 0.4200 - val_accuracy: 0.8508\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3951 - accuracy: 0.8463 - val_loss: 0.5308 - val_accuracy: 0.8205\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.4010 - accuracy: 0.8375 - val_loss: 0.4073 - val_accuracy: 0.8613\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.3999 - accuracy: 0.8389 - val_loss: 0.5243 - val_accuracy: 0.8298\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3977 - accuracy: 0.8381 - val_loss: 0.5142 - val_accuracy: 0.8310\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3938 - accuracy: 0.8451 - val_loss: 0.5726 - val_accuracy: 0.7984\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3742 - accuracy: 0.8491 - val_loss: 0.4349 - val_accuracy: 0.8531\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3739 - accuracy: 0.8486 - val_loss: 0.3824 - val_accuracy: 0.8625\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3637 - accuracy: 0.8508 - val_loss: 0.8203 - val_accuracy: 0.7855\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3791 - accuracy: 0.8450 - val_loss: 0.5116 - val_accuracy: 0.8263\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3601 - accuracy: 0.8560 - val_loss: 0.3551 - val_accuracy: 0.8695\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3600 - accuracy: 0.8600 - val_loss: 0.4681 - val_accuracy: 0.8462\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3363 - accuracy: 0.8618 - val_loss: 0.5817 - val_accuracy: 0.8042\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3560 - accuracy: 0.8558 - val_loss: 2.1761 - val_accuracy: 0.6632\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3518 - accuracy: 0.8617 - val_loss: 0.8117 - val_accuracy: 0.7832\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3579 - accuracy: 0.8579 - val_loss: 4.5880 - val_accuracy: 0.6946\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3335 - accuracy: 0.8694 - val_loss: 0.6659 - val_accuracy: 0.8089\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3362 - accuracy: 0.8687 - val_loss: 0.4830 - val_accuracy: 0.8462\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.3361 - accuracy: 0.8663 - val_loss: 0.4735 - val_accuracy: 0.8566\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.3106 - accuracy: 0.8779 - val_loss: 0.4844 - val_accuracy: 0.8625\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.3279 - accuracy: 0.8696 - val_loss: 0.4207 - val_accuracy: 0.8671\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3069 - accuracy: 0.8772 - val_loss: 0.4157 - val_accuracy: 0.8555\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3276 - accuracy: 0.8749 - val_loss: 0.5180 - val_accuracy: 0.8601\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3013 - accuracy: 0.8801 - val_loss: 0.3996 - val_accuracy: 0.8846\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.2871 - accuracy: 0.8878 - val_loss: 0.3524 - val_accuracy: 0.8869\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3014 - accuracy: 0.8784 - val_loss: 0.5067 - val_accuracy: 0.8531\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2942 - accuracy: 0.8851 - val_loss: 0.4807 - val_accuracy: 0.8508\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3039 - accuracy: 0.8811 - val_loss: 0.6201 - val_accuracy: 0.8182\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3215 - accuracy: 0.8754 - val_loss: 0.3475 - val_accuracy: 0.8846\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2926 - accuracy: 0.8823 - val_loss: 0.6120 - val_accuracy: 0.8228\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3023 - accuracy: 0.8884 - val_loss: 0.3868 - val_accuracy: 0.8741\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2756 - accuracy: 0.8960 - val_loss: 0.3844 - val_accuracy: 0.8916\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2699 - accuracy: 0.8966 - val_loss: 0.4068 - val_accuracy: 0.8520\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2829 - accuracy: 0.8902 - val_loss: 0.8309 - val_accuracy: 0.7855\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2749 - accuracy: 0.8942 - val_loss: 0.9512 - val_accuracy: 0.7809\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2737 - accuracy: 0.8950 - val_loss: 0.6547 - val_accuracy: 0.8147\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2591 - accuracy: 0.9004 - val_loss: 0.6455 - val_accuracy: 0.8217\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2717 - accuracy: 0.8960 - val_loss: 0.4801 - val_accuracy: 0.8706\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2767 - accuracy: 0.8947 - val_loss: 0.6024 - val_accuracy: 0.8403\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2664 - accuracy: 0.8988 - val_loss: 0.6059 - val_accuracy: 0.8263\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2618 - accuracy: 0.8963 - val_loss: 0.4347 - val_accuracy: 0.8858\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2671 - accuracy: 0.8992 - val_loss: 0.4325 - val_accuracy: 0.8928\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2530 - accuracy: 0.9033 - val_loss: 1.6753 - val_accuracy: 0.7331\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2565 - accuracy: 0.9027 - val_loss: 0.4468 - val_accuracy: 0.8683\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2613 - accuracy: 0.9003 - val_loss: 0.4962 - val_accuracy: 0.8636\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.2618 - accuracy: 0.9014 - val_loss: 0.4641 - val_accuracy: 0.8636\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2566 - accuracy: 0.9044 - val_loss: 0.3957 - val_accuracy: 0.8963\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2335 - accuracy: 0.9089 - val_loss: 0.4736 - val_accuracy: 0.8683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefoqD45JFoJ",
        "outputId": "7ad63b2a-42fd-4537-93c0-e7438d5c1e40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.7754\n",
            "평균 손실: 0.5500\n",
            "평균 검증 정확도: 0.7621\n",
            "평균 검증 손실: 0.8203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+RMSprop"
      ],
      "metadata": {
        "id": "2SkPIxqdL99g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model5 = Sequential()\n",
        "\n",
        "    model5.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model5.add(Dropout(0.25))\n",
        "\n",
        "    model5.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model5.add(Dropout(0.25))\n",
        "\n",
        "    model5.add(Flatten())\n",
        "    model5.add(Dense(256, activation='relu'))\n",
        "    model5.add(Dropout(0.5))\n",
        "    model5.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model5.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model5'\n",
        "    model_path = model_dir + \"/cloud_classify.model5\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "_B6LYmkfMCnv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DllLhFeKMWp9",
        "outputId": "5899c22f-3ce1-40e2-9648-57d689dddb42"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model5.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drPWYEMkMYLp",
        "outputId": "cd838e7f-d65d-46bf-aff5-6646bd7cd58d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 4s 8ms/step - loss: 1.3954 - accuracy: 0.4378 - val_loss: 1.2579 - val_accuracy: 0.5163\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.1742 - accuracy: 0.5293 - val_loss: 1.1433 - val_accuracy: 0.5198\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0750 - accuracy: 0.5754 - val_loss: 1.1352 - val_accuracy: 0.5186\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9779 - accuracy: 0.6122 - val_loss: 1.1695 - val_accuracy: 0.4779\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8771 - accuracy: 0.6481 - val_loss: 0.8492 - val_accuracy: 0.6562\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7830 - accuracy: 0.6969 - val_loss: 0.7898 - val_accuracy: 0.6841\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6801 - accuracy: 0.7389 - val_loss: 0.8087 - val_accuracy: 0.6807\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6162 - accuracy: 0.7688 - val_loss: 0.6039 - val_accuracy: 0.7657\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5389 - accuracy: 0.7958 - val_loss: 0.5574 - val_accuracy: 0.7937\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4853 - accuracy: 0.8180 - val_loss: 0.5670 - val_accuracy: 0.7739\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4315 - accuracy: 0.8424 - val_loss: 0.6531 - val_accuracy: 0.7646\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3864 - accuracy: 0.8575 - val_loss: 0.5374 - val_accuracy: 0.8065\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3586 - accuracy: 0.8691 - val_loss: 0.4968 - val_accuracy: 0.8193\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3338 - accuracy: 0.8807 - val_loss: 0.3761 - val_accuracy: 0.8625\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3097 - accuracy: 0.8897 - val_loss: 0.3642 - val_accuracy: 0.8718\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2929 - accuracy: 0.8994 - val_loss: 0.4397 - val_accuracy: 0.8275\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2652 - accuracy: 0.9045 - val_loss: 0.3935 - val_accuracy: 0.8660\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2526 - accuracy: 0.9134 - val_loss: 0.3314 - val_accuracy: 0.8741\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2555 - accuracy: 0.9145 - val_loss: 0.3239 - val_accuracy: 0.8788\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2300 - accuracy: 0.9191 - val_loss: 0.3014 - val_accuracy: 0.8951\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.2199 - accuracy: 0.9237 - val_loss: 0.3805 - val_accuracy: 0.8590\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.2193 - accuracy: 0.9254 - val_loss: 0.3533 - val_accuracy: 0.8800\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1986 - accuracy: 0.9289 - val_loss: 0.3464 - val_accuracy: 0.8730\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1991 - accuracy: 0.9350 - val_loss: 0.4384 - val_accuracy: 0.8706\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1940 - accuracy: 0.9308 - val_loss: 0.3297 - val_accuracy: 0.9021\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1839 - accuracy: 0.9376 - val_loss: 0.2979 - val_accuracy: 0.9091\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1677 - accuracy: 0.9424 - val_loss: 0.2930 - val_accuracy: 0.9103\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1792 - accuracy: 0.9360 - val_loss: 0.4797 - val_accuracy: 0.8240\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1806 - accuracy: 0.9395 - val_loss: 0.3069 - val_accuracy: 0.9138\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1685 - accuracy: 0.9415 - val_loss: 0.2928 - val_accuracy: 0.9021\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1637 - accuracy: 0.9434 - val_loss: 0.3701 - val_accuracy: 0.8928\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1625 - accuracy: 0.9447 - val_loss: 0.3200 - val_accuracy: 0.9103\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1564 - accuracy: 0.9499 - val_loss: 0.8035 - val_accuracy: 0.8252\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1512 - accuracy: 0.9497 - val_loss: 0.3189 - val_accuracy: 0.8963\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1477 - accuracy: 0.9509 - val_loss: 0.3498 - val_accuracy: 0.8811\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1352 - accuracy: 0.9539 - val_loss: 0.4122 - val_accuracy: 0.8893\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1440 - accuracy: 0.9530 - val_loss: 0.3491 - val_accuracy: 0.8928\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1516 - accuracy: 0.9490 - val_loss: 0.3738 - val_accuracy: 0.8893\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1561 - accuracy: 0.9503 - val_loss: 0.2806 - val_accuracy: 0.9207\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1320 - accuracy: 0.9553 - val_loss: 0.3340 - val_accuracy: 0.9161\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1411 - accuracy: 0.9558 - val_loss: 0.3043 - val_accuracy: 0.9161\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1314 - accuracy: 0.9560 - val_loss: 0.3538 - val_accuracy: 0.8998\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1413 - accuracy: 0.9556 - val_loss: 0.4416 - val_accuracy: 0.8881\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1344 - accuracy: 0.9595 - val_loss: 0.3683 - val_accuracy: 0.9079\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1229 - accuracy: 0.9615 - val_loss: 0.4008 - val_accuracy: 0.8986\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1274 - accuracy: 0.9584 - val_loss: 0.3234 - val_accuracy: 0.9091\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1312 - accuracy: 0.9605 - val_loss: 0.3292 - val_accuracy: 0.9184\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1423 - accuracy: 0.9552 - val_loss: 0.3079 - val_accuracy: 0.9079\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1261 - accuracy: 0.9578 - val_loss: 0.3496 - val_accuracy: 0.9266\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1343 - accuracy: 0.9601 - val_loss: 0.3946 - val_accuracy: 0.9056\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1332 - accuracy: 0.9593 - val_loss: 0.3610 - val_accuracy: 0.9044\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1208 - accuracy: 0.9630 - val_loss: 0.3579 - val_accuracy: 0.9196\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1264 - accuracy: 0.9611 - val_loss: 0.3933 - val_accuracy: 0.9138\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1114 - accuracy: 0.9641 - val_loss: 0.3367 - val_accuracy: 0.9231\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1167 - accuracy: 0.9663 - val_loss: 0.5016 - val_accuracy: 0.8811\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1161 - accuracy: 0.9661 - val_loss: 0.5116 - val_accuracy: 0.9021\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1124 - accuracy: 0.9698 - val_loss: 0.3311 - val_accuracy: 0.9266\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1187 - accuracy: 0.9645 - val_loss: 0.3762 - val_accuracy: 0.9044\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1064 - accuracy: 0.9672 - val_loss: 0.3823 - val_accuracy: 0.9184\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1098 - accuracy: 0.9665 - val_loss: 0.4040 - val_accuracy: 0.9079\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1083 - accuracy: 0.9680 - val_loss: 0.3705 - val_accuracy: 0.9242\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1159 - accuracy: 0.9666 - val_loss: 0.3676 - val_accuracy: 0.9114\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1168 - accuracy: 0.9662 - val_loss: 0.3478 - val_accuracy: 0.9242\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1138 - accuracy: 0.9657 - val_loss: 0.4164 - val_accuracy: 0.9021\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1084 - accuracy: 0.9694 - val_loss: 0.4103 - val_accuracy: 0.9138\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1159 - accuracy: 0.9676 - val_loss: 0.4726 - val_accuracy: 0.9126\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0951 - accuracy: 0.9706 - val_loss: 0.4464 - val_accuracy: 0.9126\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1263 - accuracy: 0.9654 - val_loss: 0.5971 - val_accuracy: 0.8846\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1177 - accuracy: 0.9685 - val_loss: 0.5467 - val_accuracy: 0.8800\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1170 - accuracy: 0.9678 - val_loss: 0.5543 - val_accuracy: 0.8951\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1171 - accuracy: 0.9684 - val_loss: 0.4158 - val_accuracy: 0.9114\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1023 - accuracy: 0.9718 - val_loss: 0.4539 - val_accuracy: 0.9079\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1116 - accuracy: 0.9684 - val_loss: 0.6665 - val_accuracy: 0.8776\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1182 - accuracy: 0.9679 - val_loss: 0.4899 - val_accuracy: 0.9009\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1112 - accuracy: 0.9689 - val_loss: 0.4831 - val_accuracy: 0.9207\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1142 - accuracy: 0.9658 - val_loss: 0.4078 - val_accuracy: 0.9138\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1054 - accuracy: 0.9729 - val_loss: 0.4627 - val_accuracy: 0.9114\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1231 - accuracy: 0.9684 - val_loss: 0.3658 - val_accuracy: 0.9336\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0966 - accuracy: 0.9712 - val_loss: 0.4583 - val_accuracy: 0.9231\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1061 - accuracy: 0.9700 - val_loss: 0.4499 - val_accuracy: 0.9021\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1095 - accuracy: 0.9716 - val_loss: 0.5707 - val_accuracy: 0.8881\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0993 - accuracy: 0.9707 - val_loss: 0.4045 - val_accuracy: 0.9196\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0898 - accuracy: 0.9724 - val_loss: 0.5319 - val_accuracy: 0.9219\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0895 - accuracy: 0.9734 - val_loss: 0.4735 - val_accuracy: 0.9138\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1166 - accuracy: 0.9718 - val_loss: 0.4562 - val_accuracy: 0.9219\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0982 - accuracy: 0.9707 - val_loss: 0.4835 - val_accuracy: 0.9114\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1035 - accuracy: 0.9725 - val_loss: 0.5145 - val_accuracy: 0.9266\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1087 - accuracy: 0.9719 - val_loss: 0.4548 - val_accuracy: 0.9184\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0966 - accuracy: 0.9737 - val_loss: 0.4462 - val_accuracy: 0.9114\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1191 - accuracy: 0.9680 - val_loss: 0.4370 - val_accuracy: 0.9184\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1038 - accuracy: 0.9736 - val_loss: 0.7641 - val_accuracy: 0.8706\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1045 - accuracy: 0.9733 - val_loss: 0.5415 - val_accuracy: 0.9091\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1071 - accuracy: 0.9718 - val_loss: 0.4623 - val_accuracy: 0.9161\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1092 - accuracy: 0.9698 - val_loss: 0.6394 - val_accuracy: 0.9091\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1200 - accuracy: 0.9689 - val_loss: 0.6503 - val_accuracy: 0.9056\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0990 - accuracy: 0.9747 - val_loss: 0.4542 - val_accuracy: 0.9172\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0960 - accuracy: 0.9741 - val_loss: 0.4326 - val_accuracy: 0.9149\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1079 - accuracy: 0.9720 - val_loss: 0.5021 - val_accuracy: 0.9149\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0934 - accuracy: 0.9760 - val_loss: 0.5508 - val_accuracy: 0.9231\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0963 - accuracy: 0.9764 - val_loss: 0.5623 - val_accuracy: 0.9254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvo6z1N4MaTd",
        "outputId": "4d96b5e8-c91c-4a0a-e908-6c0389d41b49"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9240\n",
            "평균 손실: 0.2194\n",
            "평균 검증 정확도: 0.8721\n",
            "평균 검증 손실: 0.4758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+RMSprop"
      ],
      "metadata": {
        "id": "uvWR2W9PMnA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model6 = Sequential()\n",
        "\n",
        "    model6.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model6.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Flatten())\n",
        "    model6.add(Dense(256, activation = 'relu'))\n",
        "    model6.add(Dropout(0.5))\n",
        "    model6.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model6.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model6'\n",
        "    model_path = model_dir + \"/cloud_classify.model6\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)"
      ],
      "metadata": {
        "id": "LgEVBFJhMqkr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-SLSa8mM89l",
        "outputId": "89437bfe-6279-413e-e465-0803ab652c27"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model6.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ8I-o5TM-ep",
        "outputId": "09ed7adb-78cd-4ee0-833a-7a4b77acf39f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 5s 11ms/step - loss: 1.4192 - accuracy: 0.4160 - val_loss: 1.2512 - val_accuracy: 0.4837\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1835 - accuracy: 0.5255 - val_loss: 1.2166 - val_accuracy: 0.4918\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0633 - accuracy: 0.5836 - val_loss: 2.0094 - val_accuracy: 0.2972\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9575 - accuracy: 0.6267 - val_loss: 0.8657 - val_accuracy: 0.6364\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.8352 - accuracy: 0.6731 - val_loss: 0.8938 - val_accuracy: 0.6492\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7173 - accuracy: 0.7283 - val_loss: 0.8021 - val_accuracy: 0.6760\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6227 - accuracy: 0.7651 - val_loss: 0.7628 - val_accuracy: 0.7145\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5362 - accuracy: 0.8018 - val_loss: 0.7193 - val_accuracy: 0.7401\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4720 - accuracy: 0.8281 - val_loss: 0.4509 - val_accuracy: 0.8310\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4201 - accuracy: 0.8479 - val_loss: 0.4992 - val_accuracy: 0.8007\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3753 - accuracy: 0.8614 - val_loss: 0.3363 - val_accuracy: 0.8741\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3666 - accuracy: 0.8706 - val_loss: 0.4085 - val_accuracy: 0.8392\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3361 - accuracy: 0.8808 - val_loss: 0.3366 - val_accuracy: 0.8765\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3184 - accuracy: 0.8894 - val_loss: 0.3923 - val_accuracy: 0.8566\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3114 - accuracy: 0.8935 - val_loss: 0.3155 - val_accuracy: 0.8951\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3082 - accuracy: 0.8976 - val_loss: 0.4062 - val_accuracy: 0.8695\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2897 - accuracy: 0.9030 - val_loss: 1.1038 - val_accuracy: 0.7949\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3012 - accuracy: 0.9003 - val_loss: 0.6699 - val_accuracy: 0.8054\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2750 - accuracy: 0.9048 - val_loss: 0.4941 - val_accuracy: 0.8788\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2659 - accuracy: 0.9102 - val_loss: 0.3086 - val_accuracy: 0.8893\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2817 - accuracy: 0.9136 - val_loss: 0.3674 - val_accuracy: 0.9161\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.2614 - accuracy: 0.9189 - val_loss: 0.6377 - val_accuracy: 0.8450\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.2737 - accuracy: 0.9150 - val_loss: 0.3615 - val_accuracy: 0.8974\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2955 - accuracy: 0.9091 - val_loss: 0.8663 - val_accuracy: 0.7622\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3003 - accuracy: 0.9114 - val_loss: 0.3797 - val_accuracy: 0.8928\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2783 - accuracy: 0.9174 - val_loss: 0.5516 - val_accuracy: 0.8636\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2820 - accuracy: 0.9169 - val_loss: 0.3439 - val_accuracy: 0.8963\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.2767 - accuracy: 0.9181 - val_loss: 0.3047 - val_accuracy: 0.9149\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3048 - accuracy: 0.9108 - val_loss: 0.6066 - val_accuracy: 0.8520\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2959 - accuracy: 0.9139 - val_loss: 0.3845 - val_accuracy: 0.8986\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3307 - accuracy: 0.9118 - val_loss: 0.4332 - val_accuracy: 0.8963\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2975 - accuracy: 0.9135 - val_loss: 0.3034 - val_accuracy: 0.9219\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3213 - accuracy: 0.9137 - val_loss: 0.2784 - val_accuracy: 0.9091\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3191 - accuracy: 0.9139 - val_loss: 0.2880 - val_accuracy: 0.9056\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3205 - accuracy: 0.9121 - val_loss: 0.4869 - val_accuracy: 0.8834\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3180 - accuracy: 0.9181 - val_loss: 0.6929 - val_accuracy: 0.8578\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3535 - accuracy: 0.9064 - val_loss: 0.3458 - val_accuracy: 0.9254\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3643 - accuracy: 0.9047 - val_loss: 0.3203 - val_accuracy: 0.8904\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3223 - accuracy: 0.9188 - val_loss: 0.3468 - val_accuracy: 0.9079\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3352 - accuracy: 0.9074 - val_loss: 0.3652 - val_accuracy: 0.9207\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3258 - accuracy: 0.9127 - val_loss: 0.5974 - val_accuracy: 0.8625\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3339 - accuracy: 0.9121 - val_loss: 0.4843 - val_accuracy: 0.8601\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3786 - accuracy: 0.9020 - val_loss: 0.3615 - val_accuracy: 0.9161\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3973 - accuracy: 0.9027 - val_loss: 0.2520 - val_accuracy: 0.9231\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3620 - accuracy: 0.9070 - val_loss: 0.4324 - val_accuracy: 0.8858\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3948 - accuracy: 0.9093 - val_loss: 0.3903 - val_accuracy: 0.9091\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4021 - accuracy: 0.9005 - val_loss: 0.3603 - val_accuracy: 0.9184\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3760 - accuracy: 0.9057 - val_loss: 0.3712 - val_accuracy: 0.9242\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3687 - accuracy: 0.9066 - val_loss: 0.3161 - val_accuracy: 0.9126\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4355 - accuracy: 0.8955 - val_loss: 0.3823 - val_accuracy: 0.9056\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4257 - accuracy: 0.8922 - val_loss: 0.4392 - val_accuracy: 0.9103\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4553 - accuracy: 0.8957 - val_loss: 0.3416 - val_accuracy: 0.9114\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3935 - accuracy: 0.8985 - val_loss: 0.3516 - val_accuracy: 0.9266\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4042 - accuracy: 0.9000 - val_loss: 0.4390 - val_accuracy: 0.9184\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4180 - accuracy: 0.9007 - val_loss: 0.4245 - val_accuracy: 0.9161\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4346 - accuracy: 0.8930 - val_loss: 0.4568 - val_accuracy: 0.8730\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3993 - accuracy: 0.9061 - val_loss: 0.5835 - val_accuracy: 0.9103\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4397 - accuracy: 0.9012 - val_loss: 0.5902 - val_accuracy: 0.7984\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4573 - accuracy: 0.8899 - val_loss: 0.4294 - val_accuracy: 0.8974\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4886 - accuracy: 0.8811 - val_loss: 0.4638 - val_accuracy: 0.8963\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4291 - accuracy: 0.8917 - val_loss: 0.3905 - val_accuracy: 0.9091\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4289 - accuracy: 0.8983 - val_loss: 0.5050 - val_accuracy: 0.8869\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4695 - accuracy: 0.8915 - val_loss: 0.2736 - val_accuracy: 0.9266\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4535 - accuracy: 0.8938 - val_loss: 1.0245 - val_accuracy: 0.8485\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4699 - accuracy: 0.8897 - val_loss: 0.6146 - val_accuracy: 0.8846\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5220 - accuracy: 0.8792 - val_loss: 0.7150 - val_accuracy: 0.8800\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4642 - accuracy: 0.8954 - val_loss: 0.3564 - val_accuracy: 0.9184\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5160 - accuracy: 0.8890 - val_loss: 0.4378 - val_accuracy: 0.8939\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4613 - accuracy: 0.8978 - val_loss: 0.3863 - val_accuracy: 0.9161\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4880 - accuracy: 0.8786 - val_loss: 1.2196 - val_accuracy: 0.8030\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5319 - accuracy: 0.8759 - val_loss: 0.3162 - val_accuracy: 0.9103\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5118 - accuracy: 0.8792 - val_loss: 0.3349 - val_accuracy: 0.9033\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5590 - accuracy: 0.8748 - val_loss: 0.6528 - val_accuracy: 0.8788\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5410 - accuracy: 0.8803 - val_loss: 0.4222 - val_accuracy: 0.8881\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5124 - accuracy: 0.8772 - val_loss: 0.6710 - val_accuracy: 0.8531\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5097 - accuracy: 0.8723 - val_loss: 2.0459 - val_accuracy: 0.8100\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5237 - accuracy: 0.8858 - val_loss: 0.6288 - val_accuracy: 0.8963\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5406 - accuracy: 0.8758 - val_loss: 0.4219 - val_accuracy: 0.9079\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5510 - accuracy: 0.8764 - val_loss: 0.4350 - val_accuracy: 0.8881\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5278 - accuracy: 0.8865 - val_loss: 0.5781 - val_accuracy: 0.8718\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5567 - accuracy: 0.8715 - val_loss: 0.4713 - val_accuracy: 0.8683\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5914 - accuracy: 0.8684 - val_loss: 0.3310 - val_accuracy: 0.9114\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5713 - accuracy: 0.8704 - val_loss: 1.4347 - val_accuracy: 0.8578\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7030 - accuracy: 0.8544 - val_loss: 0.4834 - val_accuracy: 0.8869\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6641 - accuracy: 0.8569 - val_loss: 0.6881 - val_accuracy: 0.8765\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6470 - accuracy: 0.8540 - val_loss: 0.5306 - val_accuracy: 0.8636\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6060 - accuracy: 0.8745 - val_loss: 0.5810 - val_accuracy: 0.8613\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6947 - accuracy: 0.8609 - val_loss: 0.3958 - val_accuracy: 0.8671\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7474 - accuracy: 0.8543 - val_loss: 0.4036 - val_accuracy: 0.8788\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6878 - accuracy: 0.8481 - val_loss: 0.5811 - val_accuracy: 0.8415\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6505 - accuracy: 0.8474 - val_loss: 0.5701 - val_accuracy: 0.8566\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6170 - accuracy: 0.8546 - val_loss: 0.5234 - val_accuracy: 0.8497\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6914 - accuracy: 0.8454 - val_loss: 0.6308 - val_accuracy: 0.8147\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6951 - accuracy: 0.8443 - val_loss: 0.4342 - val_accuracy: 0.9184\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7580 - accuracy: 0.8318 - val_loss: 0.4270 - val_accuracy: 0.8881\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6662 - accuracy: 0.8459 - val_loss: 0.7602 - val_accuracy: 0.8776\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7076 - accuracy: 0.8560 - val_loss: 0.6532 - val_accuracy: 0.7786\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6813 - accuracy: 0.8432 - val_loss: 1.0734 - val_accuracy: 0.8531\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6783 - accuracy: 0.8494 - val_loss: 0.4351 - val_accuracy: 0.8963\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6751 - accuracy: 0.8385 - val_loss: 0.5364 - val_accuracy: 0.8240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd84IkTJNANx",
        "outputId": "c2be714c-eef4-4d6e-ff19-a9170afda42b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8674\n",
            "평균 손실: 0.4890\n",
            "평균 검증 정확도: 0.8558\n",
            "평균 검증 손실: 0.5575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+Adamax"
      ],
      "metadata": {
        "id": "f1g5PFO8Oxto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adamax\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model7 = Sequential()\n",
        "\n",
        "    model7.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model7.add(Dropout(0.25))\n",
        "\n",
        "    model7.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model7.add(Dropout(0.25))\n",
        "\n",
        "    model7.add(Flatten())\n",
        "    model7.add(Dense(256, activation='relu'))\n",
        "    model7.add(Dropout(0.5))\n",
        "    model7.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model7.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model7'\n",
        "    model_path = model_dir + \"/cloud_classify.model7\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "sX7CaxCNOxMo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1gNFAD4PdrU",
        "outputId": "b2c4e870-4343-4458-d30f-72f307ce310b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model7.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly0mPjEcPgAW",
        "outputId": "66559f5a-c97a-40b8-e9c4-d0913c6758bc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 4s 8ms/step - loss: 1.3960 - accuracy: 0.4192 - val_loss: 1.3457 - val_accuracy: 0.4371\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.2454 - accuracy: 0.4932 - val_loss: 1.2259 - val_accuracy: 0.4977\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.1715 - accuracy: 0.5238 - val_loss: 1.1486 - val_accuracy: 0.5396\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.1044 - accuracy: 0.5516 - val_loss: 1.1054 - val_accuracy: 0.5501\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0512 - accuracy: 0.5764 - val_loss: 1.0531 - val_accuracy: 0.5758\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9888 - accuracy: 0.6054 - val_loss: 0.9912 - val_accuracy: 0.5967\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9388 - accuracy: 0.6287 - val_loss: 0.9452 - val_accuracy: 0.6049\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8919 - accuracy: 0.6476 - val_loss: 0.9242 - val_accuracy: 0.6166\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8545 - accuracy: 0.6589 - val_loss: 0.8930 - val_accuracy: 0.6154\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8052 - accuracy: 0.6810 - val_loss: 0.7860 - val_accuracy: 0.6923\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7607 - accuracy: 0.6978 - val_loss: 0.7693 - val_accuracy: 0.6981\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7234 - accuracy: 0.7079 - val_loss: 0.7288 - val_accuracy: 0.7110\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6635 - accuracy: 0.7397 - val_loss: 0.6664 - val_accuracy: 0.7378\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6332 - accuracy: 0.7544 - val_loss: 0.6272 - val_accuracy: 0.7284\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5795 - accuracy: 0.7743 - val_loss: 0.5847 - val_accuracy: 0.7564\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5627 - accuracy: 0.7845 - val_loss: 0.5341 - val_accuracy: 0.8112\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5267 - accuracy: 0.7989 - val_loss: 0.5441 - val_accuracy: 0.7902\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5005 - accuracy: 0.8062 - val_loss: 0.5009 - val_accuracy: 0.8054\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4669 - accuracy: 0.8253 - val_loss: 0.5171 - val_accuracy: 0.7972\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4509 - accuracy: 0.8262 - val_loss: 0.4436 - val_accuracy: 0.8403\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4302 - accuracy: 0.8365 - val_loss: 0.4362 - val_accuracy: 0.8392\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4049 - accuracy: 0.8426 - val_loss: 0.4270 - val_accuracy: 0.8380\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8552 - val_loss: 0.4046 - val_accuracy: 0.8555\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3631 - accuracy: 0.8618 - val_loss: 0.3942 - val_accuracy: 0.8543\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3554 - accuracy: 0.8688 - val_loss: 0.3640 - val_accuracy: 0.8625\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3332 - accuracy: 0.8754 - val_loss: 0.3560 - val_accuracy: 0.8660\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3313 - accuracy: 0.8718 - val_loss: 0.3457 - val_accuracy: 0.8800\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3175 - accuracy: 0.8816 - val_loss: 0.3337 - val_accuracy: 0.8800\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2936 - accuracy: 0.8903 - val_loss: 0.2996 - val_accuracy: 0.9009\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2821 - accuracy: 0.8938 - val_loss: 0.2952 - val_accuracy: 0.8939\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2740 - accuracy: 0.8990 - val_loss: 0.2967 - val_accuracy: 0.8974\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.2677 - accuracy: 0.8959 - val_loss: 0.2997 - val_accuracy: 0.8916\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.2513 - accuracy: 0.9030 - val_loss: 0.2865 - val_accuracy: 0.8904\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2549 - accuracy: 0.9052 - val_loss: 0.2784 - val_accuracy: 0.8974\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2410 - accuracy: 0.9084 - val_loss: 0.2851 - val_accuracy: 0.8893\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2271 - accuracy: 0.9140 - val_loss: 0.2805 - val_accuracy: 0.9033\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2268 - accuracy: 0.9149 - val_loss: 0.2973 - val_accuracy: 0.8834\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2208 - accuracy: 0.9207 - val_loss: 0.3004 - val_accuracy: 0.8846\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.2149 - accuracy: 0.9197 - val_loss: 0.2378 - val_accuracy: 0.9149\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.2021 - accuracy: 0.9275 - val_loss: 0.2398 - val_accuracy: 0.9138\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1988 - accuracy: 0.9244 - val_loss: 0.2513 - val_accuracy: 0.9068\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1887 - accuracy: 0.9308 - val_loss: 0.2629 - val_accuracy: 0.9044\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1921 - accuracy: 0.9248 - val_loss: 0.2716 - val_accuracy: 0.8974\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1833 - accuracy: 0.9324 - val_loss: 0.2385 - val_accuracy: 0.9114\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1719 - accuracy: 0.9355 - val_loss: 0.2350 - val_accuracy: 0.9126\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1808 - accuracy: 0.9328 - val_loss: 0.2256 - val_accuracy: 0.9219\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1746 - accuracy: 0.9356 - val_loss: 0.1904 - val_accuracy: 0.9254\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1657 - accuracy: 0.9390 - val_loss: 0.2164 - val_accuracy: 0.9184\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1724 - accuracy: 0.9350 - val_loss: 0.2302 - val_accuracy: 0.9172\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1617 - accuracy: 0.9400 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1513 - accuracy: 0.9428 - val_loss: 0.2357 - val_accuracy: 0.9138\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1568 - accuracy: 0.9390 - val_loss: 0.2284 - val_accuracy: 0.9161\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1527 - accuracy: 0.9433 - val_loss: 0.2262 - val_accuracy: 0.9231\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1438 - accuracy: 0.9456 - val_loss: 0.2131 - val_accuracy: 0.9254\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1478 - accuracy: 0.9440 - val_loss: 0.2258 - val_accuracy: 0.9266\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1454 - accuracy: 0.9453 - val_loss: 0.2045 - val_accuracy: 0.9242\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1419 - accuracy: 0.9501 - val_loss: 0.2143 - val_accuracy: 0.9138\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1401 - accuracy: 0.9472 - val_loss: 0.2020 - val_accuracy: 0.9277\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1318 - accuracy: 0.9535 - val_loss: 0.2137 - val_accuracy: 0.9254\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1278 - accuracy: 0.9522 - val_loss: 0.2178 - val_accuracy: 0.9312\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1217 - accuracy: 0.9562 - val_loss: 0.2120 - val_accuracy: 0.9242\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1284 - accuracy: 0.9509 - val_loss: 0.2102 - val_accuracy: 0.9184\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1265 - accuracy: 0.9521 - val_loss: 0.2146 - val_accuracy: 0.9172\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1273 - accuracy: 0.9539 - val_loss: 0.2139 - val_accuracy: 0.9254\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1190 - accuracy: 0.9540 - val_loss: 0.2310 - val_accuracy: 0.9103\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1157 - accuracy: 0.9578 - val_loss: 0.2061 - val_accuracy: 0.9231\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1198 - accuracy: 0.9542 - val_loss: 0.2083 - val_accuracy: 0.9184\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1196 - accuracy: 0.9552 - val_loss: 0.1978 - val_accuracy: 0.9242\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1151 - accuracy: 0.9564 - val_loss: 0.2070 - val_accuracy: 0.9242\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1160 - accuracy: 0.9542 - val_loss: 0.2097 - val_accuracy: 0.9289\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 0.1989 - val_accuracy: 0.9266\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1056 - accuracy: 0.9593 - val_loss: 0.2072 - val_accuracy: 0.9301\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1092 - accuracy: 0.9586 - val_loss: 0.2238 - val_accuracy: 0.9207\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0973 - accuracy: 0.9630 - val_loss: 0.2178 - val_accuracy: 0.9324\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.1027 - accuracy: 0.9615 - val_loss: 0.2169 - val_accuracy: 0.9242\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1008 - accuracy: 0.9623 - val_loss: 0.2112 - val_accuracy: 0.9266\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1020 - accuracy: 0.9613 - val_loss: 0.2221 - val_accuracy: 0.9184\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0963 - accuracy: 0.9653 - val_loss: 0.1937 - val_accuracy: 0.9336\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0959 - accuracy: 0.9626 - val_loss: 0.2060 - val_accuracy: 0.9324\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1068 - accuracy: 0.9595 - val_loss: 0.2010 - val_accuracy: 0.9242\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0972 - accuracy: 0.9648 - val_loss: 0.2088 - val_accuracy: 0.9324\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0977 - accuracy: 0.9628 - val_loss: 0.2407 - val_accuracy: 0.9207\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0945 - accuracy: 0.9668 - val_loss: 0.2073 - val_accuracy: 0.9301\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.1002 - accuracy: 0.9610 - val_loss: 0.2164 - val_accuracy: 0.9336\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0940 - accuracy: 0.9644 - val_loss: 0.2223 - val_accuracy: 0.9242\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0926 - accuracy: 0.9630 - val_loss: 0.2344 - val_accuracy: 0.9196\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0987 - accuracy: 0.9632 - val_loss: 0.2221 - val_accuracy: 0.9266\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0911 - accuracy: 0.9661 - val_loss: 0.2167 - val_accuracy: 0.9277\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 0.2187 - val_accuracy: 0.9312\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0946 - accuracy: 0.9653 - val_loss: 0.2008 - val_accuracy: 0.9312\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0848 - accuracy: 0.9696 - val_loss: 0.2343 - val_accuracy: 0.9184\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0817 - accuracy: 0.9679 - val_loss: 0.2215 - val_accuracy: 0.9277\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0832 - accuracy: 0.9693 - val_loss: 0.2277 - val_accuracy: 0.9289\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0862 - accuracy: 0.9690 - val_loss: 0.2507 - val_accuracy: 0.9277\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0840 - accuracy: 0.9681 - val_loss: 0.2466 - val_accuracy: 0.9254\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0836 - accuracy: 0.9681 - val_loss: 0.2118 - val_accuracy: 0.9301\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0866 - accuracy: 0.9657 - val_loss: 0.2364 - val_accuracy: 0.9254\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0830 - accuracy: 0.9688 - val_loss: 0.2154 - val_accuracy: 0.9336\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0775 - accuracy: 0.9693 - val_loss: 0.2269 - val_accuracy: 0.9336\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.0794 - accuracy: 0.9692 - val_loss: 0.2297 - val_accuracy: 0.9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ1FqGXFPh7d",
        "outputId": "ecea48e7-f910-4442-e599-a94225fa8211"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8856\n",
            "평균 손실: 0.2943\n",
            "평균 검증 정확도: 0.8644\n",
            "평균 검증 손실: 0.3602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+Adamax"
      ],
      "metadata": {
        "id": "I_b-_ObHRFKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model8 = Sequential()\n",
        "\n",
        "    model8.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model8.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Flatten())\n",
        "    model8.add(Dense(256, activation = 'relu'))\n",
        "    model8.add(Dropout(0.5))\n",
        "    model8.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model8.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model8'\n",
        "    model_path = model_dir + \"/cloud_classify.model8\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)"
      ],
      "metadata": {
        "id": "0N46M17IRJlR"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzMl7wFGRYka",
        "outputId": "26e70b68-db27-4066-b4ab-bce7bc55ae7f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model8.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vnV0Pu-RVN-",
        "outputId": "4f9706d9-bb63-4521-ea92-582a2f0a2c1b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 4s 10ms/step - loss: 1.3734 - accuracy: 0.4194 - val_loss: 1.2918 - val_accuracy: 0.4779\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.2093 - accuracy: 0.5108 - val_loss: 1.1437 - val_accuracy: 0.5396\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.1049 - accuracy: 0.5580 - val_loss: 1.1995 - val_accuracy: 0.4930\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0172 - accuracy: 0.6025 - val_loss: 1.0087 - val_accuracy: 0.5851\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9312 - accuracy: 0.6311 - val_loss: 0.9800 - val_accuracy: 0.6014\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.8489 - accuracy: 0.6644 - val_loss: 0.9083 - val_accuracy: 0.6270\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7767 - accuracy: 0.6974 - val_loss: 0.8500 - val_accuracy: 0.6597\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6937 - accuracy: 0.7199 - val_loss: 0.7566 - val_accuracy: 0.6981\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.6052 - accuracy: 0.7688 - val_loss: 0.7183 - val_accuracy: 0.7156\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5429 - accuracy: 0.7879 - val_loss: 0.5978 - val_accuracy: 0.7494\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4798 - accuracy: 0.8157 - val_loss: 0.4818 - val_accuracy: 0.8228\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4231 - accuracy: 0.8363 - val_loss: 0.4407 - val_accuracy: 0.8298\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3959 - accuracy: 0.8456 - val_loss: 0.4078 - val_accuracy: 0.8473\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3547 - accuracy: 0.8643 - val_loss: 0.3571 - val_accuracy: 0.8695\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3151 - accuracy: 0.8779 - val_loss: 0.3452 - val_accuracy: 0.8928\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2944 - accuracy: 0.8898 - val_loss: 0.3153 - val_accuracy: 0.8800\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2706 - accuracy: 0.8978 - val_loss: 0.3321 - val_accuracy: 0.8776\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2496 - accuracy: 0.9058 - val_loss: 0.3328 - val_accuracy: 0.8718\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2336 - accuracy: 0.9096 - val_loss: 0.2749 - val_accuracy: 0.8986\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2276 - accuracy: 0.9117 - val_loss: 0.2203 - val_accuracy: 0.9266\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.2069 - accuracy: 0.9218 - val_loss: 0.2009 - val_accuracy: 0.9359\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1914 - accuracy: 0.9275 - val_loss: 0.2231 - val_accuracy: 0.9359\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1845 - accuracy: 0.9307 - val_loss: 0.1992 - val_accuracy: 0.9347\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1721 - accuracy: 0.9323 - val_loss: 0.1994 - val_accuracy: 0.9324\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1559 - accuracy: 0.9456 - val_loss: 0.1855 - val_accuracy: 0.9336\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1453 - accuracy: 0.9443 - val_loss: 0.1935 - val_accuracy: 0.9406\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1408 - accuracy: 0.9472 - val_loss: 0.1888 - val_accuracy: 0.9336\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1323 - accuracy: 0.9483 - val_loss: 0.1562 - val_accuracy: 0.9464\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1396 - accuracy: 0.9485 - val_loss: 0.1774 - val_accuracy: 0.9452\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1352 - accuracy: 0.9481 - val_loss: 0.1536 - val_accuracy: 0.9394\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1203 - accuracy: 0.9548 - val_loss: 0.1469 - val_accuracy: 0.9464\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1169 - accuracy: 0.9553 - val_loss: 0.1708 - val_accuracy: 0.9452\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1138 - accuracy: 0.9554 - val_loss: 0.1648 - val_accuracy: 0.9429\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1196 - accuracy: 0.9544 - val_loss: 0.1621 - val_accuracy: 0.9464\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1096 - accuracy: 0.9571 - val_loss: 0.1865 - val_accuracy: 0.9312\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1162 - accuracy: 0.9552 - val_loss: 0.1861 - val_accuracy: 0.9324\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0974 - accuracy: 0.9610 - val_loss: 0.1678 - val_accuracy: 0.9429\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1010 - accuracy: 0.9617 - val_loss: 0.1996 - val_accuracy: 0.9382\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1022 - accuracy: 0.9593 - val_loss: 0.1584 - val_accuracy: 0.9510\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0902 - accuracy: 0.9623 - val_loss: 0.1564 - val_accuracy: 0.9406\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1003 - accuracy: 0.9621 - val_loss: 0.1741 - val_accuracy: 0.9371\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0993 - accuracy: 0.9610 - val_loss: 0.1512 - val_accuracy: 0.9452\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0898 - accuracy: 0.9661 - val_loss: 0.1508 - val_accuracy: 0.9464\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0915 - accuracy: 0.9614 - val_loss: 0.1517 - val_accuracy: 0.9452\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0910 - accuracy: 0.9654 - val_loss: 0.1639 - val_accuracy: 0.9394\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0822 - accuracy: 0.9680 - val_loss: 0.1346 - val_accuracy: 0.9476\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0753 - accuracy: 0.9688 - val_loss: 0.1523 - val_accuracy: 0.9382\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0822 - accuracy: 0.9674 - val_loss: 0.1652 - val_accuracy: 0.9476\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0806 - accuracy: 0.9688 - val_loss: 0.1391 - val_accuracy: 0.9510\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0725 - accuracy: 0.9723 - val_loss: 0.1527 - val_accuracy: 0.9429\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0752 - accuracy: 0.9705 - val_loss: 0.1744 - val_accuracy: 0.9429\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0739 - accuracy: 0.9723 - val_loss: 0.1448 - val_accuracy: 0.9499\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0780 - accuracy: 0.9665 - val_loss: 0.1465 - val_accuracy: 0.9476\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0751 - accuracy: 0.9698 - val_loss: 0.1687 - val_accuracy: 0.9417\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0717 - accuracy: 0.9702 - val_loss: 0.1597 - val_accuracy: 0.9522\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0715 - accuracy: 0.9728 - val_loss: 0.1775 - val_accuracy: 0.9406\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0703 - accuracy: 0.9725 - val_loss: 0.1578 - val_accuracy: 0.9487\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0670 - accuracy: 0.9734 - val_loss: 0.1486 - val_accuracy: 0.9510\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0689 - accuracy: 0.9719 - val_loss: 0.1409 - val_accuracy: 0.9476\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0625 - accuracy: 0.9757 - val_loss: 0.1548 - val_accuracy: 0.9476\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0640 - accuracy: 0.9733 - val_loss: 0.1642 - val_accuracy: 0.9452\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0642 - accuracy: 0.9728 - val_loss: 0.1553 - val_accuracy: 0.9429\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0648 - accuracy: 0.9722 - val_loss: 0.1502 - val_accuracy: 0.9522\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0598 - accuracy: 0.9749 - val_loss: 0.1578 - val_accuracy: 0.9487\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0642 - accuracy: 0.9754 - val_loss: 0.1899 - val_accuracy: 0.9429\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0628 - accuracy: 0.9740 - val_loss: 0.1566 - val_accuracy: 0.9476\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0576 - accuracy: 0.9757 - val_loss: 0.1682 - val_accuracy: 0.9487\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0634 - accuracy: 0.9728 - val_loss: 0.1602 - val_accuracy: 0.9464\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0569 - accuracy: 0.9772 - val_loss: 0.1954 - val_accuracy: 0.9347\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0527 - accuracy: 0.9764 - val_loss: 0.1661 - val_accuracy: 0.9452\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.1863 - val_accuracy: 0.9382\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0610 - accuracy: 0.9749 - val_loss: 0.1742 - val_accuracy: 0.9441\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0553 - accuracy: 0.9773 - val_loss: 0.1621 - val_accuracy: 0.9382\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0534 - accuracy: 0.9754 - val_loss: 0.1887 - val_accuracy: 0.9371\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0609 - accuracy: 0.9737 - val_loss: 0.1558 - val_accuracy: 0.9464\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0536 - accuracy: 0.9789 - val_loss: 0.1566 - val_accuracy: 0.9487\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0580 - accuracy: 0.9769 - val_loss: 0.1865 - val_accuracy: 0.9417\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0557 - accuracy: 0.9777 - val_loss: 0.1574 - val_accuracy: 0.9499\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0547 - accuracy: 0.9764 - val_loss: 0.1490 - val_accuracy: 0.9510\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0484 - accuracy: 0.9797 - val_loss: 0.1603 - val_accuracy: 0.9487\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0515 - accuracy: 0.9798 - val_loss: 0.1548 - val_accuracy: 0.9417\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0565 - accuracy: 0.9793 - val_loss: 0.1767 - val_accuracy: 0.9499\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0517 - accuracy: 0.9793 - val_loss: 0.1787 - val_accuracy: 0.9499\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0478 - accuracy: 0.9797 - val_loss: 0.1544 - val_accuracy: 0.9522\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0454 - accuracy: 0.9813 - val_loss: 0.1862 - val_accuracy: 0.9464\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0492 - accuracy: 0.9781 - val_loss: 0.1968 - val_accuracy: 0.9441\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0433 - accuracy: 0.9802 - val_loss: 0.2007 - val_accuracy: 0.9406\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0491 - accuracy: 0.9799 - val_loss: 0.1793 - val_accuracy: 0.9476\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0491 - accuracy: 0.9795 - val_loss: 0.1764 - val_accuracy: 0.9510\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0511 - accuracy: 0.9793 - val_loss: 0.1827 - val_accuracy: 0.9476\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0479 - accuracy: 0.9808 - val_loss: 0.1859 - val_accuracy: 0.9499\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0571 - accuracy: 0.9788 - val_loss: 0.1636 - val_accuracy: 0.9534\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0409 - accuracy: 0.9828 - val_loss: 0.1743 - val_accuracy: 0.9452\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0436 - accuracy: 0.9815 - val_loss: 0.1965 - val_accuracy: 0.9452\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0473 - accuracy: 0.9812 - val_loss: 0.1752 - val_accuracy: 0.9545\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0415 - accuracy: 0.9828 - val_loss: 0.1606 - val_accuracy: 0.9569\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0486 - accuracy: 0.9813 - val_loss: 0.1887 - val_accuracy: 0.9487\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0474 - accuracy: 0.9815 - val_loss: 0.1659 - val_accuracy: 0.9476\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 0.1807 - val_accuracy: 0.9429\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0479 - accuracy: 0.9803 - val_loss: 0.1589 - val_accuracy: 0.9476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs3CkNXeRbxp",
        "outputId": "84e0de63-6be7-4b3a-9189-6bd7f576cca1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9259\n",
            "평균 손실: 0.1874\n",
            "평균 검증 정확도: 0.9043\n",
            "평균 검증 손실: 0.2653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+Adamax+normalization"
      ],
      "metadata": {
        "id": "9QKuAaIgT0uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "# 모델 구성\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(image_w, image_h, 3), activation=\"relu\"))\n",
        "model9.add(BatchNormalization())\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "\n",
        "model9.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model9.add(BatchNormalization())\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "\n",
        "model9.add(Flatten())\n",
        "model9.add(Dense(256, activation='relu'))\n",
        "model9.add(Dropout(0.5))\n",
        "model9.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model9.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax',metrics=['accuracy'])\n",
        "\n",
        "model_dir = './model9'\n",
        "model_path = model_dir + \"/cloud_classify.model9\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "lGLX9eW6T8SK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIqLocT5UaSQ",
        "outputId": "d5851f05-0799-40da-dbb9-0b16621f5e01"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,621\n",
            "Trainable params: 4,215,429\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model9.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0G4fc5Ub75",
        "outputId": "b4ff579e-342b-483e-ec7f-ff5b5538b661"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 5s 12ms/step - loss: 1.8242 - accuracy: 0.4417 - val_loss: 11.3449 - val_accuracy: 0.2657\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 1.1683 - accuracy: 0.5235 - val_loss: 3.0268 - val_accuracy: 0.4499\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0778 - accuracy: 0.5602 - val_loss: 1.2311 - val_accuracy: 0.5688\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.9913 - accuracy: 0.5964 - val_loss: 0.9316 - val_accuracy: 0.6434\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.9123 - accuracy: 0.6284 - val_loss: 1.1152 - val_accuracy: 0.5991\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.8497 - accuracy: 0.6576 - val_loss: 0.9423 - val_accuracy: 0.6387\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.7864 - accuracy: 0.6752 - val_loss: 0.8737 - val_accuracy: 0.6480\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.7439 - accuracy: 0.6964 - val_loss: 0.8590 - val_accuracy: 0.6830\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.6808 - accuracy: 0.7188 - val_loss: 0.7926 - val_accuracy: 0.7110\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6422 - accuracy: 0.7423 - val_loss: 0.7100 - val_accuracy: 0.7459\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5831 - accuracy: 0.7636 - val_loss: 0.7750 - val_accuracy: 0.7273\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5419 - accuracy: 0.7845 - val_loss: 0.8939 - val_accuracy: 0.7156\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.5074 - accuracy: 0.8008 - val_loss: 0.6473 - val_accuracy: 0.7704\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4818 - accuracy: 0.8068 - val_loss: 0.7081 - val_accuracy: 0.7855\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4243 - accuracy: 0.8310 - val_loss: 0.5018 - val_accuracy: 0.8030\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4261 - accuracy: 0.8296 - val_loss: 0.5411 - val_accuracy: 0.7902\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3836 - accuracy: 0.8492 - val_loss: 0.5653 - val_accuracy: 0.8007\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3530 - accuracy: 0.8562 - val_loss: 0.7060 - val_accuracy: 0.8054\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3346 - accuracy: 0.8694 - val_loss: 0.5815 - val_accuracy: 0.7995\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.3210 - accuracy: 0.8731 - val_loss: 0.4960 - val_accuracy: 0.8275\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3056 - accuracy: 0.8827 - val_loss: 0.3502 - val_accuracy: 0.8718\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2970 - accuracy: 0.8805 - val_loss: 0.4137 - val_accuracy: 0.8473\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2926 - accuracy: 0.8851 - val_loss: 0.4624 - val_accuracy: 0.8427\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2722 - accuracy: 0.8937 - val_loss: 0.4225 - val_accuracy: 0.8531\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2532 - accuracy: 0.8987 - val_loss: 0.5961 - val_accuracy: 0.8135\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2243 - accuracy: 0.9121 - val_loss: 0.3297 - val_accuracy: 0.8834\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2278 - accuracy: 0.9102 - val_loss: 0.4596 - val_accuracy: 0.8438\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2146 - accuracy: 0.9141 - val_loss: 0.4434 - val_accuracy: 0.8380\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2053 - accuracy: 0.9193 - val_loss: 0.6968 - val_accuracy: 0.7902\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.2068 - accuracy: 0.9184 - val_loss: 0.2857 - val_accuracy: 0.8951\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1896 - accuracy: 0.9253 - val_loss: 0.4561 - val_accuracy: 0.8555\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1826 - accuracy: 0.9275 - val_loss: 0.2711 - val_accuracy: 0.8939\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1812 - accuracy: 0.9264 - val_loss: 0.3837 - val_accuracy: 0.8683\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1665 - accuracy: 0.9346 - val_loss: 0.3580 - val_accuracy: 0.8765\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1651 - accuracy: 0.9354 - val_loss: 0.4113 - val_accuracy: 0.8660\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1634 - accuracy: 0.9367 - val_loss: 0.2647 - val_accuracy: 0.9172\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1567 - accuracy: 0.9406 - val_loss: 0.2446 - val_accuracy: 0.9207\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1511 - accuracy: 0.9404 - val_loss: 0.4926 - val_accuracy: 0.8636\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1468 - accuracy: 0.9437 - val_loss: 0.3044 - val_accuracy: 0.8939\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1467 - accuracy: 0.9442 - val_loss: 0.2633 - val_accuracy: 0.9114\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1284 - accuracy: 0.9492 - val_loss: 0.2615 - val_accuracy: 0.9068\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1379 - accuracy: 0.9479 - val_loss: 0.2662 - val_accuracy: 0.9207\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1257 - accuracy: 0.9529 - val_loss: 0.4762 - val_accuracy: 0.8683\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1230 - accuracy: 0.9540 - val_loss: 0.5258 - val_accuracy: 0.8438\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1238 - accuracy: 0.9518 - val_loss: 0.5040 - val_accuracy: 0.8601\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.1175 - accuracy: 0.9548 - val_loss: 0.2783 - val_accuracy: 0.9079\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1135 - accuracy: 0.9584 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1102 - accuracy: 0.9582 - val_loss: 0.3097 - val_accuracy: 0.9056\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1065 - accuracy: 0.9589 - val_loss: 0.2885 - val_accuracy: 0.9172\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0968 - accuracy: 0.9602 - val_loss: 0.4857 - val_accuracy: 0.8601\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0981 - accuracy: 0.9611 - val_loss: 0.3350 - val_accuracy: 0.8846\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1108 - accuracy: 0.9561 - val_loss: 0.2951 - val_accuracy: 0.9044\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0917 - accuracy: 0.9643 - val_loss: 0.3046 - val_accuracy: 0.9114\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.1024 - accuracy: 0.9644 - val_loss: 0.3171 - val_accuracy: 0.9033\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0960 - accuracy: 0.9624 - val_loss: 0.2863 - val_accuracy: 0.9044\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0992 - accuracy: 0.9618 - val_loss: 0.3004 - val_accuracy: 0.9172\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.2432 - val_accuracy: 0.9266\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0863 - accuracy: 0.9676 - val_loss: 0.4478 - val_accuracy: 0.8555\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0892 - accuracy: 0.9643 - val_loss: 0.3247 - val_accuracy: 0.8963\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0899 - accuracy: 0.9655 - val_loss: 0.3542 - val_accuracy: 0.9091\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0831 - accuracy: 0.9683 - val_loss: 0.2672 - val_accuracy: 0.9254\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0757 - accuracy: 0.9702 - val_loss: 0.2759 - val_accuracy: 0.9242\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0928 - accuracy: 0.9666 - val_loss: 0.2631 - val_accuracy: 0.9161\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0809 - accuracy: 0.9680 - val_loss: 0.3172 - val_accuracy: 0.9126\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0753 - accuracy: 0.9712 - val_loss: 0.3090 - val_accuracy: 0.9079\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0771 - accuracy: 0.9705 - val_loss: 0.3797 - val_accuracy: 0.8846\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0714 - accuracy: 0.9725 - val_loss: 0.4120 - val_accuracy: 0.8765\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0753 - accuracy: 0.9716 - val_loss: 0.2843 - val_accuracy: 0.9161\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0727 - accuracy: 0.9711 - val_loss: 0.3470 - val_accuracy: 0.9138\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0812 - accuracy: 0.9689 - val_loss: 0.2417 - val_accuracy: 0.9289\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0713 - accuracy: 0.9723 - val_loss: 0.2710 - val_accuracy: 0.9207\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0688 - accuracy: 0.9750 - val_loss: 0.2927 - val_accuracy: 0.9184\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0663 - accuracy: 0.9764 - val_loss: 0.2817 - val_accuracy: 0.9207\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0671 - accuracy: 0.9744 - val_loss: 0.3693 - val_accuracy: 0.9068\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0680 - accuracy: 0.9750 - val_loss: 0.3011 - val_accuracy: 0.9044\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0676 - accuracy: 0.9732 - val_loss: 0.3562 - val_accuracy: 0.9149\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0730 - accuracy: 0.9718 - val_loss: 0.2407 - val_accuracy: 0.9219\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0644 - accuracy: 0.9737 - val_loss: 0.3096 - val_accuracy: 0.9207\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0628 - accuracy: 0.9755 - val_loss: 0.4315 - val_accuracy: 0.8648\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0702 - accuracy: 0.9740 - val_loss: 0.3067 - val_accuracy: 0.9068\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0637 - accuracy: 0.9764 - val_loss: 0.2865 - val_accuracy: 0.9219\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0606 - accuracy: 0.9785 - val_loss: 0.4743 - val_accuracy: 0.8951\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 0.5005 - val_accuracy: 0.8543\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0663 - accuracy: 0.9772 - val_loss: 0.3040 - val_accuracy: 0.9254\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0557 - accuracy: 0.9808 - val_loss: 0.3165 - val_accuracy: 0.9231\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0636 - accuracy: 0.9769 - val_loss: 0.3230 - val_accuracy: 0.9126\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0611 - accuracy: 0.9775 - val_loss: 0.2914 - val_accuracy: 0.9161\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0575 - accuracy: 0.9785 - val_loss: 0.2959 - val_accuracy: 0.9196\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 0.2706 - val_accuracy: 0.9324\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0615 - accuracy: 0.9773 - val_loss: 0.2657 - val_accuracy: 0.9277\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.3581 - val_accuracy: 0.8881\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0624 - accuracy: 0.9760 - val_loss: 0.2914 - val_accuracy: 0.9172\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.0539 - accuracy: 0.9788 - val_loss: 0.3099 - val_accuracy: 0.9172\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0546 - accuracy: 0.9795 - val_loss: 0.5796 - val_accuracy: 0.8497\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0494 - accuracy: 0.9811 - val_loss: 0.3403 - val_accuracy: 0.9033\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0560 - accuracy: 0.9784 - val_loss: 0.2726 - val_accuracy: 0.9324\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.9830 - val_loss: 0.3751 - val_accuracy: 0.9033\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.3314 - val_accuracy: 0.9184\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0530 - accuracy: 0.9794 - val_loss: 0.2997 - val_accuracy: 0.9172\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.3169 - val_accuracy: 0.9219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3xLIxBUUeEb",
        "outputId": "bd3ddcab-f620-4992-ce87-fd7f662877bd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9107\n",
            "평균 손실: 0.2293\n",
            "평균 검증 정확도: 0.8545\n",
            "평균 검증 손실: 0.5607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+Adamax+normalization"
      ],
      "metadata": {
        "id": "H_Latu95T4u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model10 = Sequential()\n",
        "\n",
        "    model10.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Flatten())\n",
        "    model10.add(Dense(256, activation='relu'))\n",
        "    model10.add(Dropout(0.5))\n",
        "    model10.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model10.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model10'\n",
        "    model_path = model_dir + \"/cloud_classify.model10\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "tATd1F5wUllI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0vWDyy1U4Hm",
        "outputId": "c23ac628-f3ee-487a-f5da-3a7a10f7e980"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,933\n",
            "Trainable params: 2,340,229\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model10.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A4L6qbqU5xf",
        "outputId": "36995b52-304e-4b3d-f0fa-e26e9a1360cf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 6s 14ms/step - loss: 1.8828 - accuracy: 0.3887 - val_loss: 1.5647 - val_accuracy: 0.2413\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.3342 - accuracy: 0.4362 - val_loss: 1.4119 - val_accuracy: 0.4079\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.2808 - accuracy: 0.4656 - val_loss: 1.2232 - val_accuracy: 0.4988\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.2446 - accuracy: 0.4904 - val_loss: 1.2138 - val_accuracy: 0.4942\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.2042 - accuracy: 0.5003 - val_loss: 1.1749 - val_accuracy: 0.5058\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.1540 - accuracy: 0.5267 - val_loss: 1.0991 - val_accuracy: 0.5350\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.1210 - accuracy: 0.5477 - val_loss: 1.0557 - val_accuracy: 0.5769\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.0582 - accuracy: 0.5684 - val_loss: 1.0443 - val_accuracy: 0.5699\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 1.0326 - accuracy: 0.5897 - val_loss: 1.1155 - val_accuracy: 0.5315\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.9812 - accuracy: 0.6102 - val_loss: 1.0217 - val_accuracy: 0.6061\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.9327 - accuracy: 0.6231 - val_loss: 0.9116 - val_accuracy: 0.6305\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.8972 - accuracy: 0.6427 - val_loss: 0.8457 - val_accuracy: 0.6678\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.8583 - accuracy: 0.6534 - val_loss: 0.9073 - val_accuracy: 0.6177\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.8178 - accuracy: 0.6658 - val_loss: 0.7599 - val_accuracy: 0.6946\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.7919 - accuracy: 0.6816 - val_loss: 0.7176 - val_accuracy: 0.7214\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.7369 - accuracy: 0.7096 - val_loss: 0.8206 - val_accuracy: 0.6713\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.7121 - accuracy: 0.7073 - val_loss: 0.6807 - val_accuracy: 0.7110\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.6746 - accuracy: 0.7240 - val_loss: 0.8013 - val_accuracy: 0.6538\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.6429 - accuracy: 0.7390 - val_loss: 0.5429 - val_accuracy: 0.7984\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.6215 - accuracy: 0.7445 - val_loss: 0.5778 - val_accuracy: 0.7844\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.6099 - accuracy: 0.7500 - val_loss: 0.5938 - val_accuracy: 0.7587\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.5761 - accuracy: 0.7619 - val_loss: 0.5315 - val_accuracy: 0.7716\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.5447 - accuracy: 0.7789 - val_loss: 1.1619 - val_accuracy: 0.6573\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.5188 - accuracy: 0.7862 - val_loss: 0.8727 - val_accuracy: 0.6981\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.5079 - accuracy: 0.7924 - val_loss: 0.4398 - val_accuracy: 0.8357\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4880 - accuracy: 0.8025 - val_loss: 0.6173 - val_accuracy: 0.7517\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4610 - accuracy: 0.8121 - val_loss: 0.6486 - val_accuracy: 0.7483\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4511 - accuracy: 0.8196 - val_loss: 0.8015 - val_accuracy: 0.7098\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4320 - accuracy: 0.8222 - val_loss: 0.4210 - val_accuracy: 0.8228\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4149 - accuracy: 0.8285 - val_loss: 0.3767 - val_accuracy: 0.8555\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3880 - accuracy: 0.8395 - val_loss: 0.3450 - val_accuracy: 0.8695\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.4007 - accuracy: 0.8372 - val_loss: 0.5512 - val_accuracy: 0.7890\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3780 - accuracy: 0.8467 - val_loss: 0.3816 - val_accuracy: 0.8438\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3698 - accuracy: 0.8498 - val_loss: 0.3272 - val_accuracy: 0.8706\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3537 - accuracy: 0.8564 - val_loss: 0.3798 - val_accuracy: 0.8508\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3388 - accuracy: 0.8622 - val_loss: 0.3428 - val_accuracy: 0.8543\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3295 - accuracy: 0.8653 - val_loss: 0.3441 - val_accuracy: 0.8765\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3143 - accuracy: 0.8705 - val_loss: 0.3391 - val_accuracy: 0.8508\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3182 - accuracy: 0.8716 - val_loss: 0.4568 - val_accuracy: 0.8205\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.3100 - accuracy: 0.8702 - val_loss: 0.2172 - val_accuracy: 0.9207\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2943 - accuracy: 0.8824 - val_loss: 0.6988 - val_accuracy: 0.7879\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2843 - accuracy: 0.8840 - val_loss: 0.4285 - val_accuracy: 0.8368\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2789 - accuracy: 0.8868 - val_loss: 0.4080 - val_accuracy: 0.8473\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2768 - accuracy: 0.8849 - val_loss: 0.5188 - val_accuracy: 0.8077\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2805 - accuracy: 0.8882 - val_loss: 0.3865 - val_accuracy: 0.8531\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2594 - accuracy: 0.8911 - val_loss: 0.3675 - val_accuracy: 0.8566\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2599 - accuracy: 0.8933 - val_loss: 0.3287 - val_accuracy: 0.8695\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2554 - accuracy: 0.8964 - val_loss: 0.1831 - val_accuracy: 0.9312\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2442 - accuracy: 0.9021 - val_loss: 0.3433 - val_accuracy: 0.8566\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2346 - accuracy: 0.9016 - val_loss: 0.1998 - val_accuracy: 0.9219\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2334 - accuracy: 0.9023 - val_loss: 0.1908 - val_accuracy: 0.9231\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2256 - accuracy: 0.9023 - val_loss: 0.1580 - val_accuracy: 0.9324\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2205 - accuracy: 0.9115 - val_loss: 0.2443 - val_accuracy: 0.9009\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2236 - accuracy: 0.9065 - val_loss: 0.2423 - val_accuracy: 0.9079\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2203 - accuracy: 0.9097 - val_loss: 0.3950 - val_accuracy: 0.8590\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2145 - accuracy: 0.9089 - val_loss: 0.2082 - val_accuracy: 0.9161\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2101 - accuracy: 0.9110 - val_loss: 0.1965 - val_accuracy: 0.9172\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1936 - accuracy: 0.9185 - val_loss: 0.1976 - val_accuracy: 0.9207\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2009 - accuracy: 0.9161 - val_loss: 0.2654 - val_accuracy: 0.8974\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1911 - accuracy: 0.9185 - val_loss: 0.2311 - val_accuracy: 0.9056\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1907 - accuracy: 0.9241 - val_loss: 0.3189 - val_accuracy: 0.8834\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1965 - accuracy: 0.9131 - val_loss: 0.2466 - val_accuracy: 0.9044\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.2026 - accuracy: 0.9193 - val_loss: 0.1772 - val_accuracy: 0.9324\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1847 - accuracy: 0.9211 - val_loss: 0.2181 - val_accuracy: 0.9068\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1832 - accuracy: 0.9236 - val_loss: 0.1688 - val_accuracy: 0.9301\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9280 - val_loss: 0.4033 - val_accuracy: 0.8566\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1836 - accuracy: 0.9237 - val_loss: 0.1812 - val_accuracy: 0.9359\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9294 - val_loss: 0.2965 - val_accuracy: 0.8893\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1726 - accuracy: 0.9316 - val_loss: 0.2685 - val_accuracy: 0.8916\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1674 - accuracy: 0.9334 - val_loss: 0.2737 - val_accuracy: 0.9033\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1634 - accuracy: 0.9342 - val_loss: 0.2125 - val_accuracy: 0.9184\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1609 - accuracy: 0.9345 - val_loss: 0.4183 - val_accuracy: 0.8660\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1677 - accuracy: 0.9323 - val_loss: 0.1727 - val_accuracy: 0.9336\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1576 - accuracy: 0.9329 - val_loss: 0.1868 - val_accuracy: 0.9289\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1562 - accuracy: 0.9365 - val_loss: 0.4868 - val_accuracy: 0.8427\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1510 - accuracy: 0.9385 - val_loss: 0.1687 - val_accuracy: 0.9371\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1477 - accuracy: 0.9373 - val_loss: 0.3442 - val_accuracy: 0.8881\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1478 - accuracy: 0.9382 - val_loss: 0.1881 - val_accuracy: 0.9242\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1397 - accuracy: 0.9417 - val_loss: 0.2219 - val_accuracy: 0.9231\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1503 - accuracy: 0.9377 - val_loss: 0.3061 - val_accuracy: 0.8893\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1502 - accuracy: 0.9368 - val_loss: 0.1509 - val_accuracy: 0.9406\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1441 - accuracy: 0.9396 - val_loss: 0.1384 - val_accuracy: 0.9394\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1387 - accuracy: 0.9421 - val_loss: 0.1888 - val_accuracy: 0.9172\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1435 - accuracy: 0.9428 - val_loss: 0.1315 - val_accuracy: 0.9441\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1348 - accuracy: 0.9444 - val_loss: 0.1643 - val_accuracy: 0.9347\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1320 - accuracy: 0.9478 - val_loss: 0.2286 - val_accuracy: 0.9091\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1286 - accuracy: 0.9482 - val_loss: 0.1462 - val_accuracy: 0.9441\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1280 - accuracy: 0.9469 - val_loss: 0.1786 - val_accuracy: 0.9347\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1269 - accuracy: 0.9491 - val_loss: 0.2078 - val_accuracy: 0.9359\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1311 - accuracy: 0.9447 - val_loss: 0.1678 - val_accuracy: 0.9289\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1411 - accuracy: 0.9391 - val_loss: 0.1776 - val_accuracy: 0.9359\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1291 - accuracy: 0.9453 - val_loss: 0.1624 - val_accuracy: 0.9417\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1287 - accuracy: 0.9490 - val_loss: 0.6890 - val_accuracy: 0.7984\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1251 - accuracy: 0.9492 - val_loss: 0.1404 - val_accuracy: 0.9417\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1240 - accuracy: 0.9481 - val_loss: 0.3831 - val_accuracy: 0.8718\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1174 - accuracy: 0.9488 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1131 - accuracy: 0.9521 - val_loss: 0.1800 - val_accuracy: 0.9301\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1204 - accuracy: 0.9466 - val_loss: 0.1395 - val_accuracy: 0.9476\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1130 - accuracy: 0.9543 - val_loss: 0.2388 - val_accuracy: 0.9231\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 3s 13ms/step - loss: 0.1136 - accuracy: 0.9547 - val_loss: 0.1425 - val_accuracy: 0.9499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3jMKJG5U7gI",
        "outputId": "a25b8452-8c1b-42a5-a4b8-6460c46e29ad"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8410\n",
            "평균 손실: 0.3924\n",
            "평균 검증 정확도: 0.8227\n",
            "평균 검증 손실: 0.4535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZY1m2Fis5pO"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test data로 비교"
      ],
      "metadata": {
        "id": "PDTDNdJDn9ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "J8Gk51iVs6xL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15358006-4a9d-45cd-d6b5-0f33d4a39bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "////////////////////\n",
            "1.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "100.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "101.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "104.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "10.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "102.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "106.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "108.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "107.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "103.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "105.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "12.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "130.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "131.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "137.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "122.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "119.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "117.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "118.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "127.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "123.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "125.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "13.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "109.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "112.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "135.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "110.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "124.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "115.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "121.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "138.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "136.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "114.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "132.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "128.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "133.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "134.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "111.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "129.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "113.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "126.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "120.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "116.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "11.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "152.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "163.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "169.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "146.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "139.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "156.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "151.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "153.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "167.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "157.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "149.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "16.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "15.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "162.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "159.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "148.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "158.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "143.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "17.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "160.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "140.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "168.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "166.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "142.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "145.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "150.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "154.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "165.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "147.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "161.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "155.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "14.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "144.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "141.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "164.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "188.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "178.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "180.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "179.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "177.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "190.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "184.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "2.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "174.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "20.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "192.jpg의 예측되는 구름종류 : Cb\n",
            "////////////////////\n",
            "195.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "193.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "18.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "187.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "189.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "175.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "191.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "197.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "173.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "183.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "198.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "172.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "171.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "185.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "200.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "19.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "194.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "181.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "182.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "186.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "199.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "196.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "201.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "170.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "176.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "202.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "25.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "212.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "28.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "27.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "220.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "26.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "217.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "21.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "31.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "218.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "206.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "209.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "215.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "32.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "211.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "34.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "30.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "216.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "24.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "33.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "214.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "207.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "208.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "219.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "36.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "23.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "213.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "210.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "22.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "205.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "203.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "35.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "204.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "29.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "3.jpg의 예측되는 구름종류 : Cb\n",
            "////////////////////\n",
            "55.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "38.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "69.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "66.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "61.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "68.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "6.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "51.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "5.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "65.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "37.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "49.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "52.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "50.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "59.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "67.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "63.jpg의 예측되는 구름종류 : Cb\n",
            "////////////////////\n",
            "60.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "40.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "4.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "44.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "56.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "58.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "42.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "54.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "53.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "48.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "39.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "62.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "47.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "41.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "64.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "45.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "46.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "57.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "43.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "9.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "73.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "78.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "70.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "76.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "87.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "96.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "81.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "83.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "97.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "94.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "72.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "90.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "93.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "82.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "84.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "7.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "85.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "80.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "8.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "71.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "86.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "92.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "99.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "98.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "75.jpg의 예측되는 구름종류 : Ns\n",
            "////////////////////\n",
            "74.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "88.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "89.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "95.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "77.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "79.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "91.jpg의 예측되는 구름종류 : Cc\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/clouddata/test/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train4\") #train위치\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path+\"/*.*\")\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model3.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/clouddata/test/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train4\") #train위치\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path+\"/*.*\")\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model8.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1"
      ],
      "metadata": {
        "id": "HI_RAOSuAXpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 찍은 data로 비교"
      ],
      "metadata": {
        "id": "yafGfeJAoGKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weather (label) :\n",
        "  if label == \"Cc\" :\n",
        "    print(\"눈꺼풀 구름입니다.\")\n",
        "    print(\"단일한 선 모양입니다.\")\n",
        "    print(\"날씨에 큰 영향을 미치지 않는 구름입니다.\")\n",
        "  elif label == \"Cb\" :\n",
        "    print(\"눈구름입니다.\")\n",
        "    print(\"세포 형태의 구름입니다.\")\n",
        "    print(\"번개, 천둥, 강한 바람과 폭우가 내릴 수 있습니다. 외출을 자제해주세요!\")\n",
        "  elif label == \"Ns\" :\n",
        "    print(\"적란운입니다.\")\n",
        "    print(\"수직 형태의 구름입니다.\")\n",
        "    print(\"비, 이슬비가 내릴 수 있습니다. 우산을 챙겨 외출해주세요!\")\n",
        "  elif label == \"Sc\" :\n",
        "    print(\"층운입니다.\")\n",
        "    print(\"둥글고 조각난 모양의 구름입니다.\")\n",
        "    print(\"안정된 날씨에 발생하는 구름입니다. 마음놓고 외출하셔도 좋습니다!\")\n",
        "  elif label == \"St\" :\n",
        "    print(\"적운입니다.\")\n",
        "    print(\"평평하고 수평으로 퍼진 모양의 구름입니다.\")\n",
        "    print(\"약한 강수나 가벼운 이슬비가 내릴 수 있습니다. 흐림과 안개를 동반합니다. 우산을 챙겨 외출해주세요! 좋습니다!\")"
      ],
      "metadata": {
        "id": "Cc9nRsE03AbK"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/myclouddata/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train4\")\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path2+\"/*.*\")\n",
        "\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model3.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "k=0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    #사진 나타내기\n",
        "    plt.imshow(X[k])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    # 날씨 예측\n",
        "    weather(category[label])\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1\n",
        "    k=k+1\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GK4oWd1K2zBz",
        "outputId": "880ada56-58b9-4511-c163-1511edf91c51"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "층운입니다.\n",
            "둥글고 조각난 모양의 구름입니다.\n",
            "안정된 날씨에 발생하는 구름입니다. 마음놓고 외출하셔도 좋습니다!\n",
            "cloud1.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud2.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud11.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud.jpg의 예측되는 구름종류 : Cc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/myclouddata/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train4\")\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path2+\"/*.*\")\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model8.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "k=0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    #사진 나타내기\n",
        "    plt.imshow(X[k])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    # 날씨 예측\n",
        "    weather(category[label])\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1\n",
        "    k=k+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Duif9Bof4i5h",
        "outputId": "9904a218-ad83-409c-f1c9-eb0c72756f6c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud1.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud2.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud11.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq3ElEQVR4nO3dW5YjWXKdYcM1MqvJpaWBaAgagiaoCXAGHJUW2V1dWXGBA9BDJo1N+v6j3CoQqpb0f4+nPA/8AuAU1tlhtrvf7/eSJKmq9n/0CUiS/n64KEiSmouCJKm5KEiSmouCJKm5KEiSmouCJKm5KEiS2nHrgf/zn/45jt9u+W/f4uguz33YH2A8r1lp+Hg8xWO//vSnPMcxvyb9Ld9utz75NPbeHHe6V+H4PVz7HV7zcMjXA7ccz/ER6L58pvyScB5wfvs/4LwnHvXMaJZ8C/M9md6pdO6Pep+M5nnQ9Yzmp+8DGL/Rc37A8/8f//2//eYx/lKQJDUXBUlSc1GQJDUXBUlSc1GQJLXN6SPcEKfjw9gODx7uqu/Wa9keEkzThAMdP0kfkTscfr/dVmO36zWfxzCVhHd2kAaZZh4ekSrBGT41IATJM3jR+B6fvicekCgZpYneGf/osVWz65le+zTtl5JAO0oCjc5k9rkaf79NznGQltzKXwqSpOaiIElqLgqSpOaiIElqLgqSpLY5fXQd7tqnzW9Kcez3kPiBJSvtrFPtnzudIVwP1hAKrzlPT9B/WA/drutE0vcXzeO3kGCq4no+u3DP7znwFI+tqtod6P8pBmkQrs60eY7v82zHwYxZraRHBKEeUv/nE+tYTY0TQgOfWa/rUT7zOtP4pFbbVv5SkCQ1FwVJUnNRkCQ1FwVJUhtsNNNGJq0rYVORNixhDtosoQY0yXQDlo6PGzo0B5SoeOdv49MLwnnA+eFjyBvn+3Q5dIKD+131zuZXHByWIaHxMM9+uHHM5SJoHvgHDzDZsPwjmhpNTc7xYRvKaWOWzuMP2MSm67zC9wd9NyVuNEuSHsJFQZLUXBQkSc1FQZLUXBQkSW17k50b7M7ncEsdQtLoACkWSiVh+Yuws4479pDWOVC6h8plpPmnDVWgdEVKIUxKYlS9l8jannCgEh/03ObSyc/+TH+SPOM8yeNLA/xeXHEjlQTJuHfVY5rYPGLuvxvD8/7M66TvrEmZC/o80Gd5C38pSJKai4IkqbkoSJKai4IkqbkoSJLa5vTRARqq0Pj5uJ76cMgvR+kj3IUPSajbLid7dsNyPlRdJCaHUgGh4lo5HO4I82AiK99DSiFQvZRdOP4QnlnVPJXDiY3UJCQf+ZlJoOncnxlKwusfjKJPPO9HPJ9HNYiZpHX+iIQZfQZHddZg/DOux18KkqTmoiBJai4KkqTmoiBJai4KkqS2OX1Eu9zHA6RkQippWuOo7tsLAGGSAZc9mHvQ3egODdYo8sRdn0KdG7r2cXLmATWE4N5O5qiadY6i18Q01eC+8KF/QO0jPJmQ1JrODf+AO8ylMUgGYgOzz+sY95m1nKYm5zJNGWG3yIfVIHufvxQkSc1FQZLUXBQkSc1FQZLUNm80kxs030mlKLicBUwOu1lp/wg3lWDu6/LxzRxubkLjsGGbrofmpk0r+hcwnBp8jDe46JbTeyLszOOxV3j2cC731EyJSpwcoZkQlGGhUi67kGKYN2WZHP/3s9H6ma/5qA3lyTyT0hLvmYQpCF1PGp+W0NjCXwqSpOaiIElqLgqSpOaiIElqLgqSpPbh9BGlXtLu9/W6xGMxPTBIWxyg+QyGkiiVFFI5aHsVjh/j1AgnTQH35JbP77bL95ZMGnYcjyeaJA/TcwsJIUxTUdmSB/x/DD3j+4lKaJzj+CGUeJmGb8Zhpcnc8BxmJUFmqb6/d9OSE+RRaaWJdO6TpN9W/lKQJDUXBUlSc1GQJDUXBUlSc1GQJLWPp49gt/2a0i2pPk29U+dn1LAjr297GKc6TJSqSCEMTDJAImAHDYlmzV0obUCpChofvCIcfLjmGkJ8OR+vRbPbUUJo8P83cBq3GzVegiTHIV3/tPbPJA0zq/EzbSb0mEZFjzA7v0ckgR6VGkp1wqbnh5/Z8L1yoyTdJEX5n/hLQZLUXBQkSc1FQZLUXBQkSc1FQZLUPi19lAMEtNs+mzsmTXiSPA5plcMRUkyh+xZ2PcKd/0F3NEjZkMM+1ye6QZIh1iHiFngwSnPDNNEsHUUpo4d0GYMXpee8S7W86PwoOUTXn27iMCCD9wob6U1egJ5DPnoS7uE5Zt8f6T0x6Wr2e8Zv4WSWt7d4LNWCo++PWPvoCt9BH0hT+UtBktRcFCRJzUVBktRcFCRJzUVBktQ2p49otz3V+qiqOoT1JiV4qqpusIPOYYj1udBm+43qEEFnouOR6vmsz51SHFjiCEC+YXIwo1sbbhg9y6nP7D41Taol0xo61wVSIiENMv2cTO45dYzbxxpMDCtwpbTOcBLuorh1cJYm+v4fIIEThvf0/8H03AYpo6qqW0gUXaF2Fj3Phd5v6XjqvPaB1nj+UpAkNRcFSVJzUZAkNRcFSVLbvNH8dMxlFCYbaLxvPNsUwQY5AW24TOaoqrrdwuYPluHAXbjBOGw/YykGaLZBjY3Ca3JZkXwutFE2LQ0wM2lMQu8rKkWRx2njL81On4fjcVZRZh/enwd8zw7fhyA9T9poxTtL3wcQMknGzYHueaN9F75X4NDa04YtNdKiTeLLZTWWNp+rqq6XPL4s6zmqYHN7WPpjC38pSJKai4IkqbkoSJKai4IkqbkoSJLa5kgEpQpGSRMK31BiYZB82EG6ARMbODf9yfz2pie40lLKKpzjLGfyno8ngajJzNQjyl+kRElV1T08H0ye0XOAcSqVkq7nDu83Li1B46GsyrTUDBx/GZRXoBIf+N6HMjFfv/60GuOSMqOXxI9VGr/fZ5/7K3ya6TNxCQ11KL22UCqJEk/p/fYJJWX8pSBJai4KkqTmoiBJai4KkqTmoiBJah9ussMplvWu+A52+DFlBHV79iGecD6d8/lBKolSFVj/J6UWqLEPnDclHPahIAvVisH7jd1nYDgkaui8px6TiKAmJvB8UmQFkkB0epj6mKSP8DHMEk+73brWGNVPotd8/vU5jr++vcbxlJKhlA2NH6DhT/qMH/70JziW/l8VnsOgxFOqKVVVBW+rWMuoquoC9zA22Vkg7QUpsMk9HzU12shfCpKk5qIgSWouCpKk5qIgSWouCpKktjl9NE6UpLojWOdl0k2rardbJxyoI9kOdvKxidUNdvNTFycsxgI1asJ5V+VSLxgE2lFCJh9O9zB1caLUw7QT1mfaQa4iPk+6hw9KWcXyXpScgTcL1cVJaaoLJGEWSre8wfGpi2DlU7xeZ/eKruf25z+vxyDV9fWndZ2kqqr9YfZ+24ck1H6fP4Ovzy9x/Ndvv8Txt9d8fExwQbRpmuxK9wtrZw07S/4tfylIkpqLgiSpuShIkpqLgiSpbd5oJrQBnTYy6Y+vsXIDvGbaRLnC0Ud6TRqH8hLpemjjfD9ca1MJhPstbx7ihj+W3Jj9Kf3EpMTJj3/x4deEfjJ1Tc8HNjK5VEgepsNTOYY73Nd0fj/+Sxy9vK6btVxhg/wK5RKwPAeVi4hlO2aNfejepk3yX/7682ju85enOH46r0uCVOWSG8/fcumPv/4ln8vLy69xnEpXXMM9p/Ip+TuSx9PzoWOn30H/8d9KkvSDi4IkqbkoSJKai4IkqbkoSJLah9NHnDQZNCAZpj7SjvueGlaM1z2K8aRDoeQElDrAOxUSQpRiwbTX8PhHNMKZp4/iLKO5b1CGJJVK4bIdsxRUbOBTuYTIJNlTNS91MJl7+poJle2gZjp0b1NCisp2fIPSEodT/ro63XP66Nsv31Zjf/6Xf4nHvr5Q2QpIGUHpipQ0mqSJ3jt+Yvoe/1v+UpAkNRcFSVJzUZAkNRcFSVJzUZAktQ832aGeIimxMUkT/Zgkn0uMAlH6Znsto+8vub3hDx4bR99LIYQUy4PSRxQ0ocZGj7F97nkDH7ovm19ynNbhHEfqsvOY18zj0+QZnUsez/PjuxnGt6eSUhOcqqrTKaeJzlDj6A2aCf3y13WK6e31NR67LPl6FkwZba8pRs2EpqmkhFJGe9NHkqRHcFGQJDUXBUlSc1GQJDUXBUlS25w+os1sqo0Sa8BAF6cdJRlgF/6QOjNhrZwFpp4lh+LcmB6gTliQEomDdD2UNBnMXY9JOEzrJ80CEbP01aTWC3Uko7t1p9pH4Rx57plJioUTTLPXTPeQ7ivVBDoeoWva+bwaO4WxqqrjKY+/POf6RJdL/oy/PK+7plG9pQXuLXVNm6SPUje2qpp92QD8bH5gTn8pSJKai4IkqbkoSJKai4IkqbkoSJLaIH1ENTaw+NEK1+3BV83DqZ7RQ2rLVN0h9ZPmv0KyCesQYael9diezgPcd5Tgwn+xeW569tPxfM8pZTTsjjZIH9GR2O1tUG9q3gVt+9yUYhmnwGB8H1J93AEvzzHpGrZQEgjSRDdI9dHn7fXlbT031DJasHYYdF4bdMzD9wR2EYzD8fmksY/yl4IkqbkoSJKai4IkqbkoSJLa5o1m+rN26JNRx+N6atoUGTdaCf+AShHUHja+rrDBSX/Wfl1fP/+pe37JG5SimGzOIbqH2L9o/R/2eLsfs9GcG/vMNtsmm9h4Hnt401KZi0HDI252NNtoThuZtLk53WimBixp9jscG0vNVNWyQFmZwQYs5U7Sd0oVv/WvYf5L+BxXzcpWfB8fhA/gWPzaw+/J8L33iO+O//zyD59RkvR/LRcFSVJzUZAkNRcFSVJzUZAktc3po6m0K4475cMmLrs4d17fJmU4qqruRU151ukEOj/8k3lqhJO77MRj0bihynos5y+qDhBLohQLlkQJj4ISaTxO75U0NmumkxJm780TS1FguoVKnNB4arIzef+8l8jLwymRdqd7kqcozHWF66c56NlfIQFJ17+EhCE/H0ofUSLt4yVHKGWF93DynfoB/lKQJDUXBUlSc1GQJDUXBUlSc1GQJLUPN9mhDEFqiLGDNMQk3fH9XMIYNGXhRhazJi4VUkyYVKIaOnCdKZlyh6QSwhpHVP9nPU5pImzuEmsZcV2c3W6dq9hDHaLjMY/T8cn1mp/PI1JGNA/dq2n6KKVbblgLLA/Tf8A+Uukc4X11u8O9hXRYek9gcOZK75/tdaJofkwA0seNelfRc0s3jK4T+3nN0nF5js2HrvhLQZLUXBQkSc1FQZLUXBQkSc1FQZLUNqePsDsYdhVab61TEgbnxuIo4dBRXSHuMgaXU0v4D2ms6jHdmujauX5UHoYgEDyLWSKLUixUyyrXoZq95qTzGnY1G6aP6PjlGl5zkkp5dzyeYDyW7jfXoMoJrlkib5aOi/cFEzLDukKUPAzfCTuohbbbwfcHJJ4mX1mU6sMUWB6OnxROzMEkG/hLQZLUXBQkSc1FQZLUXBQkSc1FQZLUPp4+ouG0/U2JH5gEAgFVqZ4RloWBej6UKoBt+yV0fVoglYIJlEEjMK6tknEQaJBMoTTE8N5iimUQbuH0BCWHtnfZukGXrWtIE1VVXRZ4T4STpDQRXfqeEnmpCxo+y/z/dlSDijqbpee2h8/J7ZbnoBRgmoaTZHEYr5OihLvQjfEWurFVccpoWvNtciS8JIXJ4jtlf6Ak2e8vfuQvBUlSc1GQJDUXBUlSc1GQJLXtG83XtzhOm19xo4z+HB22Yqh5RtpX2ocGLv82+/bRdxqqhHHYr8TroR20SUMM3FB+xKYvbNhRSZADzk3lTMLceYZ3SoXk4/NGc24EsyywoUwb0Pyi6zG8JbC5mw/PTZCGz5jKK/B7ZT1GgQfcOIcSGmlze7rRjJ9xOJn03K74fCCQMmhsU1V1HTTHor1g3JgO53g6neKx9PnZwl8KkqTmoiBJai4KkqTmoiBJai4KkqS2OX20wJ+HUwAlHY2VMqhRxKDUA5atyC+JKDwwaeKCjVMGNSoo8UNRiz0lh2A8nsvkBKvw4WOzmlQWgtItGM3Y3qhpgfIUlCaiVA6Vi0jPedoEaVI9Zhj2igkmnj2jkhj83Oh9uJ6H5samNHGU72H6zqJUziTxU1V1POWvzmOYiN5vV0i7UcosPWh6wufzGf7Lb/OXgiSpuShIkpqLgiSpuShIkpqLgiSpbU8fUWJjkBTAlNGwTsct7bkPao68b3u6hRqKYAJl0GWGruZADUVgHBNS4Rz5WQ6641ThZab/A7lRdAbrRG0fnz4FaibE3aEG6SN6zcH13OD9toe6SpRioeNjs6dhvSVKcMXnQym14T2cuEKKEpvvDFNWKSE0/p4Y1M+a1nDbwl8KkqTmoiBJai4KkqTmoiBJai4KkqQ2qH2U63TgLnzAAaFZDaG4PY+BhWmSYVZ3ZTIHzZLu4eS+Vs1SLFU5TTXpAlZVdb/O0hP71KgMr3OY+higlBEmNuAyYze+T0zOIOo8hs8+f5YPobPZbprhGjweut+cghu2KpvMPXxu9JxTtz+am2o/kZjggnThtWYd4/6WvxQkSc1FQZLUXBQkSc1FQZLUNm80c4mKj2/+vPOqo3OZoM1Taqgywc2BZhtryRXuN20eYgeS9Of48Jp72n9NO8fvTJTOkBqq7GA3GEtuhKY846ZO1IAF5knvfX5rfvzZYwkWeD7UqIjuefwsw8dhRxdKzZ7C88QmQMOP96QUxfG43kyv4mZUqbREFW/wLst6o/kSNp+r3mnqBK+Zrmd/yMceT/k6t/CXgiSpuShIkpqLgiSpuShIkpqLgiSpbU4fYW2AYXmFhHbhU0Lmx+yb5ybTZMrhsH03n5IZHNTanmLB3h5wLlxZZNBkZ5jWwQYsYXxc6gBqpaR7zs94Nj5pVDQ1+pyMS59AQxlqspPSVHguMA73arcPJTQGn4fv/wBOBsRAEaQLp6nD3SGfTEo33Z9n7x9MFIXvoCMdG+73Vv5SkCQ1FwVJUnNRkCQ1FwVJUnNRkCS1zemjhzQ3wZpAME5xnQfAq4FIxC0kOahJBjargQRXTODAJAdKFdDzoXo+aYo8A9cnGr4n0vHT5kCUh0n1pqYJs/m5fOzYqUmNn6p3mrjQfUn1oyhNNHzN9Pm5wecB31fDUNLs0wlzQFILayWF+3V+OuXJ4frP53x8urV7usoP1HDzl4IkqbkoSJKai4IkqbkoSJKai4IkqW2vfcSFSvLhg2QK1b/hTljbEx6YEBomHFIyYxyHoHsYjh8ne2gcrzPUPhq94jvnMqihNE3rTBJCtyu8r6Am0NRnJo0m6D3+kA6Fw3pYXCcrzTNLmI3rgYX/MKnL9f01c0dDSk6lpN75SGmi/NxOx/y1fAh1lWgOTClu4C8FSVJzUZAkNRcFSVJzUZAkNRcFSVL7cO2jPXQguobkB6WJrte8w3+F4yddw+bdxKDz2qBr2O06S31g57k0N9aiGSZNwuGYBaG0Drblmp1KnBpekpJDt9v6PYQd0+DEqTYVX8/ndU2bmKaMMJEX6vns4eKpEyF+3sLYOF2InfEG3fsGSaX3xkkqiXQ45K/ZdL+rsDlc3cN7/Aqfhyeon7SFvxQkSc1FQZLUXBQkSc1FQZLUNm80059ep+YmVXmjeaENZRinTcW0+UOr2/zP8bdvfk3nxk2r9Of4+cg5bGz0ibCCSHhVzBLA+ypstlXl54ZlEahByrS5y6g8CWzYwrnEGWAH8gibvlTqgMIhx1BG4QBNZo7wfUAuy7IeoyAANkeCoAoGUjYPjj9wk/I5V7hO+u5MG8pVOThBp71c8hxb+EtBktRcFCRJzUVBktRcFCRJzUVBktQ2Rwj2sH4s13WqoKrqFhJFqRRBVU4qVb1TRSGUdKAKBRRvoVIHJJWimDZr2UGSI79exqUoZg1LRkc+Kqo06bMybLQShz+xtERVPhdKpeD4Yft74kANVSB9RK95hNf8cn7aPAeN0wdxH5JQy/U5TwHfB0tIMFVxejHO/aDGSFz2Z31f6PnQuVwu8JqD83h5g0k28JeCJKm5KEiSmouCJKm5KEiSmouCJKltTh+9LXk3m5JDqc4RN9PJ4xQUSMmHlG6oqlqoAQcEh/ZQiybXPqI6SVRbZ5ZW+j+NarGgQU2gH/9l89THIyRtYDw2DRrWoJoen8anzWdGho1g6CXpPZ6PpcQTfXXkuZfXdXKImktRyugCsZxJDTI8lhovwTnSfUnz3+g7EmtwxeFc821ax2sDfylIkpqLgiSpuShIkpqLgiSpuShIktr29BHU0sBEUax9RB2IJp2T8jyUBKI0BNUhoiZO6WToeujEd7ucTMnHPyZVMDoeO17NUkl0W3bhBSitM03xTGpZTdJE743nFBz2ABzNPTE5v/eOT+Ncr2t23imNSJ0YuesedV7b3o2PYJc+uFcH+Af72AHw46m2qtwxcJo828JfCpKk5qIgSWouCpKk5qIgSWqDjea3OE6bOWkYN2an1RUGf75OqOQEb9ykjc/tf17/fZyagaTXnJ0flkDAkhvbN61o05fgBmKce9jEZeARG61Vs3Mcbx7Chi0HJ9J50NxwPIYs1q/58voSj306n+P48XiK4+fT+vhX+E6Z3kP6vKXrmZTE+P6aVM4CPp/p2Hjke+8JEj6zw7m38JeCJKm5KEiSmouCJKm5KEiSmouCJKltTh8t0CiCpM1vSrHs77DDDwmc2DgHSys8xi38Kf0kIVI1SwRQmIqSDHu60kHDjmlpCW7wkV8zpc8elT5K50KNlyZNTKqqTsf8MZk8T0w2wXWm0i/U0Iru4QmeJ83z7ddv62MhXfj09JTHIZU0jhjGGWbJoZQ+orQkp4/oeEi2pVIU00Y9k3IedN4f+Obzl4IkqbkoSJKai4IkqbkoSJKai4IkqW1OH0HQpHawg34c1stJLtcljt8v6/Ebpgfy3Nw8hFISs6TRZO5J2ab9sD4PzhOf2zQhAo1G4M2SawU94rwpffTxpjlVVQdIMVFyKM9N41SfKdUQmjVr+eXbr3H81+dcz2hZ1p8rrBUEHwdK9yzLOjlzDa9Hx1ZVLeFz//34PJ4afVGait769HnD40MqaX+k+klwb/PUdQupMUoqfSTr5S8FSVJzUZAkNRcFSVJzUZAkNRcFSVLbnD56+pJrmkzr5STLJacNdldIiYTEyn0Hc0C6hVIFvGuf5pl2b6M1OBw/rJVDSRuSzoUe2SRN9Nko3TJ5PliDa1jj6R7q4lDNmcMhf9ToHqbudZQaurzl9M3r62s+frnE8Xhv4Z5QF0V6zSUkCSkxSIkaTCVBp79UKwiTflRrDMNH1F0wTEQNFwF3s9yegMQulxv4S0GS1FwUJEnNRUGS1FwUJEnNRUGS1Danj44P6D5FtT5qR1v/23fQKcVxPM6SJlh3JOz8Y/elcV2l7XNg3R4s8kTzD+bGxNPsHNM41n+BcXrN02ldK+gEz57mxvpR8P5M0+zw2Dy+QBLozz+vu6BRLaNU4+e918TPYXh/0rGXyudNzz7Nw3WVIH0EHeOok1ycfXhP6HpuEEvah6JQ0+eAX5Px80NJJdNHkqQHcFGQJDUXBUlSc1GQJLXNG820mUV/1p+GpxsutPEX935gQyhtQFa9U14AGnZc4ilSmYs4jBtIecMyH8s9P2CjDJ5P2rSahAb+7VWz7ZuN9BzO8Ny+PuVyK+l/by7wLG/LcLMR/99p/fxpg+9y394Ipqrq5WVdLuLtkjd36T073WyMTw1DIKPhOPcjPidV75SFgHPJc0OwYbgBfQ9XeqVaGePPz/qKaJPdjWZJ0kO4KEiSmouCJKm5KEiSmouCJKltTh9RIxxqQLIL45PyB1VVByhTsLttL5cwbRxzhAYsyQVSLI9Bcz+myU5K/dAc0yQDlZf4+uXLprH35lgggfPL8/Nq7A1SOXe4HuphcrvRe2J72QFKzrxRg5y3t9UYpakowUQplhscn5reTHMzE3tKxlFTI7iJVxoPTXYwLQn28H1Ar3m7bi/nwej9uR7HRkXj1/x3/lKQJDUXBUlSc1GQJDUXBUlSc1GQJLXN6aPLZZ2GqKraQ32iQ9i1nzZrIfMaPYO56XpSLacHvWZK/RwP+dFgIgtLUG1PfC2QStnv85Wez7kO0X/9h3+I46fT+pp+DTV+qqp++fZLHL8s+RxT0mRZchKIUlZ7aJp0vUJtoZA0oqQW1ai5XKDWVhinY7kODzT2oWY1qZHUg97l6RyxMRSkwOhMKH11C9dJpZwolMTJu+0NcigJdAvv2feO5yzYZI7f5i8FSVJzUZAkNRcFSVJzUZAkNRcFSVLbnD5KtViqqg6UKArpoyMkZ/Z7Gt+enDke86VM6y1RIiKdyrQuDKWsDmHyp6eneOwTXOfxmOemFMLL27qGEIVBqAPef/nHf4zjT6ecSvr5l3Wi6H/961/isdRNi2oi7cK9nYbUOCWSzyWltRZIR12gZhOlklKXNa5xlGFNIOrWFY6n9A3mY+CeH8PzgbAXd3Wj1BTcl/Q88T0B3dGuN0p80TzxROKhKb1GU3z/D5Necr+fvxQkSc1FQZLUXBQkSc1FQZLUNm80p42vqnc2T8OfcN9utEmaX/PLU96wTKU1aKMZSxrQBvlgY5pKLry+5tINtCG2C2vznUpOnOEeDpoDfX/N9fWcj/k1qZzFV9gMp43ZXagx8PR0Gs1Bz21SXmDBZjVUX2F7yQB6xpPN0Kq8cU7XvsC9ok1iDFnEQfo8xGEOdgxG71CLAvtIQRAi39vt5Sm+gxedbPrSdw38P/n9DoGCsBn+kXIWxF8KkqTmoiBJai4KkqTmoiBJai4KkqS2OX1EUkqiKqcQqGHH6ZyTMz/96UscT80zJgmRKgwsYKpiuawTAa+vufTHAs1QUhmBqqprTFPle3KBhi903k9nKJfxlObPk9C5UJKDEl8/ff26GnuFVNvPf/01jlMZidTUiRI/lD6ixBO9tdJ1YvqI5sZ7uB5LTYqqqs7w8Ok1yT2klagUAzVvok9hurepMdKPF81zY20JOJf7+jnf8RnPynnw900Y382eA17lLpVyeXzDMX8pSJKai4IkqbkoSJKai4IkqbkoSJLa5vQR1rOBtMVhv56aarcQbEwSEigQWMBUwQUSNSnFUlX1/PyynuMNkkCQvjlDLafzaV3/53TIjyYlRL7/Bxim2johtUDNdKY1hOj4lDS6QFKL6hBNagthcxysfQT1ibilzPrYSSqlOMWTanClml9VnEA5UsQOziWl+qgcFH1OFvgHr+GeQ4mjotAUZXjo+aRncYemOZQMvFONo0HYEfr3oAN89mOjr5BI+j7++1NJ/lKQJDUXBUlSc1GQJDUXBUlSc1GQJLXN6aNLqP1TxSVA0u43pY9eXnKnsteXXFsoJjymO/y7nJ6gJMNlWSdnKDny5Uuu2UTd0c6hps2sg1XVDc6bOuYdwrOgtA6j18wJj28hwfX6ms+PrhO7j4V0y9tbnvstPMuq33H94X2Yuuj9ODiO4nOOw7M3OaXgaJb0sbpC+obSOrfr9iQQzoGdxyjBBfWjwrnTE6anBmeCn7eEvifweLjOdI4YMvpARzZ/KUiSmouCJKm5KEiSmouCJKm5KEiS2ub0EdV0oXoxaVeckxZ5fKG5w9i0rhKeCyQ20quejlQrCBIbkG5JyaYrXM+X87pO0ntzL4Mkx2G/PR31fQqocfSWU2OXZX2OFJKg1BTVLUp1la7h9aq4IxndQ0rJpETRDu435po4vkf/Yn0ojcN7GbuMxVpBdK+oUxkW4VoNUee1OySYdnwXN+MqVlSIafv14DzDjnGUvlrCa1KXww+Ej/ylIEn6dy4KkqTmoiBJai4KkqT28SY70OQh/lk7bNrsoNsG/Xn48bTeED3AZg5tEtJ5H2HzOG0K0WY1veYbbMAuy/o1n6AhzwUap7zBBiyJDVjgeqhcxALvibfQBIks13ze0wY+qTQAPQcKMNC5pOYzVe8134kHj/5DnHu4eUj3Cst5hIAEzwFTwGZwCl9QSQwCH1nuYhO+b2ir+gAbtidoxjUpXEGNsWj/mUuIhLP//b10kL8UJEnNRUGS1FwUJEnNRUGS1FwUJElte/qI/jSe/gw8xBMOUP5hD+UVaOc/7bhTogTTKjsogYBVIUIJgHwoppL2EJ84h9IVmGyC2Af9ufvxkB/xLSS+7vDn9a/wmlTiZIHyEqn5ztsrJbIolQTnGMpcvEKznyukjO6QMrrB+zaWuYDnRuUiqNRDqlMwTfzQ8VTmI77HKdmDzXe2nws1kylKI9LnCkrCpPQiVw/J3zX7G32u4LspvCZV4MHnQ+/PVOYCzoPP77f5S0GS1FwUJEnNRUGS1FwUJEnNRUGS1Danj3766Uscv0DC4xgSRVdId9D46/01Hx+27SkExd0mhkVDQiKC6yflnf+vT09xPCVtFkgPYNICLofq+VyWlDTJc1DNKkof0XsiNc6h1NjbGzTTgTpMlzQ31oOC2AfcQ6rBdTiuPz7UYCk1Uqqqen7N4+kzQUk/Gr9hHaI4HMdn7WGqblTLKZ7j7LNJ6aNYx6tyrST8nMB75XKBmkjQeOoU0n503mSSsuLvg99fFMlfCpKk5qIgSWouCpKk5qIgSWouCpKktjl99BU6gVFNl0tIvVDK6EZ1bqAuzKwrFe3kQ20QqCGU6hZ9/bKuWVRV9XTO9+oAiaJUz+gC9+QYEi/f56CEENVRCcdSigVTY5A+wvH1PFTLiM6bkk3peEoCUTCDkhxneJ4pgULnd4HU1H4H6atrquUEnwcszbS9xtF3qUDRrI7XAesQrV/ziicOqT54TXh7Qi2rWRe0/bC74u24fs2UxKzi74NJ3TPq/sf1un6bvxQkSc1FQZLUXBQkSc1FQZLUXBQkSW1z+uj5+TmOXyg9EpJDN0ilUIoFUxJhc34HqYfDPl/iDlJG1CYpdTI6UM0VSARQHaIlpAqoIxelvSgNMeqyBekjesbpvN+bJ50jd+qi+kR57pQE4nJY+b9Q97rDMT/nlFb6Aim9M9TKofTVt2/f1scOn/3L8wu8Jt3z9blQyoiSWtQt8XBc31v6eFO3wCe4h88vuUbaS0h80bOnJNCJEkLwv9PpPUQ10uizSTcmfVYoZMQJs9/mLwVJUnNRkCQ1FwVJUnNRkCS1zRvNP//8lzhOpRHSbjBt5NFGzAlKOqRNZfrz+jvsJ9PG0qRpxeXyFo99e51t8tzDS9IG33r78ccc9BwGjXNoc2q6GUwbn7RJnlA5jzOMp5IWFGzg88vncs2Pue6H9T+g8innUx4/wuZpuk663ws08HmF8hypIVFV1VuY5wDvQ3qWV643s54bvg9gXx99/ZKbV51P6zI01HiIrpO+V6hExzUEB6jBEoUMltAAq4o+sxQkscyFJOkBXBQkSc1FQZLUXBQkSc1FQZLUNqePvv2a/2Se/po6lYCgZM+02URqfEFpFU4ZUfOdPL6Ehh2vWLbjEYkASMhgfxQqc0HzhCTD8DWxyQ40mkmezrlR0fGQn8PlAk2dwmsu0KiIrhP6MWECJSXEqMzD5ZX+/4sSealcQp4By3YMr+fLaZ1Wos8Pl6ah9/56jFJt1KTpFVJTk3tIz7j2w7IQMM8ufO8ddvm7ib6zqAxJfD04j5SC2spfCpKk5qIgSWouCpKk5qIgSWouCpKktjl9dIKUCCUZqJ5RPpaSQNsbedyosQ3UJ7pTQoh280OtF0p9YJMZrBU0mJua6WCzIziXkPCgJi6UpqL0yB5SFalhSaq3U1X19i0nh27XfD1v4fqxUQ8ETfAdS0mTEO85Q/ooJeaqZik4qodFNYSwiQucS6r/kxrvVL2TVMuvGN8rqZbPe3bwILBBTmq8NGg69eO/xFFqBJTOhb7H6NlTsit9p/L3wfYE4Oq8fve/lCT9P8dFQZLUXBQkSc1FQZLUXBQkSW1z+ug4roESxiH1kDqpVVXtU0uyqrqn2keh5kgV13+hyiDLlVIv639B6Q6ag5MP6zFKVFDaq6BW0B2vNNxDqP9yzMEz7owH9zylgaZd2t4gVbFcttd64decJb5qtx5/gYQQvQ8p2ZSSKUfo6gZvfZx8D//gmDoawsO8UuqFEnbh3lL65kgJLuzcGIdjcgoTXPB5o2dPr5nnoI55swTXLs2DNZjy9WzhLwVJUnNRkCQ1FwVJUnNRkCS1zRvNT095t/Fy2b55TJs2B9hAoyYUab8J/zQ8jnJpDdrluYQNTt5kn21Ynk7re5vGqqp++voljlMZhbQp//0/pCF4PrRpBdfz6/NzHH95eV2Nvb3lMhcXKNuRNvyrqq63QZMdfG5xGMsUpPcn5QCwLARubm8vOUGbwRQOSe/lqqqXQeMler9RKYr0eUuNuKqq7nCdFBCgt/hTKHNxPMLnhJoDwfOhkjBV6/dzatBVxeVjMHgTS5/MSn9s4S8FSVJzUZAkNRcFSVJzUZAkNRcFSVLbnD7CZjrQfGeJTU+g4UvlXfjX13VapSonGShNRDv5O2rKQ813QvKBXvMM94SyUOl4Sg9QGYFXSNTQn/XHigFwPZT6oFQOPee3yzqZ8e35JR77+pYTMnT9KT1CKRZOpOVxboSzvSzEDv7/i5o67UPZEkrrnM/Q8AXO5fUCpUKW9T28wPuK0jeUhkklOuh9hc2ehqm+JTRkOh3y9ZxOUFoD7jm+h8J74gskN+mzSQ3D0nWens7x2BPVptnAXwqSpOaiIElqLgqSpOaiIElqLgqSpLa7YwcRSdL/b/ylIElqLgqSpOaiIElqLgqSpOaiIElqLgqSpOaiIElqLgqSpOaiIElq/xuxrbcpsNgjJQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈꺼풀 구름입니다.\n",
            "단일한 선 모양입니다.\n",
            "날씨에 큰 영향을 미치지 않는 구름입니다.\n",
            "cloud.jpg의 예측되는 구름종류 : Cc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uk-OlLoG2qsK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMBrSPcVWZxSkMYPufzD7gq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
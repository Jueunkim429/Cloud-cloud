{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jueunkim429/Cloud-cloud/blob/main/CNN_Cloud_Cloud1%2C4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX70GOa1pgC3",
        "outputId": "c1090d0c-6a4e-41c3-d2d8-69e13c8cb1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libarchive-c\n",
            "  Downloading libarchive_c-4.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: libarchive-c\n",
            "Successfully installed libarchive-c-4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install libarchive-c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuEb_3v7pzfI",
        "outputId": "0d432247-afe4-45d5-a1c0-6d8ba8983f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.21.1.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.22.4)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.1)\n",
            "Collecting pyshp>=2.1 (from cartopy)\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyproj>=3.0.0 (from cartopy)\n",
            "  Downloading pyproj-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.0.0->cartopy) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1->cartopy) (1.16.0)\n",
            "Building wheels for collected packages: cartopy\n",
            "  Building wheel for cartopy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cartopy: filename=Cartopy-0.21.1-cp310-cp310-linux_x86_64.whl size=11102740 sha256=24f13a3202e26cc7acb96297d058c7fe4b6ba8b4a849410d08eca87c3bd1f27a\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/b0/1a/1c1909e00c76653dc4e2ff48555257c0eb2d1698280c8d9955\n",
            "Successfully built cartopy\n",
            "Installing collected packages: pyshp, pyproj, cartopy\n",
            "Successfully installed cartopy-0.21.1 pyproj-3.6.0 pyshp-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL3ulF7qqO5y",
        "outputId": "d1502821-d6df-47e0-a9de-9a807942828c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-DFi-fpqQ4O",
        "outputId": "c90d242d-c00d-4b33-b8ba-e0a2ca578363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I9WwjvTcpLa1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os, glob, numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.backend import set_session as K\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import libarchive\n",
        "import pydot\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCJ-nD6lq8i-",
        "outputId": "70cd9f49-0ac9-48fa-9115-cd57248a2068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "import tensorflow.keras\n",
        "print(tensorflow.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzqQpOpoq_JP",
        "outputId": "eda23294-e468-46a2-bbaf-5a9f3b2e9eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image를 학습데이터로 변환"
      ],
      "metadata": {
        "id": "77sU2UXKm0i6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKKuyIoTyzLT",
        "outputId": "413ed7a0-9208-45b7-ab68-a9d4a9fabdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N156_0_135.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N149_0_9394.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N159_0_3662.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N227_0_6095.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N027_0_1818.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N063_0_5104.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_Cb-N111_0_4797.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_0_626.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_0_8064.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_0_4888.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/Cb-N022.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_0_3624.jpg\n",
            "Cb  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cb/new_0_2134.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N115_0_8934.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N189_0_6331.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N202_0_8301.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N238_0_1209.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N069_0_1780.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N092_0_9730.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/new_Cc-N135_0_4105.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_2035.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_6701.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_8592.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_6614.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_2420.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_7542.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc_new_0_7491.jpg\n",
            "Cc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Cc/Cc-N213.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_4320.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_4343.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_116.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_3444.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_1542.jpg\n",
            "St  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/St/St_new_0_2862.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N163_0_2381.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N168_0_986.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N209_0_1848.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N253_0_9761.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N081_0_8185.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N111_0_3657.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/new_Ns-N145_0_747.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_4092.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_5344.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_1741.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_1574.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_6633.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_652.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns_new_0_8664.jpg\n",
            "Ns  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Ns/Ns-N205.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N124_0_8784.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N110_0_841.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N134_0_8642.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N192_0_3636.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_7719.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N017_0_221.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/new_Sc-N060_0_2134.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_9057.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_4403.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_5607.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc-N340.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_5077.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_6296.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc_new_0_3856.jpg\n",
            "Sc  :  /content/drive/MyDrive/Colab Notebooks/clouddata/train14/Sc/Sc-N213.jpg\n"
          ]
        }
      ],
      "source": [
        "img_dir =  \"/content/drive/MyDrive/Colab Notebooks/clouddata/train14\" #학습데이터로 변환할 데이터 위치\n",
        "categories = os.listdir(img_dir)\n",
        "num_classes = len(categories)\n",
        "\n",
        "image_w = 64  #64*64*3 사이즈로 조정\n",
        "image_h = 64\n",
        "\n",
        "pixel=  image_w * image_h * 3\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for idx, cat in enumerate(categories): # 카테고리를 enumerate를 이용하여 카테고리와 인덱스 사용\n",
        "    img_dir_detail = img_dir + '/' + cat\n",
        "    files = glob.glob(img_dir_detail + \"/*.jpg\")\n",
        "    for i,f in enumerate(files):\n",
        "        try:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('RGB')\n",
        "            img = img.resize((image_w,image_h)) #이미지의 사이즈를 조정\n",
        "            data = np.asarray(img)\n",
        "            X.append(data)\n",
        "            y.append(idx)\n",
        "            if i % 300 == 0 : # 300번 마다 프린트\n",
        "                print(cat, \" : \", f)\n",
        "        except:\n",
        "            print(cat,str(i),\" 번째에서 에러\")\n",
        "\n",
        "X = np.array(X)  #array로 변환\n",
        "y = np.array(y)  #array로 변환\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3) #train test 구분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4OsknnR0WDb"
      },
      "source": [
        "## 학습데이터 가공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uLDY5yh0ZXh",
        "outputId": "1f4dbdcb-d59a-4617-e80f-e4db71b170e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12846, 64, 64, 3)\n",
            "(12846,)\n",
            "(5506, 64, 64, 3)\n",
            "(5506,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape) # 데이터 크기 확인\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# img를 array로 변환시 0~255의 값을 가지는데 이것을 0~1로 변환\n",
        "X_train = X_train.astype(float) / 255.0\n",
        "X_test = X_test.astype(float) / 255.0\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "# 기존의 1의 값을가지는 y값을 [0,1,0,0,---]와 같이 변환\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCvW0wvM0d05"
      },
      "source": [
        "## 모델 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 1"
      ],
      "metadata": {
        "id": "1378HxWJBN5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4O4u7E_uz76B"
      },
      "outputs": [],
      "source": [
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model'\n",
        "    model_path = model_dir + \"/cloud_classify.model\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LtDJgVI05II",
        "outputId": "80e3ddc7-997f-4cf6-b0e1-2af54bbbe37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkP_irWDqdVS",
        "outputId": "0edd0925-f3f0-49ae-d9df-e0ccc4a9f787"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 14s 9ms/step - loss: 1.2605 - accuracy: 0.4951 - val_loss: 1.1239 - val_accuracy: 0.5829\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 1.0531 - accuracy: 0.5878 - val_loss: 0.9978 - val_accuracy: 0.6054\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.9433 - accuracy: 0.6360 - val_loss: 0.8657 - val_accuracy: 0.6677\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.8488 - accuracy: 0.6745 - val_loss: 0.7791 - val_accuracy: 0.7128\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.7417 - accuracy: 0.7214 - val_loss: 0.7304 - val_accuracy: 0.7152\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6619 - accuracy: 0.7497 - val_loss: 0.6245 - val_accuracy: 0.7712\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.5747 - accuracy: 0.7829 - val_loss: 0.5786 - val_accuracy: 0.7953\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.5305 - accuracy: 0.7965 - val_loss: 0.5799 - val_accuracy: 0.8016\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4753 - accuracy: 0.8220 - val_loss: 0.5562 - val_accuracy: 0.7969\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4319 - accuracy: 0.8399 - val_loss: 0.4755 - val_accuracy: 0.8319\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3759 - accuracy: 0.8592 - val_loss: 0.4570 - val_accuracy: 0.8444\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3488 - accuracy: 0.8736 - val_loss: 0.4785 - val_accuracy: 0.8366\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3210 - accuracy: 0.8818 - val_loss: 0.4519 - val_accuracy: 0.8490\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.3073 - accuracy: 0.8852 - val_loss: 0.4191 - val_accuracy: 0.8560\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2927 - accuracy: 0.8956 - val_loss: 0.4726 - val_accuracy: 0.8490\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2753 - accuracy: 0.8979 - val_loss: 0.4297 - val_accuracy: 0.8553\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2515 - accuracy: 0.9055 - val_loss: 0.4315 - val_accuracy: 0.8646\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2356 - accuracy: 0.9114 - val_loss: 0.5324 - val_accuracy: 0.8475\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2256 - accuracy: 0.9178 - val_loss: 0.4184 - val_accuracy: 0.8669\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2102 - accuracy: 0.9220 - val_loss: 0.3897 - val_accuracy: 0.8825\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2053 - accuracy: 0.9252 - val_loss: 0.4767 - val_accuracy: 0.8661\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1951 - accuracy: 0.9275 - val_loss: 0.4049 - val_accuracy: 0.8809\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2033 - accuracy: 0.9273 - val_loss: 0.3677 - val_accuracy: 0.8848\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1824 - accuracy: 0.9372 - val_loss: 0.3811 - val_accuracy: 0.8918\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1727 - accuracy: 0.9352 - val_loss: 0.4469 - val_accuracy: 0.8809\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1682 - accuracy: 0.9376 - val_loss: 0.4231 - val_accuracy: 0.8786\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1581 - accuracy: 0.9426 - val_loss: 0.4479 - val_accuracy: 0.8802\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1528 - accuracy: 0.9458 - val_loss: 0.4193 - val_accuracy: 0.8840\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1534 - accuracy: 0.9457 - val_loss: 0.4124 - val_accuracy: 0.8895\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1433 - accuracy: 0.9455 - val_loss: 0.4777 - val_accuracy: 0.8794\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1604 - accuracy: 0.9420 - val_loss: 0.4287 - val_accuracy: 0.8856\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1558 - accuracy: 0.9426 - val_loss: 0.4678 - val_accuracy: 0.8817\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1401 - accuracy: 0.9479 - val_loss: 0.6088 - val_accuracy: 0.8685\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1446 - accuracy: 0.9478 - val_loss: 0.5014 - val_accuracy: 0.8739\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1364 - accuracy: 0.9513 - val_loss: 0.4992 - val_accuracy: 0.8856\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1525 - accuracy: 0.9452 - val_loss: 0.4784 - val_accuracy: 0.8739\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1238 - accuracy: 0.9526 - val_loss: 0.4609 - val_accuracy: 0.8848\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1268 - accuracy: 0.9558 - val_loss: 0.4522 - val_accuracy: 0.8942\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1265 - accuracy: 0.9555 - val_loss: 0.4299 - val_accuracy: 0.8872\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1324 - accuracy: 0.9554 - val_loss: 0.4914 - val_accuracy: 0.8825\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1199 - accuracy: 0.9550 - val_loss: 0.4797 - val_accuracy: 0.9019\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1322 - accuracy: 0.9510 - val_loss: 0.5479 - val_accuracy: 0.8864\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1100 - accuracy: 0.9612 - val_loss: 0.5082 - val_accuracy: 0.8763\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1139 - accuracy: 0.9606 - val_loss: 0.4437 - val_accuracy: 0.8981\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1183 - accuracy: 0.9567 - val_loss: 0.4761 - val_accuracy: 0.8879\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1164 - accuracy: 0.9587 - val_loss: 0.5245 - val_accuracy: 0.8856\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1284 - accuracy: 0.9509 - val_loss: 0.5131 - val_accuracy: 0.8872\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0985 - accuracy: 0.9670 - val_loss: 0.5009 - val_accuracy: 0.8840\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1116 - accuracy: 0.9595 - val_loss: 0.5021 - val_accuracy: 0.8926\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 0.5202 - val_accuracy: 0.8856\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1062 - accuracy: 0.9613 - val_loss: 0.5109 - val_accuracy: 0.8887\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1070 - accuracy: 0.9632 - val_loss: 0.5011 - val_accuracy: 0.8926\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1139 - accuracy: 0.9622 - val_loss: 0.5861 - val_accuracy: 0.8794\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1033 - accuracy: 0.9617 - val_loss: 0.4784 - val_accuracy: 0.8965\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1038 - accuracy: 0.9638 - val_loss: 0.4927 - val_accuracy: 0.8918\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9644 - val_loss: 0.4671 - val_accuracy: 0.8981\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0975 - accuracy: 0.9646 - val_loss: 0.4626 - val_accuracy: 0.9043\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1057 - accuracy: 0.9641 - val_loss: 0.5565 - val_accuracy: 0.8988\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1095 - accuracy: 0.9625 - val_loss: 0.4972 - val_accuracy: 0.9019\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0931 - accuracy: 0.9671 - val_loss: 0.5033 - val_accuracy: 0.9004\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0911 - accuracy: 0.9690 - val_loss: 0.5168 - val_accuracy: 0.8942\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0942 - accuracy: 0.9668 - val_loss: 0.5764 - val_accuracy: 0.8988\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0955 - accuracy: 0.9663 - val_loss: 0.5417 - val_accuracy: 0.8934\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.5368 - val_accuracy: 0.8942\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1037 - accuracy: 0.9666 - val_loss: 0.5344 - val_accuracy: 0.8918\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0889 - accuracy: 0.9701 - val_loss: 0.4829 - val_accuracy: 0.8918\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0888 - accuracy: 0.9696 - val_loss: 0.5323 - val_accuracy: 0.9027\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0953 - accuracy: 0.9662 - val_loss: 0.4998 - val_accuracy: 0.8996\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0979 - accuracy: 0.9664 - val_loss: 0.5361 - val_accuracy: 0.9004\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9706 - val_loss: 0.4945 - val_accuracy: 0.9012\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0877 - accuracy: 0.9696 - val_loss: 0.5387 - val_accuracy: 0.8965\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0949 - accuracy: 0.9655 - val_loss: 0.5911 - val_accuracy: 0.8864\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0974 - accuracy: 0.9658 - val_loss: 0.5329 - val_accuracy: 0.8981\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0898 - accuracy: 0.9686 - val_loss: 0.5472 - val_accuracy: 0.8942\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0789 - accuracy: 0.9706 - val_loss: 0.5892 - val_accuracy: 0.8988\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0788 - accuracy: 0.9732 - val_loss: 0.5502 - val_accuracy: 0.8942\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0783 - accuracy: 0.9720 - val_loss: 0.5576 - val_accuracy: 0.9019\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0953 - accuracy: 0.9680 - val_loss: 0.6081 - val_accuracy: 0.8965\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9693 - val_loss: 0.6342 - val_accuracy: 0.8809\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.6175 - val_accuracy: 0.8934\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0823 - accuracy: 0.9728 - val_loss: 0.6100 - val_accuracy: 0.8864\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0836 - accuracy: 0.9723 - val_loss: 0.5986 - val_accuracy: 0.8872\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0774 - accuracy: 0.9731 - val_loss: 0.5699 - val_accuracy: 0.8973\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0768 - accuracy: 0.9721 - val_loss: 0.5579 - val_accuracy: 0.9043\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 0.5954 - val_accuracy: 0.8988\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0900 - accuracy: 0.9704 - val_loss: 0.5531 - val_accuracy: 0.8973\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9695 - val_loss: 0.5212 - val_accuracy: 0.9105\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0939 - accuracy: 0.9702 - val_loss: 0.5348 - val_accuracy: 0.9074\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0757 - accuracy: 0.9741 - val_loss: 0.5673 - val_accuracy: 0.8981\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0697 - accuracy: 0.9752 - val_loss: 0.5198 - val_accuracy: 0.9043\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0706 - accuracy: 0.9747 - val_loss: 0.6314 - val_accuracy: 0.9035\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0864 - accuracy: 0.9717 - val_loss: 0.5954 - val_accuracy: 0.9035\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0943 - accuracy: 0.9704 - val_loss: 0.5395 - val_accuracy: 0.8996\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0731 - accuracy: 0.9744 - val_loss: 0.6029 - val_accuracy: 0.8973\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.6199 - val_accuracy: 0.8949\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9756 - val_loss: 0.6011 - val_accuracy: 0.9012\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0819 - accuracy: 0.9734 - val_loss: 0.6077 - val_accuracy: 0.8981\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0789 - accuracy: 0.9728 - val_loss: 0.6242 - val_accuracy: 0.8918\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0841 - accuracy: 0.9696 - val_loss: 0.6413 - val_accuracy: 0.8926\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0800 - accuracy: 0.9734 - val_loss: 0.5265 - val_accuracy: 0.9097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"정확도 : %.2f\" %(model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sijwAwL_srAw",
        "outputId": "b6ab2641-8f31-4bee-d539-f61ce05f0854"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4782 - accuracy: 0.9134\n",
            "정확도 : 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3HIcRwbqugE",
        "outputId": "fa873b62-cb9c-4450-a8f0-2f29ecc1ceb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9296\n",
            "평균 손실: 0.1911\n",
            "평균 검증 정확도: 0.8720\n",
            "평균 검증 손실: 0.5358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2GzOWo31s5V"
      },
      "source": [
        "### model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d-4hviku1vTX"
      },
      "outputs": [],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model2 = Sequential()\n",
        "\n",
        "    model2.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model2.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(256, activation = 'relu'))\n",
        "    model2.add(Dropout(0.5))\n",
        "    model2.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model2'\n",
        "    model_path = model_dir + \"/cloud_classify.model2\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNdCALYSsyyL",
        "outputId": "7b6ee58c-fb7a-459a-c93c-822b5b0c1206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BJ2gUL9jtq0",
        "outputId": "b905ea78-1e36-4f89-a2f2-9dd9f2629182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 7s 11ms/step - loss: 1.2496 - accuracy: 0.4926 - val_loss: 1.1881 - val_accuracy: 0.5214\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0298 - accuracy: 0.5998 - val_loss: 1.0211 - val_accuracy: 0.5930\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8880 - accuracy: 0.6592 - val_loss: 0.7892 - val_accuracy: 0.7152\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7578 - accuracy: 0.7101 - val_loss: 0.7255 - val_accuracy: 0.7362\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6486 - accuracy: 0.7558 - val_loss: 0.6034 - val_accuracy: 0.7821\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5466 - accuracy: 0.7941 - val_loss: 0.5871 - val_accuracy: 0.7953\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4588 - accuracy: 0.8273 - val_loss: 0.5192 - val_accuracy: 0.7977\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4088 - accuracy: 0.8474 - val_loss: 0.3837 - val_accuracy: 0.8599\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3524 - accuracy: 0.8734 - val_loss: 0.3387 - val_accuracy: 0.8778\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3032 - accuracy: 0.8907 - val_loss: 0.3179 - val_accuracy: 0.8856\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2853 - accuracy: 0.8972 - val_loss: 0.2839 - val_accuracy: 0.8957\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2679 - accuracy: 0.9031 - val_loss: 0.3901 - val_accuracy: 0.8685\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2333 - accuracy: 0.9170 - val_loss: 0.3401 - val_accuracy: 0.8739\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2246 - accuracy: 0.9194 - val_loss: 0.3034 - val_accuracy: 0.8981\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1990 - accuracy: 0.9263 - val_loss: 0.2544 - val_accuracy: 0.9089\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2009 - accuracy: 0.9273 - val_loss: 0.3313 - val_accuracy: 0.8911\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2080 - accuracy: 0.9297 - val_loss: 0.2551 - val_accuracy: 0.9097\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1738 - accuracy: 0.9351 - val_loss: 0.2653 - val_accuracy: 0.9144\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1646 - accuracy: 0.9425 - val_loss: 0.2172 - val_accuracy: 0.9284\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1630 - accuracy: 0.9401 - val_loss: 0.3313 - val_accuracy: 0.8965\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1691 - accuracy: 0.9397 - val_loss: 0.2439 - val_accuracy: 0.9121\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1407 - accuracy: 0.9497 - val_loss: 0.2145 - val_accuracy: 0.9307\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1573 - accuracy: 0.9452 - val_loss: 0.2219 - val_accuracy: 0.9284\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1391 - accuracy: 0.9500 - val_loss: 0.2789 - val_accuracy: 0.9066\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1503 - accuracy: 0.9492 - val_loss: 0.3380 - val_accuracy: 0.8996\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1431 - accuracy: 0.9506 - val_loss: 0.2500 - val_accuracy: 0.9198\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1420 - accuracy: 0.9507 - val_loss: 0.2352 - val_accuracy: 0.9292\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1267 - accuracy: 0.9540 - val_loss: 0.2706 - val_accuracy: 0.9191\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1406 - accuracy: 0.9534 - val_loss: 0.3610 - val_accuracy: 0.8988\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1245 - accuracy: 0.9579 - val_loss: 0.3144 - val_accuracy: 0.9160\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1167 - accuracy: 0.9606 - val_loss: 0.2108 - val_accuracy: 0.9385\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1269 - accuracy: 0.9556 - val_loss: 0.3019 - val_accuracy: 0.9089\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1188 - accuracy: 0.9600 - val_loss: 0.2292 - val_accuracy: 0.9300\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1293 - accuracy: 0.9554 - val_loss: 0.2579 - val_accuracy: 0.9183\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1168 - accuracy: 0.9590 - val_loss: 0.2560 - val_accuracy: 0.9245\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1056 - accuracy: 0.9644 - val_loss: 0.2347 - val_accuracy: 0.9323\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1109 - accuracy: 0.9619 - val_loss: 0.2815 - val_accuracy: 0.9136\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1166 - accuracy: 0.9600 - val_loss: 0.1989 - val_accuracy: 0.9377\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 0.2420 - val_accuracy: 0.9331\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0940 - accuracy: 0.9661 - val_loss: 0.2264 - val_accuracy: 0.9323\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1149 - accuracy: 0.9624 - val_loss: 0.2807 - val_accuracy: 0.9144\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1114 - accuracy: 0.9617 - val_loss: 0.3153 - val_accuracy: 0.9183\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1221 - accuracy: 0.9576 - val_loss: 0.2107 - val_accuracy: 0.9409\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1013 - accuracy: 0.9653 - val_loss: 0.2660 - val_accuracy: 0.9245\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1033 - accuracy: 0.9655 - val_loss: 0.2285 - val_accuracy: 0.9300\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1006 - accuracy: 0.9651 - val_loss: 0.3054 - val_accuracy: 0.9191\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1009 - accuracy: 0.9664 - val_loss: 0.2675 - val_accuracy: 0.9167\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.2625 - val_accuracy: 0.9300\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0888 - accuracy: 0.9693 - val_loss: 0.2772 - val_accuracy: 0.9261\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1342 - accuracy: 0.9607 - val_loss: 0.2497 - val_accuracy: 0.9222\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1224 - accuracy: 0.9576 - val_loss: 0.2253 - val_accuracy: 0.9401\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0791 - accuracy: 0.9725 - val_loss: 0.2311 - val_accuracy: 0.9393\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0781 - accuracy: 0.9715 - val_loss: 0.3161 - val_accuracy: 0.9198\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0916 - accuracy: 0.9704 - val_loss: 0.2600 - val_accuracy: 0.9245\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0810 - accuracy: 0.9733 - val_loss: 0.2940 - val_accuracy: 0.9198\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0969 - accuracy: 0.9683 - val_loss: 0.2528 - val_accuracy: 0.9416\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1039 - accuracy: 0.9663 - val_loss: 0.2606 - val_accuracy: 0.9370\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0832 - accuracy: 0.9709 - val_loss: 0.3024 - val_accuracy: 0.9253\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0867 - accuracy: 0.9721 - val_loss: 0.3270 - val_accuracy: 0.9160\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0916 - accuracy: 0.9688 - val_loss: 0.2473 - val_accuracy: 0.9354\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0888 - accuracy: 0.9708 - val_loss: 0.3429 - val_accuracy: 0.9128\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0790 - accuracy: 0.9738 - val_loss: 0.2769 - val_accuracy: 0.9261\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0842 - accuracy: 0.9738 - val_loss: 0.2889 - val_accuracy: 0.9198\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0918 - accuracy: 0.9713 - val_loss: 0.2670 - val_accuracy: 0.9300\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0918 - accuracy: 0.9696 - val_loss: 0.2622 - val_accuracy: 0.9315\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0816 - accuracy: 0.9744 - val_loss: 0.2716 - val_accuracy: 0.9261\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.2967 - val_accuracy: 0.9253\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0835 - accuracy: 0.9723 - val_loss: 0.3291 - val_accuracy: 0.9206\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1060 - accuracy: 0.9696 - val_loss: 0.2618 - val_accuracy: 0.9346\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0980 - accuracy: 0.9690 - val_loss: 0.2866 - val_accuracy: 0.9315\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0725 - accuracy: 0.9755 - val_loss: 0.3040 - val_accuracy: 0.9323\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0893 - accuracy: 0.9722 - val_loss: 0.2871 - val_accuracy: 0.9292\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0780 - accuracy: 0.9741 - val_loss: 0.3556 - val_accuracy: 0.9261\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.3572 - val_accuracy: 0.9183\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0843 - accuracy: 0.9729 - val_loss: 0.3881 - val_accuracy: 0.9019\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0961 - accuracy: 0.9692 - val_loss: 0.2931 - val_accuracy: 0.9331\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 0.2669 - val_accuracy: 0.9447\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 0.3649 - val_accuracy: 0.9230\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.3030 - val_accuracy: 0.9315\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.3425 - val_accuracy: 0.9331\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.3186 - val_accuracy: 0.9268\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0858 - accuracy: 0.9732 - val_loss: 0.4360 - val_accuracy: 0.9105\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1117 - accuracy: 0.9673 - val_loss: 0.4093 - val_accuracy: 0.9121\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 0.3469 - val_accuracy: 0.9245\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0746 - accuracy: 0.9773 - val_loss: 0.3964 - val_accuracy: 0.9089\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.3828 - val_accuracy: 0.9206\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 0.3070 - val_accuracy: 0.9346\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0841 - accuracy: 0.9752 - val_loss: 0.3230 - val_accuracy: 0.9331\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0817 - accuracy: 0.9752 - val_loss: 0.3670 - val_accuracy: 0.9230\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0788 - accuracy: 0.9762 - val_loss: 0.2951 - val_accuracy: 0.9307\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0619 - accuracy: 0.9807 - val_loss: 0.4229 - val_accuracy: 0.9198\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.3225 - val_accuracy: 0.9331\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1007 - accuracy: 0.9699 - val_loss: 0.3223 - val_accuracy: 0.9362\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0835 - accuracy: 0.9746 - val_loss: 0.3440 - val_accuracy: 0.9230\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0664 - accuracy: 0.9779 - val_loss: 0.3006 - val_accuracy: 0.9385\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0778 - accuracy: 0.9742 - val_loss: 0.3885 - val_accuracy: 0.9268\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0759 - accuracy: 0.9747 - val_loss: 0.3845 - val_accuracy: 0.9245\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0750 - accuracy: 0.9774 - val_loss: 0.3520 - val_accuracy: 0.9268\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0766 - accuracy: 0.9769 - val_loss: 0.4423 - val_accuracy: 0.9183\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0684 - accuracy: 0.9789 - val_loss: 0.4968 - val_accuracy: 0.9097\n"
          ]
        }
      ],
      "source": [
        "history = model2.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "U8-w1hlI9W36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f65ec2b-13c7-4872-d79f-4e0d6b191197"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9411\n",
            "평균 손실: 0.1655\n",
            "평균 검증 정확도: 0.9053\n",
            "평균 검증 손실: 0.3350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2 + normalization"
      ],
      "metadata": {
        "id": "8zHgHkZt_zq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model3 = Sequential()\n",
        "\n",
        "    model3.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model3.add(BatchNormalization())\n",
        "    model3.add(Activation(\"relu\"))\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(256, activation='relu'))\n",
        "    model3.add(Dropout(0.5))\n",
        "    model3.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model3'\n",
        "    model_path = model_dir + \"/cloud_classify.model3\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "TGx9a-GNBjL-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akOKOhEQBmF1",
        "outputId": "3ba7361c-27e3-4f6f-e470-aef8f45a94b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64, 64, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,933\n",
            "Trainable params: 2,340,229\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yfVSjEQBolX",
        "outputId": "4c186c20-2e3c-4f71-994a-621eb7002b80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 9s 14ms/step - loss: 1.5092 - accuracy: 0.4250 - val_loss: 1.4872 - val_accuracy: 0.3805\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.2394 - accuracy: 0.4792 - val_loss: 1.1253 - val_accuracy: 0.5447\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.1663 - accuracy: 0.5144 - val_loss: 1.0938 - val_accuracy: 0.5463\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.1019 - accuracy: 0.5433 - val_loss: 1.1331 - val_accuracy: 0.5253\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.0438 - accuracy: 0.5814 - val_loss: 2.3188 - val_accuracy: 0.4070\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.0011 - accuracy: 0.5961 - val_loss: 0.9332 - val_accuracy: 0.6358\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.9585 - accuracy: 0.6250 - val_loss: 0.8713 - val_accuracy: 0.6825\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.9262 - accuracy: 0.6404 - val_loss: 1.0564 - val_accuracy: 0.6179\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.8870 - accuracy: 0.6499 - val_loss: 0.8060 - val_accuracy: 0.6856\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.8457 - accuracy: 0.6694 - val_loss: 0.9357 - val_accuracy: 0.6747\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.8234 - accuracy: 0.6840 - val_loss: 0.7702 - val_accuracy: 0.7144\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.7716 - accuracy: 0.7009 - val_loss: 2.0335 - val_accuracy: 0.5549\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.7668 - accuracy: 0.7036 - val_loss: 0.9340 - val_accuracy: 0.6685\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.7229 - accuracy: 0.7210 - val_loss: 1.1214 - val_accuracy: 0.6591\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6891 - accuracy: 0.7313 - val_loss: 0.6690 - val_accuracy: 0.7619\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6678 - accuracy: 0.7466 - val_loss: 1.7939 - val_accuracy: 0.5868\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6387 - accuracy: 0.7580 - val_loss: 1.1873 - val_accuracy: 0.6389\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6191 - accuracy: 0.7703 - val_loss: 0.5175 - val_accuracy: 0.8179\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5844 - accuracy: 0.7787 - val_loss: 0.5057 - val_accuracy: 0.8101\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5723 - accuracy: 0.7831 - val_loss: 0.5940 - val_accuracy: 0.7868\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5481 - accuracy: 0.7954 - val_loss: 0.5841 - val_accuracy: 0.8016\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5473 - accuracy: 0.7918 - val_loss: 0.4599 - val_accuracy: 0.8381\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5175 - accuracy: 0.8062 - val_loss: 0.7675 - val_accuracy: 0.7634\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4922 - accuracy: 0.8143 - val_loss: 0.4551 - val_accuracy: 0.8420\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4966 - accuracy: 0.8123 - val_loss: 0.4297 - val_accuracy: 0.8506\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4629 - accuracy: 0.8246 - val_loss: 0.7022 - val_accuracy: 0.7658\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4543 - accuracy: 0.8304 - val_loss: 0.6033 - val_accuracy: 0.7868\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4398 - accuracy: 0.8370 - val_loss: 0.3850 - val_accuracy: 0.8739\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4164 - accuracy: 0.8476 - val_loss: 0.8707 - val_accuracy: 0.7743\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4059 - accuracy: 0.8497 - val_loss: 1.4894 - val_accuracy: 0.6957\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3911 - accuracy: 0.8536 - val_loss: 0.4150 - val_accuracy: 0.8459\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4038 - accuracy: 0.8496 - val_loss: 0.4352 - val_accuracy: 0.8615\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3601 - accuracy: 0.8687 - val_loss: 0.3608 - val_accuracy: 0.8693\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3552 - accuracy: 0.8703 - val_loss: 0.3414 - val_accuracy: 0.8786\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3424 - accuracy: 0.8771 - val_loss: 0.3029 - val_accuracy: 0.8872\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3360 - accuracy: 0.8775 - val_loss: 1.2649 - val_accuracy: 0.6747\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3065 - accuracy: 0.8878 - val_loss: 0.4779 - val_accuracy: 0.8576\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3071 - accuracy: 0.8894 - val_loss: 0.3812 - val_accuracy: 0.8794\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2837 - accuracy: 0.8959 - val_loss: 0.4019 - val_accuracy: 0.8584\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2789 - accuracy: 0.8996 - val_loss: 0.3163 - val_accuracy: 0.8833\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2751 - accuracy: 0.9009 - val_loss: 1.0563 - val_accuracy: 0.7665\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2589 - accuracy: 0.9067 - val_loss: 0.3227 - val_accuracy: 0.8786\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2419 - accuracy: 0.9126 - val_loss: 0.4559 - val_accuracy: 0.8607\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2326 - accuracy: 0.9186 - val_loss: 0.5324 - val_accuracy: 0.8482\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2313 - accuracy: 0.9155 - val_loss: 0.5090 - val_accuracy: 0.8459\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2298 - accuracy: 0.9194 - val_loss: 1.7989 - val_accuracy: 0.7214\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2242 - accuracy: 0.9185 - val_loss: 0.2717 - val_accuracy: 0.9097\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2176 - accuracy: 0.9204 - val_loss: 0.3774 - val_accuracy: 0.8825\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2135 - accuracy: 0.9254 - val_loss: 0.7443 - val_accuracy: 0.8350\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2054 - accuracy: 0.9252 - val_loss: 0.5512 - val_accuracy: 0.8545\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1978 - accuracy: 0.9259 - val_loss: 0.2996 - val_accuracy: 0.8996\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1898 - accuracy: 0.9309 - val_loss: 0.4953 - val_accuracy: 0.8623\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1893 - accuracy: 0.9331 - val_loss: 0.2982 - val_accuracy: 0.9051\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1821 - accuracy: 0.9342 - val_loss: 0.6602 - val_accuracy: 0.8381\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1718 - accuracy: 0.9392 - val_loss: 0.3119 - val_accuracy: 0.9074\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1722 - accuracy: 0.9360 - val_loss: 0.8544 - val_accuracy: 0.8296\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1700 - accuracy: 0.9396 - val_loss: 0.2518 - val_accuracy: 0.9128\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1502 - accuracy: 0.9448 - val_loss: 0.5594 - val_accuracy: 0.8716\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1534 - accuracy: 0.9464 - val_loss: 0.4538 - val_accuracy: 0.8685\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1432 - accuracy: 0.9454 - val_loss: 1.9264 - val_accuracy: 0.7658\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1337 - accuracy: 0.9510 - val_loss: 0.2966 - val_accuracy: 0.9105\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1364 - accuracy: 0.9516 - val_loss: 1.4885 - val_accuracy: 0.7868\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1406 - accuracy: 0.9497 - val_loss: 0.2062 - val_accuracy: 0.9292\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1284 - accuracy: 0.9517 - val_loss: 0.2083 - val_accuracy: 0.9339\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1318 - accuracy: 0.9549 - val_loss: 0.2354 - val_accuracy: 0.9198\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1198 - accuracy: 0.9560 - val_loss: 0.2673 - val_accuracy: 0.9183\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1234 - accuracy: 0.9542 - val_loss: 0.2012 - val_accuracy: 0.9284\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1173 - accuracy: 0.9561 - val_loss: 0.2006 - val_accuracy: 0.9300\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1219 - accuracy: 0.9548 - val_loss: 0.2098 - val_accuracy: 0.9331\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1035 - accuracy: 0.9632 - val_loss: 0.2842 - val_accuracy: 0.9144\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1105 - accuracy: 0.9603 - val_loss: 3.5529 - val_accuracy: 0.6669\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1087 - accuracy: 0.9593 - val_loss: 0.2206 - val_accuracy: 0.9307\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0990 - accuracy: 0.9642 - val_loss: 0.2880 - val_accuracy: 0.9268\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1098 - accuracy: 0.9579 - val_loss: 0.1918 - val_accuracy: 0.9339\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0998 - accuracy: 0.9623 - val_loss: 0.1711 - val_accuracy: 0.9479\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1070 - accuracy: 0.9642 - val_loss: 0.4014 - val_accuracy: 0.8981\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0953 - accuracy: 0.9642 - val_loss: 0.4238 - val_accuracy: 0.8895\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0935 - accuracy: 0.9670 - val_loss: 0.1953 - val_accuracy: 0.9385\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0915 - accuracy: 0.9664 - val_loss: 0.2477 - val_accuracy: 0.9230\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0932 - accuracy: 0.9658 - val_loss: 2.6289 - val_accuracy: 0.6848\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0877 - accuracy: 0.9686 - val_loss: 0.2573 - val_accuracy: 0.9268\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0945 - accuracy: 0.9667 - val_loss: 0.3090 - val_accuracy: 0.9097\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0834 - accuracy: 0.9693 - val_loss: 0.1648 - val_accuracy: 0.9518\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0866 - accuracy: 0.9706 - val_loss: 0.2463 - val_accuracy: 0.9393\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 5s 12ms/step - loss: 0.0847 - accuracy: 0.9675 - val_loss: 0.2277 - val_accuracy: 0.9346\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.1896 - val_accuracy: 0.9370\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 0.3047 - val_accuracy: 0.9237\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0709 - accuracy: 0.9740 - val_loss: 0.1453 - val_accuracy: 0.9541\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0709 - accuracy: 0.9741 - val_loss: 0.3039 - val_accuracy: 0.9261\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0799 - accuracy: 0.9715 - val_loss: 0.2078 - val_accuracy: 0.9315\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0756 - accuracy: 0.9715 - val_loss: 0.2312 - val_accuracy: 0.9362\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 0.3630 - val_accuracy: 0.9074\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0689 - accuracy: 0.9734 - val_loss: 1.3096 - val_accuracy: 0.7837\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0840 - accuracy: 0.9721 - val_loss: 0.3431 - val_accuracy: 0.9089\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0716 - accuracy: 0.9731 - val_loss: 0.2481 - val_accuracy: 0.9385\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0652 - accuracy: 0.9760 - val_loss: 0.1763 - val_accuracy: 0.9447\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 0.4154 - val_accuracy: 0.8872\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.9925 - val_accuracy: 0.8420\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0702 - accuracy: 0.9745 - val_loss: 0.2109 - val_accuracy: 0.9354\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0686 - accuracy: 0.9741 - val_loss: 0.2683 - val_accuracy: 0.9300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reHN-FkVGn7-",
        "outputId": "db6c07aa-fc48-4c2c-db18-b499ee712919"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8723\n",
            "평균 손실: 0.3353\n",
            "평균 검증 정확도: 0.8244\n",
            "평균 검증 손실: 0.6490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1 + **normalization**"
      ],
      "metadata": {
        "id": "n2STjUPnIgB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# 모델 구성\n",
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(image_w, image_h, 3), activation=\"relu\"))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model4.add(Dropout(0.25))\n",
        "\n",
        "model4.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model4.add(Dropout(0.25))\n",
        "\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(256, activation='relu'))\n",
        "model4.add(Dropout(0.5))\n",
        "model4.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_dir = './model4'\n",
        "model_path = model_dir + \"/cloud_classify.model4\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "Chv4_PoxIibb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbtYdLSII-8_",
        "outputId": "25aa4242-4d56-4298-dac9-d554a7fe423f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,621\n",
            "Trainable params: 4,215,429\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model4.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p1_8OKIJApk",
        "outputId": "791ece9a-9b9a-4eeb-9150-242fc811ece4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 6s 10ms/step - loss: 1.7254 - accuracy: 0.4519 - val_loss: 9.7820 - val_accuracy: 0.1798\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2025 - accuracy: 0.5099 - val_loss: 1.0629 - val_accuracy: 0.5774\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 1.1288 - accuracy: 0.5429 - val_loss: 1.0645 - val_accuracy: 0.5759\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0797 - accuracy: 0.5655 - val_loss: 0.9787 - val_accuracy: 0.6117\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0428 - accuracy: 0.5807 - val_loss: 0.9140 - val_accuracy: 0.6304\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.9802 - accuracy: 0.6088 - val_loss: 1.1113 - val_accuracy: 0.5914\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.9594 - accuracy: 0.6142 - val_loss: 0.8531 - val_accuracy: 0.6584\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9000 - accuracy: 0.6371 - val_loss: 0.8488 - val_accuracy: 0.6817\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9042 - accuracy: 0.6470 - val_loss: 1.0379 - val_accuracy: 0.6327\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.8448 - accuracy: 0.6650 - val_loss: 0.9599 - val_accuracy: 0.6545\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8240 - accuracy: 0.6776 - val_loss: 0.8878 - val_accuracy: 0.6809\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7938 - accuracy: 0.6875 - val_loss: 0.8078 - val_accuracy: 0.7230\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.7612 - accuracy: 0.6999 - val_loss: 0.7360 - val_accuracy: 0.7276\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.7474 - accuracy: 0.7118 - val_loss: 0.6642 - val_accuracy: 0.7673\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7181 - accuracy: 0.7249 - val_loss: 0.8535 - val_accuracy: 0.7261\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6938 - accuracy: 0.7297 - val_loss: 0.8023 - val_accuracy: 0.7128\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.6653 - accuracy: 0.7445 - val_loss: 0.7712 - val_accuracy: 0.7479\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.6628 - accuracy: 0.7463 - val_loss: 0.9164 - val_accuracy: 0.7222\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.6361 - accuracy: 0.7569 - val_loss: 1.1309 - val_accuracy: 0.6809\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6148 - accuracy: 0.7601 - val_loss: 0.6748 - val_accuracy: 0.7712\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.6226 - accuracy: 0.7634 - val_loss: 0.6011 - val_accuracy: 0.7899\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.5937 - accuracy: 0.7743 - val_loss: 0.6380 - val_accuracy: 0.7798\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5792 - accuracy: 0.7782 - val_loss: 1.1706 - val_accuracy: 0.6677\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5666 - accuracy: 0.7812 - val_loss: 0.9791 - val_accuracy: 0.7043\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.5395 - accuracy: 0.7881 - val_loss: 0.5966 - val_accuracy: 0.7860\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5491 - accuracy: 0.7963 - val_loss: 0.7650 - val_accuracy: 0.7837\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5325 - accuracy: 0.7983 - val_loss: 0.9885 - val_accuracy: 0.7183\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.5235 - accuracy: 0.8069 - val_loss: 1.1618 - val_accuracy: 0.6895\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4959 - accuracy: 0.8096 - val_loss: 0.4901 - val_accuracy: 0.8249\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4772 - accuracy: 0.8118 - val_loss: 0.9947 - val_accuracy: 0.7245\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4990 - accuracy: 0.8137 - val_loss: 0.5084 - val_accuracy: 0.8241\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4703 - accuracy: 0.8158 - val_loss: 0.5631 - val_accuracy: 0.8148\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4848 - accuracy: 0.8207 - val_loss: 0.5199 - val_accuracy: 0.8374\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4645 - accuracy: 0.8248 - val_loss: 0.5410 - val_accuracy: 0.8350\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4413 - accuracy: 0.8319 - val_loss: 0.6779 - val_accuracy: 0.7899\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.4477 - accuracy: 0.8335 - val_loss: 0.6022 - val_accuracy: 0.8008\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4390 - accuracy: 0.8363 - val_loss: 0.5150 - val_accuracy: 0.8389\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4228 - accuracy: 0.8416 - val_loss: 0.7971 - val_accuracy: 0.7393\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4341 - accuracy: 0.8344 - val_loss: 1.2780 - val_accuracy: 0.6669\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4232 - accuracy: 0.8356 - val_loss: 0.4844 - val_accuracy: 0.8436\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4113 - accuracy: 0.8428 - val_loss: 0.7423 - val_accuracy: 0.7735\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4037 - accuracy: 0.8468 - val_loss: 0.7461 - val_accuracy: 0.7782\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4077 - accuracy: 0.8459 - val_loss: 0.6043 - val_accuracy: 0.7798\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4078 - accuracy: 0.8455 - val_loss: 0.6604 - val_accuracy: 0.8008\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3777 - accuracy: 0.8545 - val_loss: 0.6408 - val_accuracy: 0.8179\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3803 - accuracy: 0.8595 - val_loss: 0.5305 - val_accuracy: 0.8140\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.3934 - accuracy: 0.8505 - val_loss: 0.4755 - val_accuracy: 0.8521\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3744 - accuracy: 0.8545 - val_loss: 0.4979 - val_accuracy: 0.8584\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3771 - accuracy: 0.8568 - val_loss: 0.5435 - val_accuracy: 0.8412\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3687 - accuracy: 0.8652 - val_loss: 0.5385 - val_accuracy: 0.8467\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.3630 - accuracy: 0.8611 - val_loss: 0.6172 - val_accuracy: 0.8366\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3658 - accuracy: 0.8621 - val_loss: 0.5340 - val_accuracy: 0.8506\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3551 - accuracy: 0.8645 - val_loss: 0.6673 - val_accuracy: 0.8031\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3357 - accuracy: 0.8702 - val_loss: 1.1106 - val_accuracy: 0.7603\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3446 - accuracy: 0.8665 - val_loss: 0.5940 - val_accuracy: 0.8514\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3407 - accuracy: 0.8704 - val_loss: 0.7775 - val_accuracy: 0.8265\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3330 - accuracy: 0.8748 - val_loss: 0.4230 - val_accuracy: 0.8638\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3351 - accuracy: 0.8745 - val_loss: 0.7122 - val_accuracy: 0.8233\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3345 - accuracy: 0.8746 - val_loss: 0.4573 - val_accuracy: 0.8654\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3308 - accuracy: 0.8790 - val_loss: 0.9385 - val_accuracy: 0.7946\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3153 - accuracy: 0.8814 - val_loss: 0.8779 - val_accuracy: 0.7790\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.3230 - accuracy: 0.8815 - val_loss: 0.5567 - val_accuracy: 0.8514\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3175 - accuracy: 0.8805 - val_loss: 1.2425 - val_accuracy: 0.7588\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3000 - accuracy: 0.8851 - val_loss: 0.5467 - val_accuracy: 0.8358\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2972 - accuracy: 0.8879 - val_loss: 0.8204 - val_accuracy: 0.8062\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3065 - accuracy: 0.8850 - val_loss: 1.0330 - val_accuracy: 0.7541\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2812 - accuracy: 0.8887 - val_loss: 0.6206 - val_accuracy: 0.8498\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3147 - accuracy: 0.8857 - val_loss: 0.5811 - val_accuracy: 0.8358\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2946 - accuracy: 0.8887 - val_loss: 0.5887 - val_accuracy: 0.8311\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2937 - accuracy: 0.8926 - val_loss: 0.4905 - val_accuracy: 0.8553\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2833 - accuracy: 0.8959 - val_loss: 0.4827 - val_accuracy: 0.8568\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2688 - accuracy: 0.8958 - val_loss: 0.5474 - val_accuracy: 0.8521\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2854 - accuracy: 0.8971 - val_loss: 0.5623 - val_accuracy: 0.8529\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2793 - accuracy: 0.8965 - val_loss: 0.5820 - val_accuracy: 0.8568\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2900 - accuracy: 0.8947 - val_loss: 0.7761 - val_accuracy: 0.8304\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2770 - accuracy: 0.8977 - val_loss: 0.6398 - val_accuracy: 0.8537\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2703 - accuracy: 0.8979 - val_loss: 0.7056 - val_accuracy: 0.8319\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2799 - accuracy: 0.8955 - val_loss: 0.9031 - val_accuracy: 0.8109\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2615 - accuracy: 0.9020 - val_loss: 0.7345 - val_accuracy: 0.8249\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2697 - accuracy: 0.8997 - val_loss: 0.6335 - val_accuracy: 0.8506\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2640 - accuracy: 0.9008 - val_loss: 0.9766 - val_accuracy: 0.7938\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2743 - accuracy: 0.8992 - val_loss: 0.8229 - val_accuracy: 0.8047\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2532 - accuracy: 0.9031 - val_loss: 1.0680 - val_accuracy: 0.7860\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2659 - accuracy: 0.9032 - val_loss: 0.6287 - val_accuracy: 0.8366\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2659 - accuracy: 0.9036 - val_loss: 0.8934 - val_accuracy: 0.7844\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2639 - accuracy: 0.9027 - val_loss: 1.0757 - val_accuracy: 0.8171\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2430 - accuracy: 0.9078 - val_loss: 0.4542 - val_accuracy: 0.8661\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2357 - accuracy: 0.9144 - val_loss: 1.0399 - val_accuracy: 0.8031\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2348 - accuracy: 0.9118 - val_loss: 1.1690 - val_accuracy: 0.7891\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2479 - accuracy: 0.9101 - val_loss: 0.5374 - val_accuracy: 0.8786\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2348 - accuracy: 0.9114 - val_loss: 0.7331 - val_accuracy: 0.8280\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2375 - accuracy: 0.9141 - val_loss: 0.6243 - val_accuracy: 0.8537\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2334 - accuracy: 0.9152 - val_loss: 0.4514 - val_accuracy: 0.8786\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2249 - accuracy: 0.9158 - val_loss: 0.4993 - val_accuracy: 0.8677\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2434 - accuracy: 0.9111 - val_loss: 0.5332 - val_accuracy: 0.8584\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2429 - accuracy: 0.9126 - val_loss: 0.6447 - val_accuracy: 0.8537\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2287 - accuracy: 0.9147 - val_loss: 0.5002 - val_accuracy: 0.8802\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2321 - accuracy: 0.9148 - val_loss: 0.9497 - val_accuracy: 0.8195\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.2186 - accuracy: 0.9198 - val_loss: 1.1163 - val_accuracy: 0.7992\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2194 - accuracy: 0.9186 - val_loss: 4.3587 - val_accuracy: 0.7704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefoqD45JFoJ",
        "outputId": "0dd7ff75-646e-4b34-e586-0a09606c2218"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8251\n",
            "평균 손실: 0.4591\n",
            "평균 검증 정확도: 0.7810\n",
            "평균 검증 손실: 0.8754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+RMSprop"
      ],
      "metadata": {
        "id": "2SkPIxqdL99g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model5 = Sequential()\n",
        "\n",
        "    model5.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model5.add(Dropout(0.25))\n",
        "\n",
        "    model5.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model5.add(Dropout(0.25))\n",
        "\n",
        "    model5.add(Flatten())\n",
        "    model5.add(Dense(256, activation='relu'))\n",
        "    model5.add(Dropout(0.5))\n",
        "    model5.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model5.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model5'\n",
        "    model_path = model_dir + \"/cloud_classify.model5\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "_B6LYmkfMCnv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DllLhFeKMWp9",
        "outputId": "3f695d20-e01b-479b-fe3d-ee835e51b495"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model5.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drPWYEMkMYLp",
        "outputId": "8d146534-b487-4948-f923-a445fcb83c6b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 4s 8ms/step - loss: 1.2792 - accuracy: 0.4987 - val_loss: 1.1738 - val_accuracy: 0.5696\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 1.0379 - accuracy: 0.6000 - val_loss: 1.0414 - val_accuracy: 0.5837\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.9293 - accuracy: 0.6476 - val_loss: 0.9588 - val_accuracy: 0.6374\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.8309 - accuracy: 0.6796 - val_loss: 0.8449 - val_accuracy: 0.6848\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.7458 - accuracy: 0.7153 - val_loss: 0.8210 - val_accuracy: 0.7206\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6645 - accuracy: 0.7522 - val_loss: 0.6972 - val_accuracy: 0.7572\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6002 - accuracy: 0.7810 - val_loss: 0.8196 - val_accuracy: 0.6918\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.5530 - accuracy: 0.8035 - val_loss: 0.5498 - val_accuracy: 0.8210\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4940 - accuracy: 0.8197 - val_loss: 0.5844 - val_accuracy: 0.8023\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4641 - accuracy: 0.8343 - val_loss: 0.5621 - val_accuracy: 0.8241\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4342 - accuracy: 0.8499 - val_loss: 0.5836 - val_accuracy: 0.7837\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3969 - accuracy: 0.8599 - val_loss: 0.7124 - val_accuracy: 0.7626\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8671 - val_loss: 0.5550 - val_accuracy: 0.8101\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3698 - accuracy: 0.8721 - val_loss: 0.5001 - val_accuracy: 0.8451\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3422 - accuracy: 0.8830 - val_loss: 0.3989 - val_accuracy: 0.8685\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3436 - accuracy: 0.8857 - val_loss: 0.4798 - val_accuracy: 0.8397\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3341 - accuracy: 0.8857 - val_loss: 0.4771 - val_accuracy: 0.8498\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3359 - accuracy: 0.8875 - val_loss: 0.4162 - val_accuracy: 0.8677\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3109 - accuracy: 0.8941 - val_loss: 0.3625 - val_accuracy: 0.8911\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3191 - accuracy: 0.8991 - val_loss: 0.5691 - val_accuracy: 0.8148\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2952 - accuracy: 0.9017 - val_loss: 0.4292 - val_accuracy: 0.8700\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2992 - accuracy: 0.9040 - val_loss: 0.4387 - val_accuracy: 0.8856\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2937 - accuracy: 0.9048 - val_loss: 0.5174 - val_accuracy: 0.8405\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2766 - accuracy: 0.9120 - val_loss: 0.5278 - val_accuracy: 0.8327\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2858 - accuracy: 0.9029 - val_loss: 0.4895 - val_accuracy: 0.8576\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2707 - accuracy: 0.9131 - val_loss: 0.4341 - val_accuracy: 0.8708\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2789 - accuracy: 0.9109 - val_loss: 0.5604 - val_accuracy: 0.8475\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2765 - accuracy: 0.9099 - val_loss: 0.4032 - val_accuracy: 0.8825\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2480 - accuracy: 0.9209 - val_loss: 0.4583 - val_accuracy: 0.8809\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2668 - accuracy: 0.9202 - val_loss: 0.3961 - val_accuracy: 0.8755\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2560 - accuracy: 0.9181 - val_loss: 0.4982 - val_accuracy: 0.8420\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2540 - accuracy: 0.9199 - val_loss: 0.4841 - val_accuracy: 0.8607\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2583 - accuracy: 0.9177 - val_loss: 0.4238 - val_accuracy: 0.8755\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2466 - accuracy: 0.9234 - val_loss: 0.4217 - val_accuracy: 0.8833\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2478 - accuracy: 0.9247 - val_loss: 0.5169 - val_accuracy: 0.8514\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2361 - accuracy: 0.9273 - val_loss: 0.4789 - val_accuracy: 0.8661\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2384 - accuracy: 0.9272 - val_loss: 0.3795 - val_accuracy: 0.8856\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2540 - accuracy: 0.9207 - val_loss: 0.5226 - val_accuracy: 0.8654\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2513 - accuracy: 0.9266 - val_loss: 0.4995 - val_accuracy: 0.8389\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2488 - accuracy: 0.9247 - val_loss: 0.5305 - val_accuracy: 0.8669\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2403 - accuracy: 0.9266 - val_loss: 0.5392 - val_accuracy: 0.8241\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2436 - accuracy: 0.9282 - val_loss: 0.4657 - val_accuracy: 0.8623\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2387 - accuracy: 0.9304 - val_loss: 0.4251 - val_accuracy: 0.8942\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2320 - accuracy: 0.9273 - val_loss: 0.4107 - val_accuracy: 0.8926\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2198 - accuracy: 0.9285 - val_loss: 0.4071 - val_accuracy: 0.8770\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2269 - accuracy: 0.9303 - val_loss: 0.4361 - val_accuracy: 0.8794\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2095 - accuracy: 0.9349 - val_loss: 0.4432 - val_accuracy: 0.8848\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2221 - accuracy: 0.9319 - val_loss: 0.4224 - val_accuracy: 0.8770\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2175 - accuracy: 0.9352 - val_loss: 0.3981 - val_accuracy: 0.8934\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2220 - accuracy: 0.9354 - val_loss: 0.5104 - val_accuracy: 0.8646\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2242 - accuracy: 0.9358 - val_loss: 0.5492 - val_accuracy: 0.8700\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2190 - accuracy: 0.9342 - val_loss: 0.4824 - val_accuracy: 0.8654\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2203 - accuracy: 0.9369 - val_loss: 0.4825 - val_accuracy: 0.8840\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2188 - accuracy: 0.9362 - val_loss: 0.4944 - val_accuracy: 0.8685\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2204 - accuracy: 0.9369 - val_loss: 0.6314 - val_accuracy: 0.7969\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2161 - accuracy: 0.9372 - val_loss: 0.4260 - val_accuracy: 0.8739\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2194 - accuracy: 0.9362 - val_loss: 0.4546 - val_accuracy: 0.8802\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2065 - accuracy: 0.9382 - val_loss: 0.5295 - val_accuracy: 0.8716\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2011 - accuracy: 0.9365 - val_loss: 0.3829 - val_accuracy: 0.8996\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2047 - accuracy: 0.9413 - val_loss: 0.4469 - val_accuracy: 0.8926\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2012 - accuracy: 0.9421 - val_loss: 0.4439 - val_accuracy: 0.8669\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2112 - accuracy: 0.9388 - val_loss: 0.4242 - val_accuracy: 0.8739\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2080 - accuracy: 0.9427 - val_loss: 0.4028 - val_accuracy: 0.8903\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1982 - accuracy: 0.9441 - val_loss: 0.5479 - val_accuracy: 0.8560\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9419 - val_loss: 0.4368 - val_accuracy: 0.8802\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2151 - accuracy: 0.9399 - val_loss: 0.8702 - val_accuracy: 0.8545\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1898 - accuracy: 0.9473 - val_loss: 0.6045 - val_accuracy: 0.8864\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2076 - accuracy: 0.9423 - val_loss: 0.4638 - val_accuracy: 0.8537\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2134 - accuracy: 0.9431 - val_loss: 0.5320 - val_accuracy: 0.8778\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2015 - accuracy: 0.9434 - val_loss: 0.7766 - val_accuracy: 0.8700\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1867 - accuracy: 0.9491 - val_loss: 0.4811 - val_accuracy: 0.8786\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1942 - accuracy: 0.9459 - val_loss: 0.6268 - val_accuracy: 0.8747\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1858 - accuracy: 0.9472 - val_loss: 0.7004 - val_accuracy: 0.8809\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2034 - accuracy: 0.9491 - val_loss: 0.4468 - val_accuracy: 0.8677\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1871 - accuracy: 0.9486 - val_loss: 0.6404 - val_accuracy: 0.8669\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1870 - accuracy: 0.9492 - val_loss: 0.5854 - val_accuracy: 0.8661\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1876 - accuracy: 0.9497 - val_loss: 0.4913 - val_accuracy: 0.8879\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1992 - accuracy: 0.9492 - val_loss: 0.4541 - val_accuracy: 0.8934\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1838 - accuracy: 0.9501 - val_loss: 0.5048 - val_accuracy: 0.8537\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1914 - accuracy: 0.9484 - val_loss: 0.5783 - val_accuracy: 0.8903\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1981 - accuracy: 0.9491 - val_loss: 0.5662 - val_accuracy: 0.8903\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1897 - accuracy: 0.9517 - val_loss: 0.4824 - val_accuracy: 0.8872\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1860 - accuracy: 0.9519 - val_loss: 0.5896 - val_accuracy: 0.8794\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1674 - accuracy: 0.9558 - val_loss: 0.5725 - val_accuracy: 0.8981\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1772 - accuracy: 0.9536 - val_loss: 0.4917 - val_accuracy: 0.8918\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1709 - accuracy: 0.9551 - val_loss: 0.5017 - val_accuracy: 0.8693\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1889 - accuracy: 0.9527 - val_loss: 0.5672 - val_accuracy: 0.8934\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1776 - accuracy: 0.9550 - val_loss: 0.5521 - val_accuracy: 0.8949\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1709 - accuracy: 0.9546 - val_loss: 0.5991 - val_accuracy: 0.8669\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1934 - accuracy: 0.9528 - val_loss: 0.5963 - val_accuracy: 0.8965\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1657 - accuracy: 0.9569 - val_loss: 0.6451 - val_accuracy: 0.8607\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1853 - accuracy: 0.9546 - val_loss: 0.5447 - val_accuracy: 0.9012\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1846 - accuracy: 0.9542 - val_loss: 0.5007 - val_accuracy: 0.9027\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1720 - accuracy: 0.9569 - val_loss: 0.6912 - val_accuracy: 0.8739\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1780 - accuracy: 0.9533 - val_loss: 0.5600 - val_accuracy: 0.8973\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1782 - accuracy: 0.9570 - val_loss: 0.5876 - val_accuracy: 0.9019\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1738 - accuracy: 0.9560 - val_loss: 0.6182 - val_accuracy: 0.8794\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1620 - accuracy: 0.9600 - val_loss: 0.5900 - val_accuracy: 0.8988\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1754 - accuracy: 0.9585 - val_loss: 0.7733 - val_accuracy: 0.9105\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1596 - accuracy: 0.9583 - val_loss: 0.7389 - val_accuracy: 0.9074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvo6z1N4MaTd",
        "outputId": "4e97fe51-3833-4cae-90c0-b4f40646cb20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9093\n",
            "평균 손실: 0.2839\n",
            "평균 검증 정확도: 0.8543\n",
            "평균 검증 손실: 0.5464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+RMSprop"
      ],
      "metadata": {
        "id": "uvWR2W9PMnA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model6 = Sequential()\n",
        "\n",
        "    model6.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model6.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model6.add(Dropout(0.25))\n",
        "\n",
        "    model6.add(Flatten())\n",
        "    model6.add(Dense(256, activation = 'relu'))\n",
        "    model6.add(Dropout(0.5))\n",
        "    model6.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model6.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model6'\n",
        "    model_path = model_dir + \"/cloud_classify.model6\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)"
      ],
      "metadata": {
        "id": "LgEVBFJhMqkr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-SLSa8mM89l",
        "outputId": "9c2b694c-bb69-4080-9485-43898ba077f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model6.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ8I-o5TM-ep",
        "outputId": "b2b04e12-acf8-4d3a-c467-01dfc2c09305"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 5s 10ms/step - loss: 1.2927 - accuracy: 0.4733 - val_loss: 1.0834 - val_accuracy: 0.5658\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0584 - accuracy: 0.5899 - val_loss: 1.2193 - val_accuracy: 0.5268\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9320 - accuracy: 0.6477 - val_loss: 0.9294 - val_accuracy: 0.6412\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8087 - accuracy: 0.6986 - val_loss: 0.8531 - val_accuracy: 0.6848\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7000 - accuracy: 0.7454 - val_loss: 0.9148 - val_accuracy: 0.6661\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6026 - accuracy: 0.7818 - val_loss: 0.6278 - val_accuracy: 0.7673\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5477 - accuracy: 0.8080 - val_loss: 0.5370 - val_accuracy: 0.8140\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4708 - accuracy: 0.8344 - val_loss: 0.5181 - val_accuracy: 0.8008\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4392 - accuracy: 0.8459 - val_loss: 0.4093 - val_accuracy: 0.8514\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4049 - accuracy: 0.8600 - val_loss: 0.5322 - val_accuracy: 0.8366\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3819 - accuracy: 0.8701 - val_loss: 0.4147 - val_accuracy: 0.8545\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3838 - accuracy: 0.8760 - val_loss: 0.6021 - val_accuracy: 0.8148\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3644 - accuracy: 0.8807 - val_loss: 0.4792 - val_accuracy: 0.8467\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3531 - accuracy: 0.8880 - val_loss: 0.5846 - val_accuracy: 0.7790\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3540 - accuracy: 0.8901 - val_loss: 0.4157 - val_accuracy: 0.8732\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3599 - accuracy: 0.8873 - val_loss: 0.6974 - val_accuracy: 0.8210\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3657 - accuracy: 0.8891 - val_loss: 0.6564 - val_accuracy: 0.8444\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3631 - accuracy: 0.8894 - val_loss: 0.4453 - val_accuracy: 0.8661\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3772 - accuracy: 0.8887 - val_loss: 0.3912 - val_accuracy: 0.8786\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3919 - accuracy: 0.8877 - val_loss: 0.5203 - val_accuracy: 0.8724\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3748 - accuracy: 0.8895 - val_loss: 0.5420 - val_accuracy: 0.8661\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3735 - accuracy: 0.8933 - val_loss: 0.3827 - val_accuracy: 0.8809\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4010 - accuracy: 0.8875 - val_loss: 0.5530 - val_accuracy: 0.8677\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3977 - accuracy: 0.8825 - val_loss: 0.9303 - val_accuracy: 0.8140\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4060 - accuracy: 0.8881 - val_loss: 0.4750 - val_accuracy: 0.8872\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4158 - accuracy: 0.8781 - val_loss: 0.7778 - val_accuracy: 0.8514\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4021 - accuracy: 0.8836 - val_loss: 0.7456 - val_accuracy: 0.8677\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4496 - accuracy: 0.8787 - val_loss: 0.8143 - val_accuracy: 0.8879\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4675 - accuracy: 0.8745 - val_loss: 0.5441 - val_accuracy: 0.8661\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4707 - accuracy: 0.8742 - val_loss: 0.6112 - val_accuracy: 0.7790\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5467 - accuracy: 0.8645 - val_loss: 0.5521 - val_accuracy: 0.8949\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5443 - accuracy: 0.8540 - val_loss: 1.6027 - val_accuracy: 0.7689\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5123 - accuracy: 0.8626 - val_loss: 0.4548 - val_accuracy: 0.8482\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5112 - accuracy: 0.8616 - val_loss: 0.5253 - val_accuracy: 0.8553\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5485 - accuracy: 0.8539 - val_loss: 0.5956 - val_accuracy: 0.7953\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5923 - accuracy: 0.8456 - val_loss: 0.6615 - val_accuracy: 0.8537\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5862 - accuracy: 0.8434 - val_loss: 0.5661 - val_accuracy: 0.8677\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5704 - accuracy: 0.8459 - val_loss: 0.4659 - val_accuracy: 0.8420\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6079 - accuracy: 0.8456 - val_loss: 0.5910 - val_accuracy: 0.8560\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6549 - accuracy: 0.8322 - val_loss: 0.5176 - val_accuracy: 0.8304\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6212 - accuracy: 0.8347 - val_loss: 0.5245 - val_accuracy: 0.8482\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6631 - accuracy: 0.8314 - val_loss: 0.5183 - val_accuracy: 0.8654\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6754 - accuracy: 0.8218 - val_loss: 0.6952 - val_accuracy: 0.7463\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6996 - accuracy: 0.8139 - val_loss: 0.6562 - val_accuracy: 0.7946\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7591 - accuracy: 0.8041 - val_loss: 0.5146 - val_accuracy: 0.8296\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7581 - accuracy: 0.7953 - val_loss: 0.4860 - val_accuracy: 0.8661\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7891 - accuracy: 0.8009 - val_loss: 0.8445 - val_accuracy: 0.7276\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8270 - accuracy: 0.7732 - val_loss: 0.8114 - val_accuracy: 0.7533\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8266 - accuracy: 0.7807 - val_loss: 0.8497 - val_accuracy: 0.7603\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8581 - accuracy: 0.7745 - val_loss: 0.6199 - val_accuracy: 0.8444\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8497 - accuracy: 0.7598 - val_loss: 0.7440 - val_accuracy: 0.8202\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8722 - accuracy: 0.7651 - val_loss: 0.9943 - val_accuracy: 0.7930\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8558 - accuracy: 0.7539 - val_loss: 0.7240 - val_accuracy: 0.7580\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8463 - accuracy: 0.7532 - val_loss: 0.7342 - val_accuracy: 0.7261\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8846 - accuracy: 0.7493 - val_loss: 0.9222 - val_accuracy: 0.6840\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8930 - accuracy: 0.7482 - val_loss: 0.8033 - val_accuracy: 0.7595\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9300 - accuracy: 0.7435 - val_loss: 0.8073 - val_accuracy: 0.7222\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9633 - accuracy: 0.7199 - val_loss: 0.7797 - val_accuracy: 0.7556\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8945 - accuracy: 0.7320 - val_loss: 0.8214 - val_accuracy: 0.6661\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9491 - accuracy: 0.7390 - val_loss: 0.8261 - val_accuracy: 0.6887\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9261 - accuracy: 0.7300 - val_loss: 0.8232 - val_accuracy: 0.6988\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9613 - accuracy: 0.7177 - val_loss: 0.7902 - val_accuracy: 0.7230\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9790 - accuracy: 0.7100 - val_loss: 0.7681 - val_accuracy: 0.7245\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9376 - accuracy: 0.7175 - val_loss: 0.8037 - val_accuracy: 0.7019\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9500 - accuracy: 0.7132 - val_loss: 0.9080 - val_accuracy: 0.6848\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9766 - accuracy: 0.7096 - val_loss: 1.1030 - val_accuracy: 0.6856\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9360 - accuracy: 0.7022 - val_loss: 1.2448 - val_accuracy: 0.6498\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9641 - accuracy: 0.7060 - val_loss: 0.9559 - val_accuracy: 0.6895\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9624 - accuracy: 0.7122 - val_loss: 0.8900 - val_accuracy: 0.6685\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9979 - accuracy: 0.7009 - val_loss: 0.8232 - val_accuracy: 0.7175\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2194 - accuracy: 0.6997 - val_loss: 1.9816 - val_accuracy: 0.6576\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1152 - accuracy: 0.7009 - val_loss: 0.8741 - val_accuracy: 0.7463\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9638 - accuracy: 0.6995 - val_loss: 1.1807 - val_accuracy: 0.5650\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9653 - accuracy: 0.7072 - val_loss: 1.4329 - val_accuracy: 0.6591\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9770 - accuracy: 0.7036 - val_loss: 0.7119 - val_accuracy: 0.7432\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9993 - accuracy: 0.6893 - val_loss: 1.0406 - val_accuracy: 0.6459\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0734 - accuracy: 0.6628 - val_loss: 0.8134 - val_accuracy: 0.7082\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0262 - accuracy: 0.6755 - val_loss: 0.9736 - val_accuracy: 0.6716\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1891 - accuracy: 0.6708 - val_loss: 0.9940 - val_accuracy: 0.7292\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0756 - accuracy: 0.6710 - val_loss: 0.9621 - val_accuracy: 0.7385\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0909 - accuracy: 0.6613 - val_loss: 2.6143 - val_accuracy: 0.6786\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1825 - accuracy: 0.6618 - val_loss: 0.9337 - val_accuracy: 0.7051\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1005 - accuracy: 0.6507 - val_loss: 1.0654 - val_accuracy: 0.6031\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1382 - accuracy: 0.6492 - val_loss: 0.9295 - val_accuracy: 0.7284\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1470 - accuracy: 0.6359 - val_loss: 0.9684 - val_accuracy: 0.6498\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1357 - accuracy: 0.6281 - val_loss: 0.7943 - val_accuracy: 0.7253\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1668 - accuracy: 0.6226 - val_loss: 0.8642 - val_accuracy: 0.6747\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1497 - accuracy: 0.6175 - val_loss: 0.8640 - val_accuracy: 0.6911\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1978 - accuracy: 0.6018 - val_loss: 1.1999 - val_accuracy: 0.6054\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2392 - accuracy: 0.5821 - val_loss: 0.9542 - val_accuracy: 0.6412\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2855 - accuracy: 0.5738 - val_loss: 1.1341 - val_accuracy: 0.6086\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.1823 - accuracy: 0.5974 - val_loss: 0.9939 - val_accuracy: 0.6498\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2793 - accuracy: 0.5679 - val_loss: 1.1187 - val_accuracy: 0.5805\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.3083 - accuracy: 0.5834 - val_loss: 1.0632 - val_accuracy: 0.5346\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2583 - accuracy: 0.5717 - val_loss: 1.2529 - val_accuracy: 0.5938\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2122 - accuracy: 0.5816 - val_loss: 1.0881 - val_accuracy: 0.6498\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2510 - accuracy: 0.5812 - val_loss: 1.1732 - val_accuracy: 0.5790\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2874 - accuracy: 0.5631 - val_loss: 1.0775 - val_accuracy: 0.5611\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.2482 - accuracy: 0.5587 - val_loss: 1.0198 - val_accuracy: 0.6615\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.4033 - accuracy: 0.5385 - val_loss: 1.2423 - val_accuracy: 0.5253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd84IkTJNANx",
        "outputId": "cea4d800-b375-4712-95ac-0756d8658bcc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.7499\n",
            "평균 손실: 0.8166\n",
            "평균 검증 정확도: 0.7445\n",
            "평균 검증 손실: 0.8284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+Adamax"
      ],
      "metadata": {
        "id": "f1g5PFO8Oxto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adamax\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model7 = Sequential()\n",
        "\n",
        "    model7.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model7.add(Dropout(0.25))\n",
        "\n",
        "    model7.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model7.add(Dropout(0.25))\n",
        "\n",
        "    model7.add(Flatten())\n",
        "    model7.add(Dense(256, activation='relu'))\n",
        "    model7.add(Dropout(0.5))\n",
        "    model7.add(Dense(num_classes, activation='softmax')) # 출력 레이어 수정\n",
        "\n",
        "    model7.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model7'\n",
        "    model_path = model_dir + \"/cloud_classify.model7\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "sX7CaxCNOxMo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1gNFAD4PdrU",
        "outputId": "f56a0995-7d1c-4b58-d335-1f9d56d36fea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,237\n",
            "Trainable params: 4,215,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model7.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly0mPjEcPgAW",
        "outputId": "aeb2d742-6394-454e-f322-ddda95b60d4d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 5s 8ms/step - loss: 1.2648 - accuracy: 0.4885 - val_loss: 1.2039 - val_accuracy: 0.5307\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 1.0727 - accuracy: 0.5779 - val_loss: 1.0565 - val_accuracy: 0.6008\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.9788 - accuracy: 0.6181 - val_loss: 0.9677 - val_accuracy: 0.6241\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.9061 - accuracy: 0.6558 - val_loss: 0.9226 - val_accuracy: 0.6475\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.8525 - accuracy: 0.6736 - val_loss: 0.8463 - val_accuracy: 0.6856\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.7896 - accuracy: 0.6935 - val_loss: 0.8130 - val_accuracy: 0.6926\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.7300 - accuracy: 0.7250 - val_loss: 0.7464 - val_accuracy: 0.7253\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6811 - accuracy: 0.7406 - val_loss: 0.6810 - val_accuracy: 0.7603\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6209 - accuracy: 0.7712 - val_loss: 0.6691 - val_accuracy: 0.7494\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.5755 - accuracy: 0.7901 - val_loss: 0.6004 - val_accuracy: 0.7914\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.5448 - accuracy: 0.8037 - val_loss: 0.5860 - val_accuracy: 0.8109\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.5055 - accuracy: 0.8171 - val_loss: 0.5439 - val_accuracy: 0.8163\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4650 - accuracy: 0.8349 - val_loss: 0.5179 - val_accuracy: 0.8257\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4389 - accuracy: 0.8459 - val_loss: 0.4795 - val_accuracy: 0.8412\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.4013 - accuracy: 0.8572 - val_loss: 0.4627 - val_accuracy: 0.8467\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8638 - val_loss: 0.4226 - val_accuracy: 0.8591\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3581 - accuracy: 0.8716 - val_loss: 0.4604 - val_accuracy: 0.8537\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3358 - accuracy: 0.8820 - val_loss: 0.4221 - val_accuracy: 0.8615\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.3051 - accuracy: 0.8937 - val_loss: 0.3934 - val_accuracy: 0.8646\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2932 - accuracy: 0.8954 - val_loss: 0.3909 - val_accuracy: 0.8693\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2865 - accuracy: 0.8981 - val_loss: 0.4124 - val_accuracy: 0.8623\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2651 - accuracy: 0.9065 - val_loss: 0.3733 - val_accuracy: 0.8716\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2532 - accuracy: 0.9122 - val_loss: 0.3988 - val_accuracy: 0.8770\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2387 - accuracy: 0.9180 - val_loss: 0.3643 - val_accuracy: 0.8763\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.2378 - accuracy: 0.9181 - val_loss: 0.4152 - val_accuracy: 0.8646\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2130 - accuracy: 0.9253 - val_loss: 0.3535 - val_accuracy: 0.8809\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2093 - accuracy: 0.9267 - val_loss: 0.3405 - val_accuracy: 0.8895\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.2010 - accuracy: 0.9299 - val_loss: 0.3427 - val_accuracy: 0.8879\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1898 - accuracy: 0.9349 - val_loss: 0.3630 - val_accuracy: 0.8911\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.1789 - accuracy: 0.9413 - val_loss: 0.3762 - val_accuracy: 0.8926\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1791 - accuracy: 0.9375 - val_loss: 0.3664 - val_accuracy: 0.8856\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1619 - accuracy: 0.9441 - val_loss: 0.3497 - val_accuracy: 0.8949\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1585 - accuracy: 0.9429 - val_loss: 0.3632 - val_accuracy: 0.8942\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1618 - accuracy: 0.9445 - val_loss: 0.3414 - val_accuracy: 0.8949\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1486 - accuracy: 0.9503 - val_loss: 0.3584 - val_accuracy: 0.8949\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1415 - accuracy: 0.9505 - val_loss: 0.3426 - val_accuracy: 0.8949\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1406 - accuracy: 0.9515 - val_loss: 0.3318 - val_accuracy: 0.8988\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1356 - accuracy: 0.9507 - val_loss: 0.3280 - val_accuracy: 0.9051\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1333 - accuracy: 0.9536 - val_loss: 0.3597 - val_accuracy: 0.9004\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1211 - accuracy: 0.9561 - val_loss: 0.3514 - val_accuracy: 0.9051\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1222 - accuracy: 0.9579 - val_loss: 0.3469 - val_accuracy: 0.9058\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1151 - accuracy: 0.9619 - val_loss: 0.3609 - val_accuracy: 0.8965\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1165 - accuracy: 0.9608 - val_loss: 0.3257 - val_accuracy: 0.9035\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1164 - accuracy: 0.9596 - val_loss: 0.3266 - val_accuracy: 0.9074\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9643 - val_loss: 0.3480 - val_accuracy: 0.9035\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.3514 - val_accuracy: 0.9066\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1007 - accuracy: 0.9638 - val_loss: 0.3263 - val_accuracy: 0.9097\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9652 - val_loss: 0.3138 - val_accuracy: 0.9175\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.1011 - accuracy: 0.9628 - val_loss: 0.3232 - val_accuracy: 0.9089\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 0.3594 - val_accuracy: 0.9043\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0894 - accuracy: 0.9698 - val_loss: 0.3405 - val_accuracy: 0.9082\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9696 - val_loss: 0.3445 - val_accuracy: 0.9183\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0851 - accuracy: 0.9707 - val_loss: 0.3779 - val_accuracy: 0.9121\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0897 - accuracy: 0.9696 - val_loss: 0.3570 - val_accuracy: 0.9097\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.3535 - val_accuracy: 0.9121\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0853 - accuracy: 0.9707 - val_loss: 0.3709 - val_accuracy: 0.9105\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0831 - accuracy: 0.9729 - val_loss: 0.3809 - val_accuracy: 0.9121\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.3447 - val_accuracy: 0.9121\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0792 - accuracy: 0.9739 - val_loss: 0.3400 - val_accuracy: 0.9160\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0778 - accuracy: 0.9725 - val_loss: 0.3757 - val_accuracy: 0.9097\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0775 - accuracy: 0.9736 - val_loss: 0.3769 - val_accuracy: 0.9097\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 0.3736 - val_accuracy: 0.9167\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0785 - accuracy: 0.9714 - val_loss: 0.3997 - val_accuracy: 0.9043\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0768 - accuracy: 0.9721 - val_loss: 0.3788 - val_accuracy: 0.9160\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0705 - accuracy: 0.9746 - val_loss: 0.3851 - val_accuracy: 0.9144\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0738 - accuracy: 0.9736 - val_loss: 0.3676 - val_accuracy: 0.9160\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 0.3734 - val_accuracy: 0.9105\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9761 - val_loss: 0.3897 - val_accuracy: 0.9160\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 0.4006 - val_accuracy: 0.9066\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0624 - accuracy: 0.9777 - val_loss: 0.3904 - val_accuracy: 0.9121\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0601 - accuracy: 0.9774 - val_loss: 0.3843 - val_accuracy: 0.9160\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.3988 - val_accuracy: 0.9160\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0612 - accuracy: 0.9787 - val_loss: 0.3845 - val_accuracy: 0.9206\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.3992 - val_accuracy: 0.9082\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0600 - accuracy: 0.9795 - val_loss: 0.3686 - val_accuracy: 0.9152\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.3939 - val_accuracy: 0.9121\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0595 - accuracy: 0.9797 - val_loss: 0.4137 - val_accuracy: 0.9105\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.3883 - val_accuracy: 0.9136\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.3806 - val_accuracy: 0.9128\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.4178 - val_accuracy: 0.9113\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0548 - accuracy: 0.9804 - val_loss: 0.4319 - val_accuracy: 0.9113\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 0.3838 - val_accuracy: 0.9237\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0494 - accuracy: 0.9827 - val_loss: 0.4314 - val_accuracy: 0.9089\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 0.4146 - val_accuracy: 0.9198\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0507 - accuracy: 0.9830 - val_loss: 0.4180 - val_accuracy: 0.9105\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.3831 - val_accuracy: 0.9175\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 0.4181 - val_accuracy: 0.9152\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9824 - val_loss: 0.4000 - val_accuracy: 0.9113\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.4308 - val_accuracy: 0.9105\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9822 - val_loss: 0.4226 - val_accuracy: 0.9214\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.4014 - val_accuracy: 0.9230\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0449 - accuracy: 0.9830 - val_loss: 0.4043 - val_accuracy: 0.9222\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0434 - accuracy: 0.9843 - val_loss: 0.3944 - val_accuracy: 0.9214\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 0.4194 - val_accuracy: 0.9113\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 0.4400 - val_accuracy: 0.9206\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9840 - val_loss: 0.4359 - val_accuracy: 0.9136\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0424 - accuracy: 0.9840 - val_loss: 0.4184 - val_accuracy: 0.9198\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 8ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.4262 - val_accuracy: 0.9206\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.4331 - val_accuracy: 0.9214\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.4754 - val_accuracy: 0.9074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ1FqGXFPh7d",
        "outputId": "362940c6-f327-416b-a246-605653ff3e21"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9255\n",
            "평균 손실: 0.2042\n",
            "평균 검증 정확도: 0.8779\n",
            "평균 검증 손실: 0.4353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+Adamax"
      ],
      "metadata": {
        "id": "I_b-_ObHRFKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model8 = Sequential()\n",
        "\n",
        "    model8.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model8.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")) #새로추가\n",
        "    model8.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model8.add(Dropout(0.25))\n",
        "\n",
        "    model8.add(Flatten())\n",
        "    model8.add(Dense(256, activation = 'relu'))\n",
        "    model8.add(Dropout(0.5))\n",
        "    model8.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model8.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax',metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model8'\n",
        "    model_path = model_dir + \"/cloud_classify.model8\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)"
      ],
      "metadata": {
        "id": "0N46M17IRJlR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzMl7wFGRYka",
        "outputId": "bcb90fd1-c5aa-4bdd-f691-c0d286f895b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,339,525\n",
            "Trainable params: 2,339,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model8.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vnV0Pu-RVN-",
        "outputId": "907b637a-dd30-4fb6-ef48-1304d6b22c93"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 6s 10ms/step - loss: 1.2804 - accuracy: 0.4734 - val_loss: 1.1818 - val_accuracy: 0.5463\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0887 - accuracy: 0.5713 - val_loss: 1.0530 - val_accuracy: 0.5774\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9764 - accuracy: 0.6237 - val_loss: 0.9158 - val_accuracy: 0.6366\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8651 - accuracy: 0.6714 - val_loss: 0.8185 - val_accuracy: 0.6833\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7792 - accuracy: 0.7064 - val_loss: 0.7982 - val_accuracy: 0.6856\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6919 - accuracy: 0.7398 - val_loss: 0.7397 - val_accuracy: 0.7276\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6109 - accuracy: 0.7740 - val_loss: 0.5969 - val_accuracy: 0.7696\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5392 - accuracy: 0.7990 - val_loss: 0.5788 - val_accuracy: 0.7805\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4736 - accuracy: 0.8263 - val_loss: 0.4387 - val_accuracy: 0.8459\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4028 - accuracy: 0.8548 - val_loss: 0.4118 - val_accuracy: 0.8553\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3778 - accuracy: 0.8662 - val_loss: 0.3881 - val_accuracy: 0.8630\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3328 - accuracy: 0.8805 - val_loss: 0.3253 - val_accuracy: 0.8856\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2881 - accuracy: 0.8959 - val_loss: 0.3337 - val_accuracy: 0.8848\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2730 - accuracy: 0.9053 - val_loss: 0.2980 - val_accuracy: 0.8949\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2402 - accuracy: 0.9132 - val_loss: 0.2755 - val_accuracy: 0.8996\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2266 - accuracy: 0.9197 - val_loss: 0.2749 - val_accuracy: 0.9043\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2045 - accuracy: 0.9283 - val_loss: 0.2804 - val_accuracy: 0.8934\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1874 - accuracy: 0.9346 - val_loss: 0.2395 - val_accuracy: 0.9136\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1770 - accuracy: 0.9379 - val_loss: 0.2714 - val_accuracy: 0.9144\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1593 - accuracy: 0.9465 - val_loss: 0.2623 - val_accuracy: 0.9051\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1580 - accuracy: 0.9452 - val_loss: 0.2048 - val_accuracy: 0.9237\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1516 - accuracy: 0.9489 - val_loss: 0.2317 - val_accuracy: 0.9198\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1420 - accuracy: 0.9518 - val_loss: 0.2235 - val_accuracy: 0.9253\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1330 - accuracy: 0.9534 - val_loss: 0.2194 - val_accuracy: 0.9276\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1225 - accuracy: 0.9589 - val_loss: 0.2427 - val_accuracy: 0.9214\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1246 - accuracy: 0.9569 - val_loss: 0.1928 - val_accuracy: 0.9284\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1130 - accuracy: 0.9596 - val_loss: 0.1995 - val_accuracy: 0.9198\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1169 - accuracy: 0.9580 - val_loss: 0.1940 - val_accuracy: 0.9315\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1077 - accuracy: 0.9619 - val_loss: 0.2161 - val_accuracy: 0.9261\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0972 - accuracy: 0.9658 - val_loss: 0.2059 - val_accuracy: 0.9284\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0978 - accuracy: 0.9659 - val_loss: 0.2145 - val_accuracy: 0.9315\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0897 - accuracy: 0.9676 - val_loss: 0.2358 - val_accuracy: 0.9292\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0997 - accuracy: 0.9638 - val_loss: 0.1687 - val_accuracy: 0.9385\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0901 - accuracy: 0.9671 - val_loss: 0.1834 - val_accuracy: 0.9393\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0828 - accuracy: 0.9698 - val_loss: 0.1936 - val_accuracy: 0.9370\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0823 - accuracy: 0.9708 - val_loss: 0.1910 - val_accuracy: 0.9362\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0780 - accuracy: 0.9725 - val_loss: 0.1838 - val_accuracy: 0.9370\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0715 - accuracy: 0.9737 - val_loss: 0.1731 - val_accuracy: 0.9377\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0806 - accuracy: 0.9702 - val_loss: 0.2143 - val_accuracy: 0.9362\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0730 - accuracy: 0.9732 - val_loss: 0.1866 - val_accuracy: 0.9416\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0694 - accuracy: 0.9757 - val_loss: 0.1944 - val_accuracy: 0.9401\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 0.1853 - val_accuracy: 0.9447\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.2108 - val_accuracy: 0.9354\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 0.2221 - val_accuracy: 0.9370\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 0.2089 - val_accuracy: 0.9424\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0626 - accuracy: 0.9766 - val_loss: 0.2222 - val_accuracy: 0.9370\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0674 - accuracy: 0.9766 - val_loss: 0.1728 - val_accuracy: 0.9471\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0642 - accuracy: 0.9768 - val_loss: 0.1759 - val_accuracy: 0.9377\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0554 - accuracy: 0.9800 - val_loss: 0.1915 - val_accuracy: 0.9370\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0584 - accuracy: 0.9798 - val_loss: 0.1992 - val_accuracy: 0.9432\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0535 - accuracy: 0.9815 - val_loss: 0.2222 - val_accuracy: 0.9393\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0568 - accuracy: 0.9804 - val_loss: 0.2012 - val_accuracy: 0.9307\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.2163 - val_accuracy: 0.9409\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0547 - accuracy: 0.9803 - val_loss: 0.2212 - val_accuracy: 0.9393\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0514 - accuracy: 0.9809 - val_loss: 0.1723 - val_accuracy: 0.9486\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.1929 - val_accuracy: 0.9502\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0477 - accuracy: 0.9820 - val_loss: 0.2224 - val_accuracy: 0.9416\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.1998 - val_accuracy: 0.9432\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0460 - accuracy: 0.9824 - val_loss: 0.1896 - val_accuracy: 0.9486\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0441 - accuracy: 0.9832 - val_loss: 0.2185 - val_accuracy: 0.9440\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.1884 - val_accuracy: 0.9432\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.2006 - val_accuracy: 0.9486\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 0.1902 - val_accuracy: 0.9447\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.1881 - val_accuracy: 0.9494\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 0.2253 - val_accuracy: 0.9463\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.2178 - val_accuracy: 0.9479\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.1976 - val_accuracy: 0.9440\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0432 - accuracy: 0.9830 - val_loss: 0.2165 - val_accuracy: 0.9471\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0486 - accuracy: 0.9817 - val_loss: 0.2357 - val_accuracy: 0.9432\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.1890 - val_accuracy: 0.9549\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.2250 - val_accuracy: 0.9486\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.1877 - val_accuracy: 0.9494\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 0.2155 - val_accuracy: 0.9416\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0386 - accuracy: 0.9865 - val_loss: 0.2064 - val_accuracy: 0.9424\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.2345 - val_accuracy: 0.9385\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0394 - accuracy: 0.9855 - val_loss: 0.1834 - val_accuracy: 0.9479\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.2064 - val_accuracy: 0.9432\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0387 - accuracy: 0.9858 - val_loss: 0.1959 - val_accuracy: 0.9549\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.2144 - val_accuracy: 0.9486\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 0.2445 - val_accuracy: 0.9432\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.1998 - val_accuracy: 0.9447\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.2117 - val_accuracy: 0.9486\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.2206 - val_accuracy: 0.9494\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 0.2001 - val_accuracy: 0.9486\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0426 - accuracy: 0.9860 - val_loss: 0.1962 - val_accuracy: 0.9479\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.1909 - val_accuracy: 0.9533\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0317 - accuracy: 0.9880 - val_loss: 0.2270 - val_accuracy: 0.9494\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.2884 - val_accuracy: 0.9385\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.2242 - val_accuracy: 0.9494\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 0.2196 - val_accuracy: 0.9471\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0323 - accuracy: 0.9876 - val_loss: 0.1947 - val_accuracy: 0.9502\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.2392 - val_accuracy: 0.9479\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0318 - accuracy: 0.9879 - val_loss: 0.2095 - val_accuracy: 0.9494\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.2512 - val_accuracy: 0.9494\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.2351 - val_accuracy: 0.9486\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 0.2347 - val_accuracy: 0.9424\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9879 - val_loss: 0.2253 - val_accuracy: 0.9455\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.2521 - val_accuracy: 0.9432\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.2108 - val_accuracy: 0.9549\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 0.2008 - val_accuracy: 0.9494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs3CkNXeRbxp",
        "outputId": "06f21d0c-d325-4601-c55a-633507a388e7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9447\n",
            "평균 손실: 0.1493\n",
            "평균 검증 정확도: 0.9140\n",
            "평균 검증 손실: 0.2719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model1+Adamax+normalization"
      ],
      "metadata": {
        "id": "9QKuAaIgT0uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "# 모델 구성\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(image_w, image_h, 3), activation=\"relu\"))\n",
        "model9.add(BatchNormalization())\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "\n",
        "model9.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model9.add(BatchNormalization())\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "\n",
        "model9.add(Flatten())\n",
        "model9.add(Dense(256, activation='relu'))\n",
        "model9.add(Dropout(0.5))\n",
        "model9.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model9.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax',metrics=['accuracy'])\n",
        "\n",
        "model_dir = './model9'\n",
        "model_path = model_dir + \"/cloud_classify.model9\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "metadata": {
        "id": "lGLX9eW6T8SK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIqLocT5UaSQ",
        "outputId": "e3e72e60-406f-4b6f-dba6-56e6ac21cdda"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,621\n",
            "Trainable params: 4,215,429\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "history = model9.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0G4fc5Ub75",
        "outputId": "6d648650-1ff1-4ab9-90d8-c3d55e06376a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 6s 11ms/step - loss: 1.5708 - accuracy: 0.4933 - val_loss: 19.5789 - val_accuracy: 0.2444\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 1.0892 - accuracy: 0.5763 - val_loss: 1.0158 - val_accuracy: 0.6389\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.9736 - accuracy: 0.6165 - val_loss: 0.9140 - val_accuracy: 0.6724\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8995 - accuracy: 0.6552 - val_loss: 0.9329 - val_accuracy: 0.6747\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.8241 - accuracy: 0.6795 - val_loss: 0.8097 - val_accuracy: 0.7121\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.7530 - accuracy: 0.7079 - val_loss: 0.7570 - val_accuracy: 0.7307\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.6935 - accuracy: 0.7308 - val_loss: 0.6684 - val_accuracy: 0.7774\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.6317 - accuracy: 0.7540 - val_loss: 0.6275 - val_accuracy: 0.7790\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5819 - accuracy: 0.7734 - val_loss: 0.7368 - val_accuracy: 0.7572\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5475 - accuracy: 0.7927 - val_loss: 0.5878 - val_accuracy: 0.8156\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.5073 - accuracy: 0.7983 - val_loss: 0.7005 - val_accuracy: 0.7798\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.4672 - accuracy: 0.8218 - val_loss: 0.5002 - val_accuracy: 0.8311\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4276 - accuracy: 0.8318 - val_loss: 1.0385 - val_accuracy: 0.7401\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.4065 - accuracy: 0.8451 - val_loss: 0.4699 - val_accuracy: 0.8459\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3776 - accuracy: 0.8559 - val_loss: 0.4082 - val_accuracy: 0.8553\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.3635 - accuracy: 0.8614 - val_loss: 0.4625 - val_accuracy: 0.8560\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3329 - accuracy: 0.8731 - val_loss: 0.5487 - val_accuracy: 0.8405\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.3113 - accuracy: 0.8794 - val_loss: 0.4347 - val_accuracy: 0.8708\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2968 - accuracy: 0.8844 - val_loss: 0.6120 - val_accuracy: 0.8101\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2870 - accuracy: 0.8894 - val_loss: 0.4393 - val_accuracy: 0.8700\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2770 - accuracy: 0.8951 - val_loss: 1.1275 - val_accuracy: 0.7152\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2596 - accuracy: 0.9007 - val_loss: 0.3538 - val_accuracy: 0.8872\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2446 - accuracy: 0.9033 - val_loss: 0.5221 - val_accuracy: 0.8599\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2366 - accuracy: 0.9084 - val_loss: 0.4413 - val_accuracy: 0.8747\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2318 - accuracy: 0.9146 - val_loss: 0.4239 - val_accuracy: 0.8778\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.2115 - accuracy: 0.9193 - val_loss: 0.4613 - val_accuracy: 0.8537\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.2007 - accuracy: 0.9222 - val_loss: 0.3860 - val_accuracy: 0.8809\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1928 - accuracy: 0.9283 - val_loss: 0.3630 - val_accuracy: 0.8981\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1886 - accuracy: 0.9292 - val_loss: 0.4282 - val_accuracy: 0.8957\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1706 - accuracy: 0.9369 - val_loss: 0.6189 - val_accuracy: 0.8459\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1714 - accuracy: 0.9359 - val_loss: 0.3785 - val_accuracy: 0.8965\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1662 - accuracy: 0.9364 - val_loss: 0.4660 - val_accuracy: 0.8654\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1629 - accuracy: 0.9387 - val_loss: 0.3768 - val_accuracy: 0.9012\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1562 - accuracy: 0.9399 - val_loss: 0.4509 - val_accuracy: 0.8911\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1543 - accuracy: 0.9385 - val_loss: 0.8864 - val_accuracy: 0.7665\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1510 - accuracy: 0.9424 - val_loss: 0.3651 - val_accuracy: 0.8996\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1438 - accuracy: 0.9472 - val_loss: 0.4154 - val_accuracy: 0.8949\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1326 - accuracy: 0.9506 - val_loss: 0.5069 - val_accuracy: 0.8693\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1353 - accuracy: 0.9468 - val_loss: 0.3779 - val_accuracy: 0.9136\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1311 - accuracy: 0.9530 - val_loss: 0.4031 - val_accuracy: 0.8887\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1301 - accuracy: 0.9515 - val_loss: 0.6184 - val_accuracy: 0.8366\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1233 - accuracy: 0.9529 - val_loss: 0.4599 - val_accuracy: 0.9097\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1226 - accuracy: 0.9542 - val_loss: 0.3619 - val_accuracy: 0.9113\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1207 - accuracy: 0.9537 - val_loss: 0.3759 - val_accuracy: 0.9105\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1085 - accuracy: 0.9600 - val_loss: 0.5019 - val_accuracy: 0.8607\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1171 - accuracy: 0.9568 - val_loss: 0.3572 - val_accuracy: 0.9089\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1024 - accuracy: 0.9614 - val_loss: 0.6434 - val_accuracy: 0.8669\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1068 - accuracy: 0.9606 - val_loss: 0.3730 - val_accuracy: 0.9082\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1061 - accuracy: 0.9609 - val_loss: 0.4938 - val_accuracy: 0.8716\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.1077 - accuracy: 0.9588 - val_loss: 0.3718 - val_accuracy: 0.9097\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.1034 - accuracy: 0.9608 - val_loss: 0.3469 - val_accuracy: 0.9035\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0910 - accuracy: 0.9652 - val_loss: 0.3888 - val_accuracy: 0.9058\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0969 - accuracy: 0.9657 - val_loss: 0.4385 - val_accuracy: 0.9089\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0934 - accuracy: 0.9657 - val_loss: 0.4341 - val_accuracy: 0.8949\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0940 - accuracy: 0.9658 - val_loss: 0.3791 - val_accuracy: 0.9097\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0884 - accuracy: 0.9691 - val_loss: 0.3991 - val_accuracy: 0.9136\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0822 - accuracy: 0.9689 - val_loss: 0.4267 - val_accuracy: 0.9082\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0879 - accuracy: 0.9676 - val_loss: 0.3125 - val_accuracy: 0.9198\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0740 - accuracy: 0.9731 - val_loss: 0.5294 - val_accuracy: 0.8739\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0741 - accuracy: 0.9734 - val_loss: 0.3931 - val_accuracy: 0.9183\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0848 - accuracy: 0.9693 - val_loss: 0.3408 - val_accuracy: 0.9074\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.3865 - val_accuracy: 0.9175\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0785 - accuracy: 0.9724 - val_loss: 0.3854 - val_accuracy: 0.9012\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0804 - accuracy: 0.9712 - val_loss: 0.3123 - val_accuracy: 0.9082\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0721 - accuracy: 0.9741 - val_loss: 0.4032 - val_accuracy: 0.9222\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0772 - accuracy: 0.9715 - val_loss: 0.3758 - val_accuracy: 0.9043\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 0.3907 - val_accuracy: 0.9097\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.0688 - accuracy: 0.9739 - val_loss: 0.4401 - val_accuracy: 0.9082\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0685 - accuracy: 0.9753 - val_loss: 0.4319 - val_accuracy: 0.9152\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.3724 - val_accuracy: 0.8988\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0712 - accuracy: 0.9732 - val_loss: 0.3990 - val_accuracy: 0.8895\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.7366 - val_accuracy: 0.8677\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0703 - accuracy: 0.9763 - val_loss: 0.4601 - val_accuracy: 0.9105\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0679 - accuracy: 0.9760 - val_loss: 0.3612 - val_accuracy: 0.9175\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0628 - accuracy: 0.9777 - val_loss: 0.4263 - val_accuracy: 0.9004\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0622 - accuracy: 0.9783 - val_loss: 0.3751 - val_accuracy: 0.9121\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0724 - accuracy: 0.9750 - val_loss: 0.4536 - val_accuracy: 0.9167\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0622 - accuracy: 0.9789 - val_loss: 0.3349 - val_accuracy: 0.9152\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0632 - accuracy: 0.9772 - val_loss: 0.4335 - val_accuracy: 0.8794\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.3714 - val_accuracy: 0.9144\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 0.4081 - val_accuracy: 0.9089\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.3797 - val_accuracy: 0.9144\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 0.4113 - val_accuracy: 0.9206\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0634 - accuracy: 0.9784 - val_loss: 0.4471 - val_accuracy: 0.9237\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.3597 - val_accuracy: 0.9152\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 4s 10ms/step - loss: 0.0612 - accuracy: 0.9779 - val_loss: 0.3457 - val_accuracy: 0.9206\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.6054 - val_accuracy: 0.8934\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.4341 - val_accuracy: 0.9113\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.3561 - val_accuracy: 0.9268\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0599 - accuracy: 0.9798 - val_loss: 0.3558 - val_accuracy: 0.9144\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0557 - accuracy: 0.9808 - val_loss: 0.4562 - val_accuracy: 0.8918\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0576 - accuracy: 0.9803 - val_loss: 0.3970 - val_accuracy: 0.9066\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.3668 - val_accuracy: 0.9253\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0535 - accuracy: 0.9814 - val_loss: 0.3671 - val_accuracy: 0.9105\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.5645 - val_accuracy: 0.9074\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.4239 - val_accuracy: 0.9105\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0556 - accuracy: 0.9807 - val_loss: 0.3399 - val_accuracy: 0.9074\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 3s 10ms/step - loss: 0.0607 - accuracy: 0.9784 - val_loss: 0.3383 - val_accuracy: 0.9245\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0545 - accuracy: 0.9809 - val_loss: 0.3590 - val_accuracy: 0.9097\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 3s 9ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.3558 - val_accuracy: 0.8996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3xLIxBUUeEb",
        "outputId": "5509ad20-5ddb-468d-e704-3afaf3de2990"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.9225\n",
            "평균 손실: 0.2066\n",
            "평균 검증 정확도: 0.8679\n",
            "평균 검증 손실: 0.6686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model2+Adamax+normalization"
      ],
      "metadata": {
        "id": "H_Latu95T4u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model10 = Sequential()\n",
        "\n",
        "    model10.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model10.add(BatchNormalization())\n",
        "    model10.add(Activation(\"relu\"))\n",
        "    model10.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model10.add(Dropout(0.25))\n",
        "\n",
        "    model10.add(Flatten())\n",
        "    model10.add(Dense(256, activation='relu'))\n",
        "    model10.add(Dropout(0.5))\n",
        "    model10.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model10.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "\n",
        "    model_dir = './model10'\n",
        "    model_path = model_dir + \"/cloud_classify.model10\"\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n"
      ],
      "metadata": {
        "id": "tATd1F5wUllI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0vWDyy1U4Hm",
        "outputId": "45854fba-2cae-4482-8189-7bc1646f2572"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,933\n",
            "Trainable params: 2,340,229\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model10.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1)\n",
        "#callbacks=[checkpoint, early_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A4L6qbqU5xf",
        "outputId": "3d0b1af2-204d-4a49-da1b-fe42add7d5e4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "362/362 [==============================] - 8s 14ms/step - loss: 1.5117 - accuracy: 0.4705 - val_loss: 1.4908 - val_accuracy: 0.3401\n",
            "Epoch 2/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.1628 - accuracy: 0.5442 - val_loss: 1.1714 - val_accuracy: 0.5253\n",
            "Epoch 3/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.0738 - accuracy: 0.5839 - val_loss: 1.0247 - val_accuracy: 0.5899\n",
            "Epoch 4/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 1.0207 - accuracy: 0.6056 - val_loss: 1.1181 - val_accuracy: 0.5626\n",
            "Epoch 5/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.9546 - accuracy: 0.6337 - val_loss: 0.8417 - val_accuracy: 0.6809\n",
            "Epoch 6/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.8838 - accuracy: 0.6641 - val_loss: 0.8476 - val_accuracy: 0.6755\n",
            "Epoch 7/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.8360 - accuracy: 0.6839 - val_loss: 0.8851 - val_accuracy: 0.6630\n",
            "Epoch 8/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.7782 - accuracy: 0.7009 - val_loss: 0.6881 - val_accuracy: 0.7284\n",
            "Epoch 9/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.7235 - accuracy: 0.7227 - val_loss: 0.7612 - val_accuracy: 0.7027\n",
            "Epoch 10/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6870 - accuracy: 0.7383 - val_loss: 0.6137 - val_accuracy: 0.7767\n",
            "Epoch 11/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6282 - accuracy: 0.7653 - val_loss: 0.6923 - val_accuracy: 0.7331\n",
            "Epoch 12/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.6121 - accuracy: 0.7688 - val_loss: 0.8000 - val_accuracy: 0.7043\n",
            "Epoch 13/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5659 - accuracy: 0.7828 - val_loss: 0.6342 - val_accuracy: 0.7728\n",
            "Epoch 14/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5544 - accuracy: 0.7914 - val_loss: 1.3028 - val_accuracy: 0.6459\n",
            "Epoch 15/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.5139 - accuracy: 0.8047 - val_loss: 0.5306 - val_accuracy: 0.8086\n",
            "Epoch 16/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4888 - accuracy: 0.8163 - val_loss: 0.7312 - val_accuracy: 0.7603\n",
            "Epoch 17/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4545 - accuracy: 0.8309 - val_loss: 0.6408 - val_accuracy: 0.7580\n",
            "Epoch 18/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4444 - accuracy: 0.8307 - val_loss: 0.5447 - val_accuracy: 0.8226\n",
            "Epoch 19/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.4177 - accuracy: 0.8420 - val_loss: 0.5125 - val_accuracy: 0.8054\n",
            "Epoch 20/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3960 - accuracy: 0.8511 - val_loss: 0.6031 - val_accuracy: 0.7805\n",
            "Epoch 21/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3842 - accuracy: 0.8582 - val_loss: 0.4955 - val_accuracy: 0.8311\n",
            "Epoch 22/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3642 - accuracy: 0.8637 - val_loss: 0.6657 - val_accuracy: 0.7829\n",
            "Epoch 23/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3595 - accuracy: 0.8662 - val_loss: 0.4083 - val_accuracy: 0.8545\n",
            "Epoch 24/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3404 - accuracy: 0.8713 - val_loss: 0.4380 - val_accuracy: 0.8389\n",
            "Epoch 25/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3291 - accuracy: 0.8741 - val_loss: 0.3804 - val_accuracy: 0.8568\n",
            "Epoch 26/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.3147 - accuracy: 0.8780 - val_loss: 0.3219 - val_accuracy: 0.8802\n",
            "Epoch 27/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2942 - accuracy: 0.8870 - val_loss: 0.3399 - val_accuracy: 0.8840\n",
            "Epoch 28/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2895 - accuracy: 0.8928 - val_loss: 0.4628 - val_accuracy: 0.8436\n",
            "Epoch 29/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2902 - accuracy: 0.8918 - val_loss: 0.2916 - val_accuracy: 0.8949\n",
            "Epoch 30/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2707 - accuracy: 0.8977 - val_loss: 0.3138 - val_accuracy: 0.8942\n",
            "Epoch 31/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2570 - accuracy: 0.9042 - val_loss: 0.3751 - val_accuracy: 0.8732\n",
            "Epoch 32/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2467 - accuracy: 0.9091 - val_loss: 0.3656 - val_accuracy: 0.8677\n",
            "Epoch 33/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2420 - accuracy: 0.9075 - val_loss: 0.3530 - val_accuracy: 0.8895\n",
            "Epoch 34/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2387 - accuracy: 0.9071 - val_loss: 0.2999 - val_accuracy: 0.8926\n",
            "Epoch 35/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2304 - accuracy: 0.9128 - val_loss: 0.3334 - val_accuracy: 0.8942\n",
            "Epoch 36/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2329 - accuracy: 0.9126 - val_loss: 0.2849 - val_accuracy: 0.8973\n",
            "Epoch 37/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2237 - accuracy: 0.9142 - val_loss: 0.7005 - val_accuracy: 0.8125\n",
            "Epoch 38/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2145 - accuracy: 0.9183 - val_loss: 0.2485 - val_accuracy: 0.9074\n",
            "Epoch 39/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2143 - accuracy: 0.9207 - val_loss: 0.4155 - val_accuracy: 0.8669\n",
            "Epoch 40/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.2055 - accuracy: 0.9228 - val_loss: 0.3403 - val_accuracy: 0.8895\n",
            "Epoch 41/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1913 - accuracy: 0.9268 - val_loss: 0.2615 - val_accuracy: 0.9058\n",
            "Epoch 42/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1943 - accuracy: 0.9273 - val_loss: 1.0848 - val_accuracy: 0.7790\n",
            "Epoch 43/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1810 - accuracy: 0.9334 - val_loss: 0.3228 - val_accuracy: 0.8833\n",
            "Epoch 44/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1915 - accuracy: 0.9265 - val_loss: 0.2490 - val_accuracy: 0.8996\n",
            "Epoch 45/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1692 - accuracy: 0.9351 - val_loss: 0.2649 - val_accuracy: 0.9066\n",
            "Epoch 46/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1791 - accuracy: 0.9326 - val_loss: 0.3945 - val_accuracy: 0.8887\n",
            "Epoch 47/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1727 - accuracy: 0.9343 - val_loss: 0.2534 - val_accuracy: 0.9035\n",
            "Epoch 48/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1696 - accuracy: 0.9333 - val_loss: 0.2347 - val_accuracy: 0.9175\n",
            "Epoch 49/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.2354 - val_accuracy: 0.9160\n",
            "Epoch 50/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1598 - accuracy: 0.9375 - val_loss: 0.2882 - val_accuracy: 0.9035\n",
            "Epoch 51/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1676 - accuracy: 0.9371 - val_loss: 0.2019 - val_accuracy: 0.9284\n",
            "Epoch 52/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1528 - accuracy: 0.9411 - val_loss: 0.1956 - val_accuracy: 0.9276\n",
            "Epoch 53/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1566 - accuracy: 0.9420 - val_loss: 0.2468 - val_accuracy: 0.9097\n",
            "Epoch 54/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1490 - accuracy: 0.9425 - val_loss: 0.5419 - val_accuracy: 0.8638\n",
            "Epoch 55/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1494 - accuracy: 0.9436 - val_loss: 0.1882 - val_accuracy: 0.9323\n",
            "Epoch 56/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1520 - accuracy: 0.9423 - val_loss: 0.2347 - val_accuracy: 0.9222\n",
            "Epoch 57/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1384 - accuracy: 0.9471 - val_loss: 0.2335 - val_accuracy: 0.9160\n",
            "Epoch 58/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1375 - accuracy: 0.9459 - val_loss: 0.3615 - val_accuracy: 0.8981\n",
            "Epoch 59/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1384 - accuracy: 0.9482 - val_loss: 0.1742 - val_accuracy: 0.9362\n",
            "Epoch 60/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1325 - accuracy: 0.9513 - val_loss: 0.2464 - val_accuracy: 0.9230\n",
            "Epoch 61/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1232 - accuracy: 0.9512 - val_loss: 0.2138 - val_accuracy: 0.9300\n",
            "Epoch 62/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1265 - accuracy: 0.9519 - val_loss: 0.4620 - val_accuracy: 0.8755\n",
            "Epoch 63/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1256 - accuracy: 0.9526 - val_loss: 0.2114 - val_accuracy: 0.9346\n",
            "Epoch 64/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1261 - accuracy: 0.9516 - val_loss: 0.6996 - val_accuracy: 0.8257\n",
            "Epoch 65/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1258 - accuracy: 0.9521 - val_loss: 0.2598 - val_accuracy: 0.9206\n",
            "Epoch 66/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1168 - accuracy: 0.9563 - val_loss: 0.2929 - val_accuracy: 0.9245\n",
            "Epoch 67/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1163 - accuracy: 0.9558 - val_loss: 0.2297 - val_accuracy: 0.9292\n",
            "Epoch 68/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1139 - accuracy: 0.9538 - val_loss: 0.4315 - val_accuracy: 0.8887\n",
            "Epoch 69/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1136 - accuracy: 0.9539 - val_loss: 0.4948 - val_accuracy: 0.8778\n",
            "Epoch 70/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1201 - accuracy: 0.9543 - val_loss: 0.1917 - val_accuracy: 0.9385\n",
            "Epoch 71/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1062 - accuracy: 0.9587 - val_loss: 0.2349 - val_accuracy: 0.9245\n",
            "Epoch 72/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1138 - accuracy: 0.9587 - val_loss: 0.1831 - val_accuracy: 0.9393\n",
            "Epoch 73/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1118 - accuracy: 0.9566 - val_loss: 0.2251 - val_accuracy: 0.9160\n",
            "Epoch 74/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1014 - accuracy: 0.9605 - val_loss: 0.5409 - val_accuracy: 0.8732\n",
            "Epoch 75/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1031 - accuracy: 0.9598 - val_loss: 0.1803 - val_accuracy: 0.9377\n",
            "Epoch 76/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1051 - accuracy: 0.9579 - val_loss: 0.4314 - val_accuracy: 0.8895\n",
            "Epoch 77/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0982 - accuracy: 0.9612 - val_loss: 0.2440 - val_accuracy: 0.9276\n",
            "Epoch 78/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.1011 - accuracy: 0.9621 - val_loss: 0.2416 - val_accuracy: 0.9323\n",
            "Epoch 79/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0965 - accuracy: 0.9623 - val_loss: 0.1966 - val_accuracy: 0.9323\n",
            "Epoch 80/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0936 - accuracy: 0.9646 - val_loss: 0.2306 - val_accuracy: 0.9268\n",
            "Epoch 81/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0970 - accuracy: 0.9607 - val_loss: 0.2569 - val_accuracy: 0.9284\n",
            "Epoch 82/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0910 - accuracy: 0.9652 - val_loss: 0.1915 - val_accuracy: 0.9432\n",
            "Epoch 83/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0997 - accuracy: 0.9634 - val_loss: 0.2163 - val_accuracy: 0.9362\n",
            "Epoch 84/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0913 - accuracy: 0.9649 - val_loss: 1.2530 - val_accuracy: 0.7922\n",
            "Epoch 85/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0943 - accuracy: 0.9621 - val_loss: 0.2113 - val_accuracy: 0.9370\n",
            "Epoch 86/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 0.2092 - val_accuracy: 0.9362\n",
            "Epoch 87/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0916 - accuracy: 0.9651 - val_loss: 0.1841 - val_accuracy: 0.9463\n",
            "Epoch 88/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0927 - accuracy: 0.9648 - val_loss: 0.3836 - val_accuracy: 0.8973\n",
            "Epoch 89/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0834 - accuracy: 0.9667 - val_loss: 0.2469 - val_accuracy: 0.9331\n",
            "Epoch 90/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0916 - accuracy: 0.9654 - val_loss: 0.1916 - val_accuracy: 0.9354\n",
            "Epoch 91/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0879 - accuracy: 0.9652 - val_loss: 0.2071 - val_accuracy: 0.9346\n",
            "Epoch 92/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0839 - accuracy: 0.9687 - val_loss: 0.2413 - val_accuracy: 0.9292\n",
            "Epoch 93/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0798 - accuracy: 0.9692 - val_loss: 0.1657 - val_accuracy: 0.9447\n",
            "Epoch 94/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0795 - accuracy: 0.9698 - val_loss: 0.2235 - val_accuracy: 0.9370\n",
            "Epoch 95/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.2184 - val_accuracy: 0.9393\n",
            "Epoch 96/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0836 - accuracy: 0.9678 - val_loss: 0.2642 - val_accuracy: 0.9253\n",
            "Epoch 97/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0818 - accuracy: 0.9683 - val_loss: 0.2477 - val_accuracy: 0.9183\n",
            "Epoch 98/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.2413 - val_accuracy: 0.9284\n",
            "Epoch 99/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0819 - accuracy: 0.9696 - val_loss: 0.2619 - val_accuracy: 0.9370\n",
            "Epoch 100/100\n",
            "362/362 [==============================] - 5s 13ms/step - loss: 0.0755 - accuracy: 0.9686 - val_loss: 0.1553 - val_accuracy: 0.9502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(history.history['accuracy'])\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "\n",
        "print(f\"평균 정확도: {accuracy:.4f}\")\n",
        "print(f\"평균 손실: {loss:.4f}\")\n",
        "print(f\"평균 검증 정확도: {val_accuracy:.4f}\")\n",
        "print(f\"평균 검증 손실: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3jMKJG5U7gI",
        "outputId": "971bb367-f11c-4ff6-d19e-cc751f013a72"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도: 0.8957\n",
            "평균 손실: 0.2748\n",
            "평균 검증 정확도: 0.8602\n",
            "평균 검증 손실: 0.4225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZY1m2Fis5pO"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test data로 비교"
      ],
      "metadata": {
        "id": "PDTDNdJDn9ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "J8Gk51iVs6xL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fa59c3-b3dd-4f4b-9a06-333492a2374e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 40ms/step\n",
            "////////////////////\n",
            "1.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "100.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "101.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "104.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "10.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "102.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "106.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "108.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "107.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "103.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "105.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "12.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "130.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "131.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "137.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "122.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "119.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "117.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "118.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "127.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "123.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "125.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "13.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "109.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "112.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "135.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "110.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "124.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "115.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "121.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "138.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "136.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "114.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "132.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "128.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "133.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "134.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "111.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "129.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "113.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "126.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "120.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "116.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "11.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "152.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "163.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "169.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "146.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "139.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "156.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "151.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "153.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "167.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "157.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "149.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "16.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "15.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "162.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "159.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "148.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "158.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "143.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "17.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "160.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "140.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "168.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "166.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "142.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "145.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "150.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "154.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "165.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "147.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "161.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "155.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "14.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "144.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "141.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "164.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "188.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "178.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "180.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "179.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "177.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "190.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "184.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "2.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "174.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "20.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "192.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "195.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "193.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "18.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "187.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "189.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "175.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "191.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "197.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "173.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "183.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "198.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "172.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "171.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "185.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "200.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "19.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "194.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "181.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "182.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "186.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "199.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "196.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "201.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "170.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "176.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "202.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "25.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "212.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "28.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "27.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "220.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "26.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "217.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "21.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "31.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "218.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "206.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "209.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "215.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "32.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "211.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "34.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "30.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "216.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "24.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "33.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "214.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "207.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "208.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "219.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "36.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "23.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "213.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "210.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "22.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "205.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "203.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "35.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "204.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "29.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "3.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "55.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "38.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "69.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "66.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "61.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "68.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "6.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "51.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "5.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "65.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "37.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "49.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "52.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "50.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "59.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "67.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "63.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "60.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "40.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "4.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "44.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "56.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "58.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "42.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "54.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "53.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "48.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "39.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "62.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "47.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "41.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "64.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "45.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "46.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "57.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "43.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "9.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "73.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "78.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "70.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "76.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "87.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "96.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "81.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "83.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "97.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "94.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "72.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "90.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "93.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "82.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "84.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "7.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "85.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "80.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "8.jpg의 예측되는 구름종류 : Cb\n",
            "////////////////////\n",
            "71.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "86.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "92.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "99.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "98.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "75.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "74.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "88.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "89.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "95.jpg의 예측되는 구름종류 : St\n",
            "////////////////////\n",
            "77.jpg의 예측되는 구름종류 : Sc\n",
            "////////////////////\n",
            "79.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n",
            "91.jpg의 예측되는 구름종류 : Cc\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/clouddata/test/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train14\") #train위치\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path+\"/*.*\")\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model10.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 찍은 data로 비교"
      ],
      "metadata": {
        "id": "yafGfeJAoGKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/mydata/\"\n",
        "category = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/clouddata/train14\")\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(path2+\"/*.*\")\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "prediction_test = model10.predict(X)\n",
        "\n",
        "file_index = 0\n",
        "k=0\n",
        "for i in prediction_test:\n",
        "    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스\n",
        "    print(\"////////////////////\")\n",
        "    # Display the image\n",
        "    plt.imshow(X[k])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print( filenames[file_index].split('/')[-1] + \"의 예측되는 구름종류 : \" + category[label])\n",
        "    file_index  = file_index+1\n",
        "    k=k+1"
      ],
      "metadata": {
        "id": "vN-F1N_8lPPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1b91dfb-c8b9-426b-8c0f-ed333f439f61"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 164ms/step\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloud.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloud1.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloud2.jpg의 예측되는 구름종류 : Cc\n",
            "////////////////////\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloud3.jpg의 예측되는 구름종류 : Cc\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvB8szjXDAIyDujxZSjaTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}